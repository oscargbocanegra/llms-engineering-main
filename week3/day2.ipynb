{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f2ed49d-7873-4a03-bdc8-bda1c23cb979",
   "metadata": {},
   "source": [
    "# HuggingFace pipelines\n",
    "\n",
    "For this session we head to Google Colab and use this Notebook to explore the HuggingFace High Level API, pipelines.\n",
    "\n",
    "https://colab.research.google.com/drive/1aMaEw8A56xs0bRM4lu8z7ou18jqyybGm?usp=sharing\n",
    "\n",
    "You can use a low cost (or free) T4 GPU runtime for this notebook - and the results look great!\n",
    "\n",
    "There are instructions in the notebook for setting up your HuggingFace Token and including it as a secret in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5d84b78-0a02-4a35-8f10-e3f7451d352f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q transformers datasets diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd54e9de-ec0c-4bfa-bf1c-4f05cd9fadfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import os\n",
    "import soundfile as sf\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "from transformers import pipeline\n",
    "from diffusers import DiffusionPipeline\n",
    "from datasets import load_dataset\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e246890-4629-494d-8110-931f07958837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face API Key loaded: hf_f...\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# API keys from environment\n",
    "HUGGINGFACE_API_KEY = os.getenv('HUGGINGFACE_API_KEY')\n",
    "\n",
    "# Verify API keys\n",
    "if HUGGINGFACE_API_KEY:\n",
    "    print(f\"Hugging Face API Key loaded: {HUGGINGFACE_API_KEY[:4]}...\")\n",
    "else:\n",
    "    print(\"Hugging Face API Key not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "794f022e-d2c2-45e5-9de6-5e1ff89d0243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged in to Hugging Face successfully!\n"
     ]
    }
   ],
   "source": [
    "# Login to Hugging Face\n",
    "if HUGGINGFACE_API_KEY:\n",
    "    login(HUGGINGFACE_API_KEY)\n",
    "    print(\"Logged in to Hugging Face successfully!\")\n",
    "else:\n",
    "    print(\"Error: HUGGINGFACE_API_KEY not found in environment variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b53eb975-fead-4517-9f6f-8d4ffdb7affb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Usar CPU en lugar de CUDA si no hay GPU disponible\n",
    "clasiffier = pipeline(\"sentiment-analysis\", device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "282c61b0-5d6c-4eb3-9449-c85398f12ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9305714964866638}]\n"
     ]
    }
   ],
   "source": [
    "# sentiment Analysis\n",
    "\n",
    "result = clasiffier(\"!Estoy super emocionado de estar en camino hacia la maestria en LLM!\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "57e2ef7d-b63f-4ba0-a6ce-522e74ab2b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision 4c53496 (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "960ca68a14274c19a6bc2e79529ce497",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/998 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec7c9c2339974b548b3b8a23fe3fa06b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9acdd95f77d64924a2ea6cc411a0bf66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/60.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c349f2d11af945d08689a6c597c7fe44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity_group': 'PER', 'score': 0.99757403, 'word': 'Barak Obama', 'start': 0, 'end': 11}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/LLM/lib/python3.11/site-packages/transformers/pipelines/token_classification.py:186: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Named Entity Recognition\n",
    "\n",
    "ner = pipeline(\"ner\", grouped_entities=True, device=\"cpu\")\n",
    "result = ner(\"Barak Obama fue el 44 presidente de los estados unidos\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "37ef3374-a5e7-4b57-8cbc-eafdf666453e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 564e9b5 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.8796626329421997, 'start': 0, 'end': 12, 'answer': 'Barack Obama'}\n"
     ]
    }
   ],
   "source": [
    "# Question Answering with context\n",
    "\n",
    "question_answerer = pipeline(\"question-answering\", device=\"cpu\")\n",
    "result = question_answerer(question=\"¿Quien fue el 44 presidente de los estados unidos?\", \n",
    "                           context=\"Barack Obama fue el 44 presidente de los estados unidos\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb598c4a-65cb-47e2-a852-57258c5bf279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Sumarization\n",
    "\n",
    "sumarizer = pipeline(\"summarization\", device=\"cuda\")\n",
    "text = \"\"\"Hugging Face Transformers ha estado causando sensación en el campo del Procesamiento del Lenguaje Natural (PLN). \n",
    "Ofrece una API fácil de usar que reduce los costos de computación aprovechando modelos pre-entrenados de última tecnología \n",
    "para varias tareas de PLN. Este artículo se adentrará en el mundo de Hugging Face Transformers, explorando sus \n",
    "características, beneficios y cómo se destacan en el panorama del PLN.\n",
    "\n",
    "La biblioteca Hugging Face Transformers es un recurso completo que proporciona modelos pre-entrenados para tareas de PLN \n",
    "como análisis de sentimientos, clasificación de texto y reconocimiento de entidades nombradas. También ofrece herramientas \n",
    "para ajustar estos modelos para adaptarlos a casos de uso específicos. Este artículo te guiará a través de las \n",
    "complejidades de Hugging Face Transformers, sus aplicaciones y cómo usarlos de manera efectiva.\n",
    "\"\"\"\n",
    "\n",
    "summary = sumarizer(text, max_length=50, min_length=25, do_sample=False)\n",
    "print(summary[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e6988d-0ecb-4685-8c17-e059d7c390fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traslation\n",
    "\n",
    "traslator = pipeline(\"translation_en_to_fr\", device=\"cuda\")\n",
    "result = traslator(\"Hugging Face Transformers has been causing a sensation in the field of Natural Language Processing (NLP).\")\n",
    "print(result[0]['translation_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd31bcab-f5d4-4d53-970f-47dd36362fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clasificacion\n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\", device=\"cuda\")\n",
    "result = classifier(\"¡La biblioteca de Transformers de Hugging face es increibe!\",\n",
    "                    candidate_labels=[\"tecnologia\", \"deporte\", \"politica\"])\n",
    "print(result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc598562-780b-42d0-975d-01711817f242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Generation\n",
    "\n",
    "generator = pipeline(\"text-generation\", device=\"cuda\")\n",
    "result = generator(\"Si hay algo que quiero que recuerdes sobre el uso de los ppelines de Hugging Face,\")\n",
    "print(result[0]['generated_text'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955de0b2-7d4d-4d9a-9bbd-d63a2314c89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagen_gen = DiffusionPipeline.from_pretrained(\n",
    "\"stabilityai/stable-diffusion-xl-base-1.0\",\n",
    "torch_dtype=torch.float16,\n",
    "use_safetensors=True,\n",
    "variant=\"fp16\",\n",
    ").to(\"cpu\")\n",
    "\n",
    "\n",
    "text = \"Una clase de centificos de datos aprendiendo sobre IA, al estilo de Salvador Daly\"\n",
    "image = imagen_gen(prompt=text).images[0]\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae556816-d50b-46ac-9ef0-e7179e77ab6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import soundfile as sf\n",
    "from IPython.display import Audio\n",
    "\n",
    "# Audio Generation\n",
    "#synthesiser = pipeline(\"text-to-speech\", \"facebook/mms-tts-eng\", device=\"cuda\")\n",
    "synthesiser = pipeline(\"text-to-speech\", \"facebook/mms-tts-spa\", device=\"cuda\")\n",
    "\n",
    "# The problematic lines related to embeddings_dataset and speaker_embeddings are removed\n",
    "# as they are not needed for 'facebook/mms-tts-eng' with the pipeline.\n",
    "\n",
    "speech = synthesiser(\"!Hola a un ingeniero de Inteligencia Artificial, en camino hacia la maestría\")\n",
    "\n",
    "sf.write(\"speech.wav\", speech[\"audio\"].flatten(), samplerate=speech[\"sampling_rate\"], subtype='PCM_16', format='WAV')\n",
    "Audio(\"speech.wav\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (LLM)",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
