{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "473e5b39-da8f-4db1-83ae-dbaca2e9531e",
   "metadata": {},
   "source": [
    "# Personalized Programming Tutor - Week 2 Project 2\n",
    "\n",
    "## Project Objective\n",
    "\n",
    "Agente con inteligencia artificial multimodal para una aerolÃ­nea.\n",
    "\n",
    "### desafÃ­o para este proyecto\n",
    "- **Reservas** AÃ±ade otra herramienta para hacer una reserva\n",
    "- **Traductor** AÃ±ade un agente que traduzca todas las respuestas a otro idioma\n",
    "- **Audio** AÃ±ade otro agente que pueda escuchar audio y convertirlo a texto.\n",
    "\n",
    "\n",
    "### Features:\n",
    "\n",
    "- **Flexible**: Switch between Ollama (local, free) and OpenAI (cloud)\n",
    "- **Interactive**: Streaming mode with typewriter effect\n",
    "- **Educational**: Designed specifically for learning\n",
    "\n",
    "---\n",
    "\n",
    "**Instructions**: Execute the cells in order and modify the `question` variable to ask new questions.\n",
    "\n",
    "---\n",
    "**Models (ALL FREE!)**\n",
    "- **Text** gemini-2.0-flash-exp (Google Gemini - FREE, 15 RPM)\n",
    "- **Image** Pollinations AI (FREE - no API key needed)\n",
    "- **Audio a Texto** Whisper large-v3 (ASR)\n",
    "- **Texto a voz** gTTS (Google TTS - FREE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab88d6e",
   "metadata": {},
   "source": [
    "## ðŸŽ‰ 100% GRATIS - All Free Models!\n",
    "\n",
    "âš ï¸ **REALIDAD: Google NO tiene generaciÃ³n de imÃ¡genes gratuita**\n",
    "\n",
    "DespuÃ©s de revisar la documentaciÃ³n y probar los modelos:\n",
    "- âŒ `imagen-4.0` - Requiere facturaciÃ³n ($0.02-$0.06/imagen)\n",
    "- âŒ `gemini-2.5-flash-image` - Requiere facturaciÃ³n ($0.039/imagen)  \n",
    "- âŒ `gemini-2.0-flash` - Solo puede **analizar** imÃ¡genes, no generarlas\n",
    "\n",
    "**âœ… SOLUCIÃ“N: Pollinations AI (Completamente GRATIS)**\n",
    "\n",
    "| FunciÃ³n | Modelo | Proveedor | Costo |\n",
    "|---------|--------|-----------|-------|\n",
    "| ðŸ’¬ Chat | `gemini-2.0-flash-exp` | Google AI | **FREE** (15 RPM) |\n",
    "| ðŸ–¼ï¸ ImÃ¡genes | `Pollinations AI` | Pollinations.ai | **FREE** (sin lÃ­mite) |\n",
    "| ðŸ”Š Voz | `gTTS` | Google TTS | **FREE** |\n",
    "\n",
    "**Requisitos:**\n",
    "1. Para Chat - API Key de Google (gratis): https://aistudio.google.com/apikey\n",
    "2. Para ImÃ¡genes - **NO requiere API key** (Pollinations AI)\n",
    "3. Agregar al archivo `.env`:\n",
    "   ```\n",
    "   GOOGLE_API_KEY=tu_key_aqui\n",
    "   ```\n",
    "\n",
    "**LÃ­mites gratuitos:**\n",
    "- Gemini 2.0 Flash: 15 requests/minuto\n",
    "- Pollinations AI: Ilimitado (sin autenticaciÃ³n)\n",
    "- gTTS: Ilimitado\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3e0545",
   "metadata": {},
   "source": [
    "### âš ï¸ Errores comunes con generaciÃ³n de imÃ¡genes en Google\n",
    "\n",
    "**Error 1: \"Imagen API is only accessible to billed users\"**\n",
    "- Causa: Intentando usar `imagen-4.0-generate-001`\n",
    "- SoluciÃ³n: Requiere cuenta de Google Cloud con facturaciÃ³n\n",
    "\n",
    "**Error 2: \"Model does not support the requested response modalities: image\"**\n",
    "- Causa: `gemini-2.0-flash` **NO puede generar imÃ¡genes**, solo analizarlas\n",
    "- SoluciÃ³n: Usar Pollinations AI o habilitar facturaciÃ³n\n",
    "\n",
    "**La verdad sobre Google Gemini e imÃ¡genes:**\n",
    "- âœ… Gemini puede **analizar/entender** imÃ¡genes (GRATIS)\n",
    "- âŒ Gemini NO puede **generar** imÃ¡genes sin facturaciÃ³n\n",
    "- âœ… Pollinations AI **SÃ genera** imÃ¡genes gratis sin API key\n",
    "\n",
    "**Por eso este notebook usa Pollinations AI** ðŸŽ¨\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c166723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Install Google Gemini SDK (for chat only - image generation not free)\n",
    "!pip install -q google-genai\n",
    "\n",
    "# Install requests and pillow for Pollinations AI (FREE image generation)\n",
    "!pip install -q requests pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e7f9b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Install Google TTS (Text-to-Speech - FREE)\n",
    "!pip install -q gtts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2c27c4ba-8ed5-492f-add1-02ce9c81d34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "\n",
    "import base64\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "import gradio as gr\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from IPython.display import display\n",
    "from google import genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7f42c899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Ollama API Key loaded: 7885...\n",
      "âœ… Ollama configured at: http://192.168.80.200:11434\n",
      "âœ… Google API Key loaded: AIzaSyDO...\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# API keys from environment\n",
    "ollama_base_url = os.getenv('OLLAMA_BASE_URL')\n",
    "ollama_api_key = os.getenv('OLLAMA_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "# Verify API keys\n",
    "if ollama_api_key:\n",
    "    print(f\"âœ… Ollama API Key loaded: {ollama_api_key[:4]}...\")\n",
    "else:\n",
    "    print(\"âŒ Ollama API Key not set\")\n",
    "\n",
    "if ollama_base_url:\n",
    "    print(f\"âœ… Ollama configured at: {ollama_base_url}\")\n",
    "else:\n",
    "    print(\"âŒ Ollama Base URL not set\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"âœ… Google API Key loaded: {google_api_key[:8]}...\")\n",
    "else:\n",
    "    print(\"âŒ Google API Key not set (needed for FREE Imagen images)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "54c72813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Ollama client initialized\n",
      "   Chat Model: deepseek-v3.1:671b-cloud\n",
      "âœ… Google client initialized\n",
      "   Chat Model: gemini-2.0-flash-exp (Gemini 2.0 Flash - FREE)\n",
      "âœ… Image generation: Pollinations AI (100% FREE - no API key needed)\n"
     ]
    }
   ],
   "source": [
    "# Initialize clients\n",
    "ollama_client = OpenAI(base_url=f\"{ollama_base_url}/v1\", api_key=ollama_api_key)\n",
    "google_client = genai.Client(api_key=google_api_key)\n",
    "\n",
    "# Model configurations\n",
    "OLLAMA_CHAT_MODEL = \"deepseek-v3.1:671b-cloud\"  # Chat (FREE with Ollama)\n",
    "GEMINI_CHAT_MODEL = \"gemini-2.0-flash-exp\"  # Chat (FREE with Google - 15 RPM)\n",
    "\n",
    "print(f\"âœ… Ollama client initialized\")\n",
    "print(f\"   Chat Model: {OLLAMA_CHAT_MODEL}\")\n",
    "print(f\"âœ… Google client initialized\")\n",
    "print(f\"   Chat Model: {GEMINI_CHAT_MODEL} (Gemini 2.0 Flash - FREE)\")\n",
    "print(f\"âœ… Image generation: Pollinations AI (100% FREE - no API key needed)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "773a9f11-557e-43c9-ad50-56cbec3a0f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def artist(city):\n",
    "    \"\"\"\n",
    "    Generate images using Pollinations AI (100% FREE - no API key needed)\n",
    "    \n",
    "    Why Pollinations AI?\n",
    "    - Google Gemini models (gemini-2.0-flash, gemini-2.5-flash-image) require billing\n",
    "    - Imagen 4 requires Google Cloud with billing enabled\n",
    "    - Pollinations AI is completely free with no authentication\n",
    "    \n",
    "    Docs: https://pollinations.ai/\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Pollinations AI - completely free text-to-image API\n",
    "        prompt = f\"An image representing a vacation in {city}, showing tourist spots and everything unique about {city}, in a vibrant pop-art style\"\n",
    "        \n",
    "        # Encode prompt for URL\n",
    "        encoded_prompt = requests.utils.quote(prompt)\n",
    "        \n",
    "        # Pollinations API endpoint (no auth needed!)\n",
    "        url = f\"https://image.pollinations.ai/prompt/{encoded_prompt}\"\n",
    "        \n",
    "        print(f\"ðŸŽ¨ Generating image for: {city}\")\n",
    "        print(f\"   Using: Pollinations AI (FREE)\")\n",
    "        \n",
    "        # Download image\n",
    "        response = requests.get(url, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Convert to PIL Image\n",
    "        image = Image.open(BytesIO(response.content))\n",
    "        \n",
    "        print(f\"âœ… Image generated successfully\")\n",
    "        return image\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error generating image: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d877c453-e7fb-482a-88aa-1a03f976b9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¨ Generating image for: New York City\n",
      "   Using: Pollinations AI (FREE)\n",
      "âŒ Error generating image: 530 Server Error:  for url: https://image.pollinations.ai/prompt/An%20image%20representing%20a%20vacation%20in%20New%20York%20City%2C%20showing%20tourist%20spots%20and%20everything%20unique%20about%20New%20York%20City%2C%20in%20a%20vibrant%20pop-art%20style\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = artist(\"New York City\")\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af806283",
   "metadata": {},
   "source": [
    "### Nueva etapa: Audio/TTS (Text-to-Speech)\n",
    "\n",
    "Ahora vamos a agregar generaciÃ³n de voz para que el asistente pueda \"hablar\" las respuestas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728a12c5-adc3-415d-bb05-82beb73b079b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio TTS usando gTTS (100% GRATIS)\n",
    "from gtts import gTTS\n",
    "from io import BytesIO\n",
    "\n",
    "print(\"ðŸŽµ TTS configurado con gTTS (Google Text-to-Speech - FREE)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90002b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio generated: 38400 bytes\n",
      "Saved to test_audio_openai.mp3\n"
     ]
    }
   ],
   "source": [
    "# Test gTTS (Google TTS - FREE)\n",
    "audio_test = talker_local_gtts(\"Hello! Welcome to New York City.\")\n",
    "if audio_test:\n",
    "    print(f\"âœ… Audio generated: {len(audio_test)} bytes\")\n",
    "    with open(\"test_audio_gtts.mp3\", \"wb\") as f:\n",
    "        f.write(audio_test)\n",
    "    print(\"ðŸ’¾ Saved to test_audio_gtts.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55029bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install: pip install pyttsx3\n",
    "# For Google TTS: pip install gtts\n",
    "\n",
    "def talker_local_pyttsx3(message):\n",
    "    \"\"\"\n",
    "    Generate speech locally using pyttsx3 (FREE - offline)\n",
    "    Quality: Basic but functional\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import pyttsx3\n",
    "        engine = pyttsx3.init()\n",
    "        \n",
    "        # Save to file\n",
    "        output_file = \"audio_local.mp3\"\n",
    "        engine.save_to_file(message, output_file)\n",
    "        engine.runAndWait()\n",
    "        \n",
    "        # Read file content\n",
    "        with open(output_file, \"rb\") as f:\n",
    "            return f.read()\n",
    "    except ImportError:\n",
    "        print(\" Install: pip install pyttsx3\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfc6e91-f32c-405e-8881-e3efe2fb6239",
   "metadata": {},
   "outputs": [],
   "source": [
    "talker_local_pyttsx3(\"Hello! Welcome to New York City.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f4e02dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def talker_local_gtts(message):\n",
    "    \"\"\"\n",
    "    Generate speech using Google TTS (FREE - requires internet)\n",
    "    Quality: Better than pyttsx3, similar to basic cloud TTS\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from gtts import gTTS\n",
    "        from io import BytesIO\n",
    "        \n",
    "        # Generate speech\n",
    "        tts = gTTS(text=message, lang='es')  # Change 'es' to 'en' for English\n",
    "        \n",
    "        # Save to BytesIO\n",
    "        audio_fp = BytesIO()\n",
    "        tts.write_to_fp(audio_fp)\n",
    "        audio_fp.seek(0)\n",
    "        \n",
    "        return audio_fp.read()\n",
    "    except ImportError:\n",
    "        print(\" Install: pip install gtts\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1439163d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Audio generated: 25536 bytes\n",
      " Saved to test_audio_gtts.mp3\n",
      "You can now download and play this file\n"
     ]
    }
   ],
   "source": [
    "# Test gTTS - Generate and save audio\n",
    "audio_gtts = talker_local_gtts(\"Hello! Welcome to New York City.\")\n",
    "\n",
    "if audio_gtts:\n",
    "    print(f\" Audio generated: {len(audio_gtts)} bytes\")\n",
    "    \n",
    "    # Save to file to listen\n",
    "    with open(\"test_audio_gtts.mp3\", \"wb\") as f:\n",
    "        f.write(audio_gtts)\n",
    "    print(\" Saved to test_audio_gtts.mp3\")\n",
    "    print(\"You can now download and play this file\")\n",
    "else:\n",
    "    print(\" Failed to generate audio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b51c5a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¤ Available Coqui TTS Voices:\n",
      "\n",
      "âœ… LIGHTWEIGHT (Recommended):\n",
      "  - tacotron2_en: ~100MB - Female English (fastest)\n",
      "  - tacotron2_es: ~100MB - Female Spanish\n",
      "  - glow_tts_en: ~120MB - Female English (good quality)\n",
      "\n",
      "âš ï¸ MEDIUM:\n",
      "  - vits_en: ~200MB - Better quality\n",
      "  - vits_es: ~200MB - Spanish better quality\n",
      "\n",
      "ðŸ”´ HEAVY (Avoid in notebooks):\n",
      "  - jenny: 1.6GB - Very high quality (TOO HEAVY)\n",
      "  - vctk: ~800MB - Multiple speakers\n"
     ]
    }
   ],
   "source": [
    "# Install Coqui TTS: pip install TTS\n",
    "\n",
    "# Available voices/models for Coqui TTS\n",
    "COQUI_VOICES = {\n",
    "    # === LIGHTWEIGHT MODELS (Recommended for notebooks) ===\n",
    "    \"tacotron2_en\": \"tts_models/en/ljspeech/tacotron2-DDC\",      # ~100MB - Female English (FASTEST)\n",
    "    \"tacotron2_es\": \"tts_models/es/mai/tacotron2-DDC\",           # ~100MB - Female Spanish\n",
    "    \"glow_tts_en\": \"tts_models/en/ljspeech/glow-tts\",            # ~120MB - Female English (good quality)\n",
    "    \n",
    "    # === MEDIUM MODELS ===\n",
    "    \"vits_en\": \"tts_models/en/ljspeech/vits\",                    # ~200MB - Better quality\n",
    "    \"vits_es\": \"tts_models/es/css10/vits\",                       # ~200MB - Spanish better quality\n",
    "    \n",
    "    # === HEAVY MODELS (NOT RECOMMENDED for notebooks) ===\n",
    "    \"jenny\": \"tts_models/en/jenny/jenny\",                        # ðŸ”´ 1.6GB - Very high quality (TOO HEAVY)\n",
    "    \"vctk\": \"tts_models/en/vctk/vits\",                           # ðŸ”´ ~800MB - Multiple speakers\n",
    "}\n",
    "\n",
    "# Print available voices with size info\n",
    "print(\"ðŸŽ¤ Available Coqui TTS Voices:\")\n",
    "print(\"\\nâœ… LIGHTWEIGHT (Recommended):\")\n",
    "print(\"  - tacotron2_en: ~100MB - Female English (fastest)\")\n",
    "print(\"  - tacotron2_es: ~100MB - Female Spanish\")\n",
    "print(\"  - glow_tts_en: ~120MB - Female English (good quality)\")\n",
    "print(\"\\nâš ï¸ MEDIUM:\")\n",
    "print(\"  - vits_en: ~200MB - Better quality\")\n",
    "print(\"  - vits_es: ~200MB - Spanish better quality\")\n",
    "print(\"\\nðŸ”´ HEAVY (Avoid in notebooks):\")\n",
    "print(\"  - jenny: 1.6GB - Very high quality (TOO HEAVY)\")\n",
    "print(\"  - vctk: ~800MB - Multiple speakers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a58265f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def talker_coqui(message, voice=\"tacotron2_es\"):\n",
    "    \"\"\"\n",
    "    Generate speech using Coqui TTS (FREE - high quality, multiple voices)\n",
    "    \n",
    "    Args:\n",
    "        message: Text to convert to speech\n",
    "        voice: Voice name from COQUI_VOICES (default: \"jenny\")\n",
    "        \n",
    "    Available voices:\n",
    "        - jenny (Female, American English - RECOMMENDED)\n",
    "        - ljspeech (Female, neutral English)\n",
    "        - mai_es (Female, Spanish)\n",
    "        - css10_es (Female, Spanish - better quality)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from TTS.api import TTS\n",
    "        import tempfile\n",
    "        import os\n",
    "        \n",
    "        # Get model path from voice name\n",
    "        model_path = COQUI_VOICES.get(voice, COQUI_VOICES[\"tacotron2_es\"])\n",
    "        \n",
    "        print(f\"ðŸ”Š Loading Coqui TTS model: {voice}\")\n",
    "        print(f\"   Model: {model_path}\")\n",
    "        print(f\"   Note: First run will download the model (~100-500MB)\")\n",
    "        \n",
    "        # Initialize TTS\n",
    "        tts = TTS(model_path)\n",
    "        \n",
    "        # Create temporary file\n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\") as tmp_file:\n",
    "            tmp_path = tmp_file.name\n",
    "        \n",
    "        # Generate speech\n",
    "        tts.tts_to_file(text=message, file_path=tmp_path)\n",
    "        \n",
    "        # Read audio data\n",
    "        with open(tmp_path, \"rb\") as f:\n",
    "            audio_data = f.read()\n",
    "        \n",
    "        # Clean up temp file\n",
    "        os.unlink(tmp_path)\n",
    "        \n",
    "        print(f\" Audio generated: {len(audio_data)} bytes\")\n",
    "        return audio_data\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\" Coqui TTS not installed\")\n",
    "        print(\"   Install: pip install TTS\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\" Error generating audio: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa27e821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Testing voice: tacotron2_en (English - LIGHTWEIGHT)\n",
      "==================================================\n",
      "ðŸ”Š Loading Coqui TTS model: tacotron2_en\n",
      "   Model: tts_models/en/ljspeech/tacotron2-DDC\n",
      "   Note: First run will download the model (~100-500MB)\n",
      " > tts_models/en/ljspeech/tacotron2-DDC is already downloaded.\n",
      " > vocoder_models/en/ljspeech/hifigan_v2 is already downloaded.\n",
      " > Using model: Tacotron2\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:2.718281828459045\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Model's reduction rate `r` is set to: 1\n",
      " > Vocoder Model: hifigan\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:2.718281828459045\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Generator Model: hifigan_generator\n",
      " > Discriminator Model: hifigan_discriminator\n",
      "Removing weight norm...\n",
      " > Text splitted to sentences.\n",
      "['Hello!', 'Welcome to New York City.']\n",
      " > Processing time: 1.06966233253479\n",
      " > Real-time factor: 0.3175632059509926\n",
      " Audio generated: 148588 bytes\n",
      "ðŸ’¾ Saved to test_audio_coqui_tacotron2.wav\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test Coqui TTS with LIGHTWEIGHT model\n",
    "\n",
    "# Test 1: Tacotron2 (English - LIGHTWEIGHT ~100MB)\n",
    "print(\"=\" * 50)\n",
    "print(\"Testing voice: tacotron2_en (English - LIGHTWEIGHT)\")\n",
    "print(\"=\" * 50)\n",
    "audio_coqui = talker_coqui(\"Hello! Welcome to New York City.\", voice=\"tacotron2_en\")\n",
    "\n",
    "if audio_coqui:\n",
    "    with open(\"test_audio_coqui_tacotron2.wav\", \"wb\") as f:\n",
    "        f.write(audio_coqui)\n",
    "    print(\"ðŸ’¾ Saved to test_audio_coqui_tacotron2.wav\")\n",
    "    print()\n",
    "\n",
    "# Test 2: Spanish lightweight (uncomment to test)\n",
    "# print(\"=\" * 50)\n",
    "# print(\"Testing voice: tacotron2_es (Spanish - LIGHTWEIGHT)\")\n",
    "# print(\"=\" * 50)\n",
    "# audio_coqui_es = talker_coqui(\"Hola! Bienvenido a Nueva York.\", voice=\"tacotron2_es\")\n",
    "# if audio_coqui_es:\n",
    "#     with open(\"test_audio_coqui_spanish.wav\", \"wb\") as f:\n",
    "#         f.write(audio_coqui_es)\n",
    "#     print(\"ðŸ’¾ Saved to test_audio_coqui_spanish.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80f8608",
   "metadata": {},
   "source": [
    "## Integrando Todo: Chat + Tools + Images + Audio\n",
    "\n",
    "Ahora vamos a juntar todo en un asistente multimodal completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e791f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat Model configured: qwen3-coder:480b-cloud\n"
     ]
    }
   ],
   "source": [
    "# Configuration for the airline assistant\n",
    "system_message = \"\"\"\n",
    "Eres un asistente Ãºtil para una aerolÃ­nea llamada FlightAI.\n",
    "Da respuestas breves y corteses, de no mÃ¡s de una oraciÃ³n.\n",
    "Se siempre preciso. Si no sabes la respuesta, dilo.\n",
    "\"\"\"\n",
    "\n",
    "# Choose which model to use for chat (ALL FREE OPTIONS)\n",
    "# MODEL = OLLAMA_CHAT_MODEL  # \"deepseek-v3.1:671b-cloud\" - Ollama FREE\n",
    "MODEL = GEMINI_CHAT_MODEL  # \"gemini-2.0-flash-exp\" - Google FREE (RECOMMENDED)\n",
    "\n",
    "print(f\"âœ… Chat Model configured: {MODEL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f736614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ticket prices database (from day4)\n",
    "ticket_prices = {\n",
    "    \"londres\": \"$799\",\n",
    "    \"paris\": \"$899\",\n",
    "    \"tokyo\": \"$1400\",\n",
    "    \"berlin\": \"$499\",\n",
    "    \"new york\": \"$650\",\n",
    "    \"barcelona\": \"$550\",\n",
    "    \"miami\": \"$450\"\n",
    "}\n",
    "\n",
    "def get_ticket_price(destination_city):\n",
    "    \"\"\"Get the price of a ticket to a specific city\"\"\"\n",
    "    print(f\"ðŸ”§ Tool called for city: {destination_city}\")\n",
    "    price = ticket_prices.get(destination_city.lower(), \"Unknown ticket price\")\n",
    "    return f\"The price of a ticket to {destination_city} is {price}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0202c61f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tools configured: 1 tool(s)\n"
     ]
    }
   ],
   "source": [
    "# Define the tool for OpenAI function calling\n",
    "price_function = {\n",
    "    \"name\": \"get_ticket_price\",\n",
    "    \"description\": \"Get the price of a return ticket to the destination city.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"destination_city\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city that the customer wants to travel to\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"destination_city\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}\n",
    "\n",
    "tools = [{\"type\": \"function\", \"function\": price_function}]\n",
    "print(f\" Tools configured: {len(tools)} tool(s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc7580b",
   "metadata": {},
   "source": [
    "## Let's bring this home:\n",
    "\n",
    "1. A multi-modal AI assistant with image and audio generation\n",
    "2. Tool callling with database lookup\n",
    "3. A step towards an Agentic workflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bd591c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio TTS Configuration - Choose your preferred TTS engine\n",
    "\n",
    "# Option 1: Google TTS Free (RECOMMENDED - FREE, good quality)\n",
    "USE_TTS_FUNCTION = talker_local_gtts\n",
    "\n",
    "# Option 2: Coqui TTS (FREE - offline, high quality but larger model)\n",
    "# USE_TTS_FUNCTION = lambda msg: talker_coqui(msg, voice=\"tacotron2_en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b119ed1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(history):\n",
    "    \"\"\"\n",
    "    Main chat function that integrates:\n",
    "    - Chat with Tools (Gemini or Ollama - both FREE)\n",
    "    - Image generation (Google Imagen 4 - FREE)\n",
    "    - Audio generation (gTTS - FREE)\n",
    "    \"\"\"\n",
    "    history = [{\"role\":h[\"role\"], \"content\":h[\"content\"]} for h in history]\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history\n",
    "    \n",
    "    cities = []\n",
    "    image = None\n",
    "    \n",
    "    # Choose client based on model\n",
    "    if MODEL == GEMINI_CHAT_MODEL:\n",
    "        # Use Google Gemini (FREE)\n",
    "        # Convert messages to Gemini format\n",
    "        gemini_messages = []\n",
    "        for msg in messages:\n",
    "            if msg[\"role\"] == \"system\":\n",
    "                continue  # Gemini doesn't use system messages the same way\n",
    "            gemini_messages.append({\n",
    "                \"role\": \"user\" if msg[\"role\"] == \"user\" else \"model\",\n",
    "                \"parts\": [{\"text\": msg[\"content\"]}]\n",
    "            })\n",
    "        \n",
    "        # Add system message as first user message\n",
    "        if messages and messages[0][\"role\"] == \"system\":\n",
    "            gemini_messages.insert(0, {\n",
    "                \"role\": \"user\",\n",
    "                \"parts\": [{\"text\": messages[0][\"content\"]}]\n",
    "            })\n",
    "        \n",
    "        response = google_client.models.generate_content(\n",
    "            model=MODEL,\n",
    "            contents=gemini_messages\n",
    "        )\n",
    "        \n",
    "        reply = response.text\n",
    "        \n",
    "        # Extract city from reply (simple heuristic)\n",
    "        for city in ticket_prices.keys():\n",
    "            if city.lower() in reply.lower():\n",
    "                cities.append(city)\n",
    "                break\n",
    "    else:\n",
    "        # Use Ollama client (works with OpenAI-compatible API)\n",
    "        response = ollama_client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=messages,\n",
    "            tools=tools\n",
    "        )\n",
    "        \n",
    "        # Handle tool calls (if any)\n",
    "        while response.choices[0].finish_reason==\"tool_calls\":\n",
    "            message = response.choices[0].message\n",
    "            responses, cities = handle_tool_calls_and_return_cities(message)\n",
    "            messages.append(message)\n",
    "            messages.extend(responses)\n",
    "            response = ollama_client.chat.completions.create(\n",
    "                model=MODEL,\n",
    "                messages=messages,\n",
    "                tools=tools\n",
    "            )\n",
    "        \n",
    "        reply = response.choices[0].message.content\n",
    "    \n",
    "    history += [{\"role\":\"assistant\", \"content\":reply}]\n",
    "\n",
    "    # Generate audio from reply using configured TTS engine\n",
    "    voice = USE_TTS_FUNCTION(reply)\n",
    "\n",
    "    # Generate image if a city was mentioned\n",
    "    if cities:\n",
    "        image = artist(cities[0])\n",
    "    \n",
    "    return history, voice, image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8a14d0-0362-4199-8a1f-d49e35f9eee5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5846bc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_tool_calls_and_return_cities(message):\n",
    "    responses = []\n",
    "    cities = []\n",
    "    for tool_call in message.tool_calls:\n",
    "        if tool_call.function.name == \"get_ticket_price\":\n",
    "            arguments = json.loads(tool_call.function.arguments)\n",
    "            city = arguments.get('destination_city')\n",
    "            cities.append(city)\n",
    "            price_details = get_ticket_price(city)\n",
    "            responses.append({\n",
    "                \"role\": \"tool\",\n",
    "                \"content\": price_details,\n",
    "                \"tool_call_id\": tool_call.id\n",
    "            })\n",
    "    return responses, cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58323850-3128-4265-b5a6-b7711ff07128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks (along with the chat() function above)\n",
    "\n",
    "def put_message_in_chatbot(message, history):\n",
    "        return \"\", history + [{\"role\":\"user\", \"content\":message}]\n",
    "\n",
    "# UI definition\n",
    "\n",
    "with gr.Blocks() as ui:\n",
    "    with gr.Row():\n",
    "        chatbot = gr.Chatbot(height=500, type=\"messages\")\n",
    "        image_output = gr.Image(height=500, interactive=False)\n",
    "    with gr.Row():\n",
    "        audio_output = gr.Audio(autoplay=True)\n",
    "    with gr.Row():\n",
    "        message = gr.Textbox(label=\"Chat with our AI Assistant:\")\n",
    "\n",
    "# Hooking up events to callbacks\n",
    "\n",
    "    message.submit(put_message_in_chatbot, inputs=[message, chatbot], outputs=[message, chatbot]).then(\n",
    "        chat, inputs=chatbot, outputs=[chatbot, audio_output, image_output]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5342f025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* Running on public URL: https://8b1025a2a7398f3198.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://8b1025a2a7398f3198.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ Tool called for city: Londres\n"
     ]
    }
   ],
   "source": [
    "# Launch the Gradio interface\n",
    "# Important: Use server_name=\"0.0.0.0\" for Docker/remote access\n",
    "\n",
    "ui.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (LLM)",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
