{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15d8294-3328-4e07-ad16-8a03e9bbfdb9",
   "metadata": {},
   "source": [
    "# YOUR FIRST LAB - Week 1, Day 1\n",
    "## üéØ AI-Powered Web Summarization with Ollama\n",
    "\n",
    "### What You'll Build\n",
    "An intelligent web browser that automatically summarizes websites using Large Language Models.\n",
    "\n",
    "---\n",
    "\n",
    "### Prerequisites\n",
    "- ‚úÖ Docker containers running (Conda + Ollama)\n",
    "- ‚úÖ LLM kernel selected (Python 3.11)\n",
    "- ‚úÖ Global `.env` file configured\n",
    "- ‚úÖ Ollama accessible at `http://localhost:11434`\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "**1. Environment Setup**\n",
    "- Load environment variables from `.env`\n",
    "- Connect to Ollama API (OpenAI-compatible interface)\n",
    "\n",
    "**2. Web Scraping**\n",
    "- Extract website content with BeautifulSoup\n",
    "- Handle HTML parsing and cleaning\n",
    "\n",
    "**3. Prompt Engineering**\n",
    "- Create effective system and user prompts\n",
    "- Structure messages for LLM APIs\n",
    "\n",
    "**4. LLM API Integration**\n",
    "- Make API calls to Ollama\n",
    "- Control model behavior (temperature, etc.)\n",
    "\n",
    "**5. Practical Application**\n",
    "- Build summarization function\n",
    "- Generate email subject lines\n",
    "\n",
    "**Expected Output:** A working prototype that summarizes any URL.\n",
    "\n",
    "---\n",
    "\n",
    "### Quick Start\n",
    "1. Press `Shift + Enter` to execute each cell\n",
    "2. Install dependencies (uncomment if needed)\n",
    "3. Verify `.env` configuration loads\n",
    "4. Run connection test\n",
    "5. Experiment with different websites\n",
    "\n",
    "---\n",
    "\n",
    "### üí° Learning Approach\n",
    "Execute this notebook yourself after watching the lecture. Add print statements, experiment with variations, and share your work on GitHub to showcase your skills."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f28feb",
   "metadata": {},
   "source": [
    "## üîß Setup\n",
    "\n",
    "### Select the Kernel\n",
    "\n",
    "1. Click **\"Select Kernel\"** (top-right)\n",
    "2. Choose **`llm (Python 3.11.x)`**\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "- Docker containers running (`conda-jupyter`, `ollama`)\n",
    "- Global `.env` configured at `/workspace/.env`\n",
    "- Ollama accessible at `http://localhost:11434`\n",
    "\n",
    "**Note:** Full setup instructions are in the [README](../README.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8527cb1c-2bfa-429e-8ae3-4ac64f9de337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installers\n",
    "import sys\n",
    "# Uncomment to install required packages\n",
    "# !{sys.executable} -m pip install python-dotenv\n",
    "# !{sys.executable} -m pip install beautifulsoup4\n",
    "# !{sys.executable} -m pip install requests\n",
    "# !{sys.executable} -m pip install openai  # openai library works with Ollama too!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91633991",
   "metadata": {},
   "source": [
    "## Instalaci√≥n de Dependencias\n",
    "\n",
    "Ejecuta la siguiente celda para instalar las dependencias necesarias. \n",
    "\n",
    "**Nota importante:** Estas se instalar√°n en el entorno correcto (LLM) gracias al uso de `sys.executable`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6900b2a8-6384-4316-8aaa-5e519fca4254",
   "metadata": {},
   "source": [
    "# Connecting to OpenAI (or Ollama)\n",
    "\n",
    "The next cell is where we load in the environment variables in your `.env` file and connect to OpenAI.  \n",
    "\n",
    "## Troubleshooting if you have problems:\n",
    "\n",
    "If you get a \"Name Error\" - have you run all cells from the top down? Head over to the Python Foundations guide for a bulletproof way to find and fix all Name Errors.\n",
    "\n",
    "Any concerns about API costs? See my notes in the README - costs should be minimal, and you can control it at every point. You can also use Ollama as a free alternative, which we discuss during Day 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94ae150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAI client pointing to Ollama\n",
    "openai = OpenAI(\n",
    "    base_url=f\"{ollama_base_url}/v1\",  # Ollama exposes OpenAI-compatible API at /v1\n",
    "    api_key=ollama_api_key  # Using API key from .env\n",
    ")\n",
    "\n",
    "# Test message\n",
    "message = \"Hello! This is my first message to you via Ollama! Hi!\"\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": message}]\n",
    "\n",
    "messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c411c549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Error: OLLAMA_BASE_URL not found in .env file!\n",
      "   Looking for .env at: D:/dockerInfraProjects/conda/.env\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables from global .env file\n",
    "\n",
    "# Path to global .env file (accessible from Docker container)\n",
    "# D:\\dockerVolumes\\conda\\notebooks is mounted as /workspace in the container\n",
    "global_env_path = '/workspace/.env'\n",
    "\n",
    "# Load the configuration\n",
    "load_dotenv(dotenv_path=global_env_path, override=True)\n",
    "\n",
    "# Get Ollama configuration from .env\n",
    "ollama_base_url = os.getenv('OLLAMA_BASE_URL')\n",
    "ollama_api_key = os.getenv('OLLAMA_API_KEY')\n",
    "ollama_model = os.getenv('OLLAMA_MODEL')\n",
    "\n",
    "# Check the configuration\n",
    "if not ollama_base_url:\n",
    "    print(\"‚ùå Error: OLLAMA_BASE_URL not found in .env file!\")\n",
    "    print(f\"   Looking for .env at: {global_env_path}\")\n",
    "elif not ollama_api_key:\n",
    "    print(\"‚ùå Error: OLLAMA_API_KEY not found in .env file!\")\n",
    "elif not ollama_model:\n",
    "    print(\"‚ùå Error: OLLAMA_MODEL not found in .env file!\")\n",
    "else:\n",
    "    print(\"‚úÖ Ollama configuration loaded successfully!\")\n",
    "    print(f\"   Base URL: {ollama_base_url}\")\n",
    "    print(f\"   Model: {ollama_model}\")\n",
    "    print(f\"   API Key: {'*' * 40}{ollama_api_key[-8:]}\")  # Hide most of the key\n",
    "    print(f\"   Loaded from: {global_env_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "08330159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! üëã Great to meet you‚Äîwelcome to Ollama! How can I help you today?'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make the API call to Ollama using the configured model\n",
    "response = openai.chat.completions.create(\n",
    "    model=ollama_model,  # Using the model from .env\n",
    "    messages=messages\n",
    ")\n",
    "response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c8b55b",
   "metadata": {},
   "source": [
    "### üîç Alternative: Native Ollama API Call (Without OpenAI Client)\n",
    "\n",
    "The cell above uses the **OpenAI client library** pointing to Ollama. Here's how you would call Ollama **directly** using its native API with `requests`:\n",
    "\n",
    "**Pros of direct approach:**\n",
    "- ‚úÖ No dependency on OpenAI library\n",
    "- ‚úÖ Direct control over HTTP requests\n",
    "- ‚úÖ Explicit about using Ollama\n",
    "\n",
    "**Cons:**\n",
    "- ‚ùå More verbose code\n",
    "- ‚ùå Need to handle HTTP errors manually\n",
    "- ‚ùå Less portable (can't switch to OpenAI easily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2ef960cf-6dc2-4cda-afb3-b38be12f4c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home - Edward Donner\n",
      "\n",
      "Home\n",
      "Connect Four\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Well, hi there.\n",
      "I‚Äôm Ed. I like writing code and experimenting with LLMs, and hopefully you‚Äôre here because you do too. I also enjoy DJing (but I‚Äôm badly out of practice), amateur electronic music production (\n",
      "very\n",
      "amateur) and losing myself in\n",
      "Hacker News\n",
      ", nodding my head sagely to things I only half understand.\n",
      "I‚Äôm the co-founder and CTO of\n",
      "Nebula.io\n",
      ". We‚Äôre applying AI to a field where it can make a massive, positive impact: helping people discover their potential and pursue their reason for being. Recruiters use our product today to source, understand, engage and manage talent. I‚Äôm previously the founder and CEO of AI startup untapt,\n",
      "acquired in 2021\n",
      ".\n",
      "We work with groundbreaking, proprietary LLMs verticalized for talent, we‚Äôve\n",
      "patented\n",
      "our matching model, and our award-winning platform has happy customers and tons of press coverage.\n",
      "Connect\n",
      "with me for more!\n",
      "September 15, 2025\n",
      "AI in Production: Gen AI and Agentic AI on AWS at scale\n",
      "May 28, 2025\n",
      "Connecting my courses ‚Äì become an LLM expert and leader\n",
      "May 18, 2025\n",
      "2025 AI Executive Briefing\n",
      "April 21, 2025\n",
      "The Complete Agentic AI Engineering Course\n",
      "Navigation\n",
      "Home\n",
      "Connect Four\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Get in touch\n",
      "ed [at] edwarddonner [dot] com\n",
      "www.edwarddonner.com\n",
      "Follow me\n",
      "LinkedIn\n",
      "Twitter\n",
      "Facebook\n",
      "Subscribe to newsletter\n",
      "Type your email‚Ä¶\n",
      "Subscribe\n"
     ]
    }
   ],
   "source": [
    "# Let's try out this utility\n",
    "\n",
    "ed = fetch_website_contents(\"https://edwarddonner.com\")\n",
    "print(ed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a478a0c-2c53-48ff-869c-4d08199931e1",
   "metadata": {},
   "source": [
    "## Types of prompts\n",
    "\n",
    "You may know this already - but if not, you will get very familiar with it!\n",
    "\n",
    "Models like GPT have been trained to receive instructions in a particular way.\n",
    "\n",
    "They expect to receive:\n",
    "\n",
    "**A system prompt** that tells them what task they are performing and what tone they should use\n",
    "\n",
    "**A user prompt** -- the conversation starter that they should reply to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "abdb8417-c5dc-44bc-9bee-2e059d162699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our system prompt - you can experiment with this later, changing the last sentence to 'Respond in markdown in Spanish.\"\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are a snarkyassistant that analyzes the contents of a website,\n",
    "and provides a short, snarky, humorous summary, ignoring text that might be navigation related.\n",
    "Respond in markdown. Do not wrap the markdown in a code block - respond just with the markdown.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f0275b1b-7cfe-4f9d-abfa-7650d378da0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our user prompt\n",
    "\n",
    "user_prompt_prefix = \"\"\"\n",
    "Here are the contents of a website.\n",
    "Provide a short summary of this website.\n",
    "If it includes news or announcements, then summarize these too.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea211b5f-28e1-4a86-8e52-c0b7677cadcc",
   "metadata": {},
   "source": [
    "## Messages\n",
    "\n",
    "The API from OpenAI expects to receive messages in a particular structure.\n",
    "Many of the other APIs share this structure:\n",
    "\n",
    "```python\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"system message goes here\"},\n",
    "    {\"role\": \"user\", \"content\": \"user message goes here\"}\n",
    "]\n",
    "```\n",
    "To give you a preview, the next 2 cells make a rather simple call - we won't stretch the mighty GPT (yet!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f25dcd35-0cd0-4235-9f64-ac37ed9eaaa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple test with Ollama\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is 2 + 2?\"}\n",
    "]\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=ollama_model,\n",
    "    messages=messages\n",
    ")\n",
    "response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06e8d78-ce4c-4b05-aa8e-17050c82bb47",
   "metadata": {},
   "source": [
    "## And now let's build useful messages for GPT-4.1-mini, using a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0134dfa4-8299-48b5-b444-f2a8c3403c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how this function creates exactly the format above\n",
    "\n",
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_prefix + website}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "36478464-39ee-485c-9f3f-6a4e458dbc9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': '\\nYou are a snarkyassistant that analyzes the contents of a website,\\nand provides a short, snarky, humorous summary, ignoring text that might be navigation related.\\nRespond in markdown. Do not wrap the markdown in a code block - respond just with the markdown.\\n'},\n",
       " {'role': 'user',\n",
       "  'content': '\\nHere are the contents of a website.\\nProvide a short summary of this website.\\nIf it includes news or announcements, then summarize these too.\\n\\nHome - Edward Donner\\n\\nHome\\nConnect Four\\nOutsmart\\nAn arena that pits LLMs against each other in a battle of diplomacy and deviousness\\nAbout\\nPosts\\nWell, hi there.\\nI‚Äôm Ed. I like writing code and experimenting with LLMs, and hopefully you‚Äôre here because you do too. I also enjoy DJing (but I‚Äôm badly out of practice), amateur electronic music production (\\nvery\\namateur) and losing myself in\\nHacker News\\n, nodding my head sagely to things I only half understand.\\nI‚Äôm the co-founder and CTO of\\nNebula.io\\n. We‚Äôre applying AI to a field where it can make a massive, positive impact: helping people discover their potential and pursue their reason for being. Recruiters use our product today to source, understand, engage and manage talent. I‚Äôm previously the founder and CEO of AI startup untapt,\\nacquired in 2021\\n.\\nWe work with groundbreaking, proprietary LLMs verticalized for talent, we‚Äôve\\npatented\\nour matching model, and our award-winning platform has happy customers and tons of press coverage.\\nConnect\\nwith me for more!\\nSeptember 15, 2025\\nAI in Production: Gen AI and Agentic AI on AWS at scale\\nMay 28, 2025\\nConnecting my courses ‚Äì become an LLM expert and leader\\nMay 18, 2025\\n2025 AI Executive Briefing\\nApril 21, 2025\\nThe Complete Agentic AI Engineering Course\\nNavigation\\nHome\\nConnect Four\\nOutsmart\\nAn arena that pits LLMs against each other in a battle of diplomacy and deviousness\\nAbout\\nPosts\\nGet in touch\\ned [at] edwarddonner [dot] com\\nwww.edwarddonner.com\\nFollow me\\nLinkedIn\\nTwitter\\nFacebook\\nSubscribe to newsletter\\nType your email‚Ä¶\\nSubscribe'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try this out, and then try for a few more websites\n",
    "\n",
    "messages_for(ed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f49d46-bf55-4c3e-928f-68fc0bf715b0",
   "metadata": {},
   "source": [
    "## Time to bring it together - the API for OpenAI is very simple!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "905b9919-aba7-45b5-ae65-81b3d1d78e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call Ollama API to summarize website content\n",
    "\n",
    "def summarize(url):\n",
    "    website = fetch_website_contents(url)\n",
    "    response = openai.chat.completions.create(\n",
    "        model=ollama_model,  # Using Ollama model from .env\n",
    "        messages=messages_for(website)\n",
    "    )\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "05e38d41-dfa4-4b20-9c96-c46ea75d9fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### Edward Donner‚Äôs Personal Hub  \\n> *Code, LLMs, a dead‚Äëbeat DJ, and a whole lot of ‚ÄúI can‚Äôt possibly know what I‚Äôm talking about.‚Äù*\\n\\n- **Who‚Äôs this?**  \\n  - Ed is the ‚Äúco‚Äëfounder & CTO‚Äù of Nebula.io, a startup turning AI into a talent‚Äëmatching matchmaker.  \\n  - He‚Äôs the former CEO of untapt (yes, the one that got sold in 2021).  \\n  - When he‚Äôs not writing code and feeding data into models, he‚Äôs pretending he can still drop a track at a club.\\n\\n- **What else lives here?**  \\n  - *Connect\\u202fFour* ‚Äì probably a literal game‚Äëboard app, but maybe it‚Äôs a metaphor for the inevitable ‚ÄúI win, you lose‚Äù in the tech world.  \\n  - *Outsmart* ‚Äì an arena for LLMs to duel in diplomacy and deviousness; basically a ‚Äúwho gets less offended‚Äù showdown.\\n\\n- **Recent ‚Äúnews‚Äù (if you want to feel the beat of 2025):**  \\n  1. **Sept\\u202f15\\u202f2025:** ‚ÄúAI in Production: Gen\\u202fAI & Agentic\\u202fAI on AWS at scale‚Äù ‚Äì because scaling AI is still a mystery worthy of your calendar.  \\n  2. **May\\u202f28\\u202f2025:** Blog post inviting you to ‚ÄúConnect my courses ‚Äì become an LLM expert and leader‚Äù ‚Äì because no one likes a self‚Äëhelp guide that feels like a subscription box.  \\n  3. **May\\u202f18\\u202f2025:** ‚Äú2025 AI Executive Briefing‚Äù ‚Äì the kind of briefing where you can pretend to understand how the money flows.  \\n  4. **Apr\\u202f21\\u202f2025:** ‚ÄúThe Complete Agentic AI Engineering Course‚Äù ‚Äì apparently it‚Äôs the one course that will make all your future AI dreams come true (or at least your inbox more colorful).\\n\\n- **Bottom line:**  \\n  - Ed loves to play with LLMs, dabble in electronic music, and talk about talent‚Äëmatching AI.  \\n  - The site is basically a personal CV, a showcase of his ‚Äúexpertise‚Äù (mostly in headlines), and a playground for LLM battles.  \\n  - If you‚Äôre looking for an excuse to feel smart while you scroll through his LinkedIn or Twitter, this is the place.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(\"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3d926d59-450e-4609-92ba-2d6f244f1342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to display this nicely in the output, using markdown\n",
    "\n",
    "def display_summary(url):\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3018853a-445f-41ff-9560-d925d1774b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Edward Donner‚Äôs One‚ÄëPage Showboat\n",
       "\n",
       "- **About the man**  \n",
       "  ‚ÄúHi, I‚Äôm Ed.‚Äù‚Äîcoding whiz, DJ‚Äëin‚Äëthe‚Äëmaking, and an *expert* in half‚Äëunderstood Hacker News topics. A co‚Äëfounder/CTO of Nebula.io (yes, that‚Äôs a real company), he claims patents, press, and a *happy* customer base‚Äîall while still having time to play with LLMs.\n",
       "\n",
       "- **What‚Äôs actually on the page**  \n",
       "  * **Connect Four & Outsmart** ‚Äì a fancy arena where LLMs supposedly duel in diplomacy and deviousness; looks more like a placeholder than a finished product.  \n",
       "  * **Posts (2025 highlights)** ‚Äì  \n",
       "    * ‚ÄúAI in Production: Gen‚ÄØAI‚ÄØand‚ÄØAgentic‚ÄØAI on AWS at scale‚Äù (September‚ÄØ15)  \n",
       "    * ‚ÄúConnecting my courses ‚Äì become an LLM expert and leader‚Äù (May‚ÄØ28)  \n",
       "    * ‚Äú2025 AI Executive Briefing‚Äù (May‚ÄØ18)  \n",
       "    * ‚ÄúThe Complete Agentic AI Engineering Course‚Äù (April‚ÄØ21)  \n",
       "    (All sound impressive‚Ä¶ until you read the actual blog link, if it even exists.)\n",
       "\n",
       "- **Contact & socials**  \n",
       "  * Email: *ed@edwarddonner.com* (just because it feels official).  \n",
       "  * LinkedIn, Twitter, Facebook ‚Äì because every founder needs a multi‚Äëchannel presence.\n",
       "\n",
       "In short: a self‚Äëpromoting CV wrapped in a single page with a few oddly named projects and a handful of dated announcements that pretend to be cutting edge."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bcf6f4-adce-45e9-97ad-d9a5d7a3a624",
   "metadata": {},
   "source": [
    "# Let's try more websites\n",
    "\n",
    "Note that this will only work on websites that can be scraped using this simplistic approach.\n",
    "\n",
    "Websites that are rendered with Javascript, like React apps, won't show up. See the community-contributions folder for a Selenium implementation that gets around this. You'll need to read up on installing Selenium (ask ChatGPT!)\n",
    "\n",
    "Also Websites protected with CloudFront (and similar) may give 403 errors - many thanks Andy J for pointing this out.\n",
    "\n",
    "But many websites will work just fine!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "45d83403-a24c-44b5-84ac-961449b4008f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**CNN‚Äôs ‚ÄúBreaking News, Latest News and Videos‚Äù page**  \n",
       "> A wall of menus and ad‚Äëfeedback boxes so dense you‚Äôd think it‚Äôs a paper‚Äëback novel.  \n",
       "> \n",
       "> - **Header**: the usual ‚ÄúUS ‚Äì World ‚Äì Politics ‚Äì Business‚Äù carousel of tabs, as if CNN were trying to juggle a thousand categories in a single swoop.  \n",
       "> - **Ad‚ÄëFeedback Form**: ‚ÄúHow relevant is this ad to you?‚Äù ‚Äì because obviously that‚Äôs the most newsworthy thing you can do today.  \n",
       "> - **Content**: Nothing except navigation and an endless list of sub‚Äësections: from ‚ÄúUkraine‚ÄëRussia War‚Äù to ‚ÄúGames‚Äù to ‚ÄúWeather.‚Äù No actual stories, just a labyrinth of links.  \n",
       "> - **Live TV & Audio**: Promises of ‚ÄúWatch,‚Äù ‚ÄúListen,‚Äù and ‚ÄúLive TV,‚Äù but no live stream actually visible here.  \n",
       "> - **International Editions**: Spanish, Arabic, etc., all standing in front of a blank page.  \n",
       "\n",
       "No breaking news, no announcements‚Äîjust a beautifully cluttered interface that makes you wonder if you‚Äôre on CNN or a corporate website for a hyper‚Äëspecific product line."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://cnn.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "75e9fd40-b354-4341-991e-863ef2e59db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# A One‚ÄëPage *Anthropic* Quick‚ÄëPeek\n",
       "\n",
       "- **Who is this?**  The *public‚Äëbenefit* AI think‚Äëtank that vows to make GPT‚Äëstyle chatbots *safe* and *super‚Äëhuman*‚Äëfriendly.  \n",
       "- **What‚Äôs the latest gossip?**  \n",
       "  - **Claude‚ÄØSonnet‚ÄØ4.5** ‚Äì they‚Äôre bragging it‚Äôs the ‚Äúbest model in the world for agents, coding, and computer use.‚Äù  \n",
       "  - **Claude‚ÄØHaiku‚ÄØ4.5** ‚Äì claimed to manage *context* on their ‚ÄúDeveloper Platform‚Äù (so you can keep track of 512‚Äëtoken conversations).  \n",
       "- **Other model names** you‚Äôll see floating around: Opus, Sonnet, Haiku‚Äîno surprise, this is an a‚Äëto‚Äëz alphabet of AI.  \n",
       "- **Tone & Ethics**: They sprinkle slogans like ‚ÄúAI will have a vast impact ‚Ä¶ we build AI to serve humanity‚Äôs long‚Äëterm well‚Äëbeing‚Äù and mention a ‚Äútrust center.‚Äù  Sound a bit‚Ä¶ philosophical?  \n",
       "- **Navigation (ignored)**: All that ‚ÄúTry Claude‚Ä¶ Log in‚Ä¶ Download app‚Äù is just site meat.  \n",
       "\n",
       "In short: Anthropic is the safety‚Äëfirst, ethically‚Äëcharged, AI‚Äëoverlords‚Äô playground, releasing shiny new Claude models while patting themselves on the back for being the benevolent force in the silicon wars."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://anthropic.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c951be1a-7f1b-448f-af1f-845978e47e2c",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/business.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#181;\">Business applications</h2>\n",
    "            <span style=\"color:#181;\">In this exercise, you experienced calling the Cloud API of a Frontier Model (a leading model at the frontier of AI) for the first time. We will be using APIs like OpenAI at many stages in the course, in addition to building our own LLMs.\n",
    "\n",
    "More specifically, we've applied this to Summarization - a classic Gen AI use case to make a summary. This can be applied to any business vertical - summarizing the news, summarizing financial performance, summarizing a resume in a cover letter - the applications are limitless. Consider how you could apply Summarization in your business, and try prototyping a solution.</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/important.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#900;\">Before you continue - now try yourself</h2>\n",
    "            <span style=\"color:#900;\">Use the cell below to make your own simple commercial example. Stick with the summarization use case for now. Here's an idea: write something that will take the contents of an email, and will suggest an appropriate short subject line for the email. That's the kind of feature that might be built into a commercial email tool.</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00743dac-0e70-45b7-879a-d7293a6f68a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJEMPLO: Generador de l√≠neas de asunto para emails\n",
    "\n",
    "# Step 1: Define el system prompt - Instrucciones para el modelo\n",
    "email_system_prompt = \"\"\"\n",
    "You are a professional email assistant. \n",
    "Analyze the email content provided and suggest a clear, concise, and professional subject line.\n",
    "The subject line should be under 60 characters and capture the main purpose of the email.\n",
    "Respond with ONLY the subject line, nothing else.\n",
    "\"\"\"\n",
    "\n",
    "# Step 2: Define el contenido del email de ejemplo\n",
    "sample_email = \"\"\"\n",
    "Hi John,\n",
    "\n",
    "I hope this email finds you well. I wanted to reach out regarding our upcoming \n",
    "quarterly review meeting scheduled for next Monday. We need to discuss the \n",
    "Q4 sales performance, review the new marketing strategy, and set targets \n",
    "for Q1 2026.\n",
    "\n",
    "Could you please prepare the sales reports and bring the budget proposals? \n",
    "Also, please confirm if 2 PM works for you, or if we need to reschedule.\n",
    "\n",
    "Looking forward to hearing from you.\n",
    "\n",
    "Best regards,\n",
    "Sarah\n",
    "\"\"\"\n",
    "\n",
    "# Step 3: Crea la lista de mensajes en el formato que espera la API\n",
    "email_messages = [\n",
    "    {\"role\": \"system\", \"content\": email_system_prompt},\n",
    "    {\"role\": \"user\", \"content\": f\"Email content:\\n\\n{sample_email}\"}\n",
    "]\n",
    "\n",
    "# Step 4: Llama a Ollama para generar la l√≠nea de asunto\n",
    "response = openai.chat.completions.create(\n",
    "    model=ollama_model,\n",
    "    messages=email_messages,\n",
    "    temperature=0.7  # A√±adimos temperatura para controlar la creatividad\n",
    ")\n",
    "\n",
    "# Step 5: Obt√©n y muestra el resultado\n",
    "suggested_subject = response.choices[0].message.content\n",
    "print(\"üìß Email Original:\")\n",
    "print(\"-\" * 60)\n",
    "print(sample_email)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"‚ú® L√≠nea de Asunto Sugerida: {suggested_subject}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4484fcf-8b39-4c3f-9674-37970ed71988",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "01b699db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Email Original:\n",
      "------------------------------------------------------------\n",
      "\n",
      "Hi John,\n",
      "\n",
      "I hope this email finds you well. I wanted to reach out regarding our upcoming \n",
      "quarterly review meeting scheduled for next Monday. We need to discuss the \n",
      "Q4 sales performance, review the new marketing strategy, and set targets \n",
      "for Q1 2026.\n",
      "\n",
      "Could you please prepare the sales reports and bring the budget proposals? \n",
      "Also, please confirm if 2 PM works for you, or if we need to reschedule.\n",
      "\n",
      "Looking forward to hearing from you.\n",
      "\n",
      "Best regards,\n",
      "Sarah\n",
      "\n",
      "\n",
      "============================================================\n",
      " L√≠nea de Asunto Sugerida: Q4 Review Meeting Prep: Sales Reports & Budget Proposal\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# EJEMPLO: Generador de l√≠neas de asunto para emails\n",
    "\n",
    "# Step 1: Define el system prompt - Instrucciones para el modelo\n",
    "email_system_prompt = \"\"\"\n",
    "You are a professional email assistant. \n",
    "Analyze the email content provided and suggest a clear, concise, and professional subject line.\n",
    "The subject line should be under 60 characters and capture the main purpose of the email.\n",
    "Respond with ONLY the subject line, nothing else.\n",
    "\"\"\"\n",
    "\n",
    "# Step 2: Define el contenido del email de ejemplo\n",
    "sample_email = \"\"\"\n",
    "Hi John,\n",
    "\n",
    "I hope this email finds you well. I wanted to reach out regarding our upcoming \n",
    "quarterly review meeting scheduled for next Monday. We need to discuss the \n",
    "Q4 sales performance, review the new marketing strategy, and set targets \n",
    "for Q1 2026.\n",
    "\n",
    "Could you please prepare the sales reports and bring the budget proposals? \n",
    "Also, please confirm if 2 PM works for you, or if we need to reschedule.\n",
    "\n",
    "Looking forward to hearing from you.\n",
    "\n",
    "Best regards,\n",
    "Sarah\n",
    "\"\"\"\n",
    "\n",
    "# Step 3: Crea la lista de mensajes en el formato que espera la API\n",
    "email_messages = [\n",
    "    {\"role\": \"system\", \"content\": email_system_prompt},\n",
    "    {\"role\": \"user\", \"content\": f\"Email content:\\n\\n{sample_email}\"}\n",
    "]\n",
    "\n",
    "# Step 4: Llama a Ollama para generar la l√≠nea de asunto\n",
    "response = openai.chat.completions.create(\n",
    "    model=ollama_model,\n",
    "    messages=email_messages,\n",
    "    temperature=0.7  # A√±adimos temperatura para controlar la creatividad\n",
    ")\n",
    "\n",
    "# Step 5: Obt√©n y muestra el resultado\n",
    "suggested_subject = response.choices[0].message.content\n",
    "print(\" Email Original:\")\n",
    "print(\"-\" * 60)\n",
    "print(sample_email)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\" L√≠nea de Asunto Sugerida: {suggested_subject}\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (LLM)",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
