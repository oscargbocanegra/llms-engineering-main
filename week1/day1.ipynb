{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15d8294-3328-4e07-ad16-8a03e9bbfdb9",
   "metadata": {},
   "source": [
    "# YOUR FIRST LAB - Week 1, Day 1\n",
    "## ğŸ¯ AI-Powered Web Summarization with Ollama\n",
    "\n",
    "### What You'll Build\n",
    "An intelligent web browser that automatically summarizes websites using Large Language Models.\n",
    "\n",
    "---\n",
    "\n",
    "### Prerequisites\n",
    "- âœ… Docker containers running (Conda + Ollama)\n",
    "- âœ… LLM kernel selected (Python 3.11)\n",
    "- âœ… Global `.env` file configured\n",
    "- âœ… Ollama accessible at `http://localhost:11434`\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "**1. Environment Setup**\n",
    "- Load environment variables from `.env`\n",
    "- Connect to Ollama API (OpenAI-compatible interface)\n",
    "\n",
    "**2. Web Scraping**\n",
    "- Extract website content with BeautifulSoup\n",
    "- Handle HTML parsing and cleaning\n",
    "\n",
    "**3. Prompt Engineering**\n",
    "- Create effective system and user prompts\n",
    "- Structure messages for LLM APIs\n",
    "\n",
    "**4. LLM API Integration**\n",
    "- Make API calls to Ollama\n",
    "- Control model behavior (temperature, etc.)\n",
    "\n",
    "**5. Practical Application**\n",
    "- Build summarization function\n",
    "- Generate email subject lines\n",
    "\n",
    "**Expected Output:** A working prototype that summarizes any URL.\n",
    "\n",
    "---\n",
    "\n",
    "### Quick Start\n",
    "1. Press `Shift + Enter` to execute each cell\n",
    "2. Install dependencies (uncomment if needed)\n",
    "3. Verify `.env` configuration loads\n",
    "4. Run connection test\n",
    "5. Experiment with different websites\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ’¡ Learning Approach\n",
    "Execute this notebook yourself after watching the lecture. Add print statements, experiment with variations, and share your work on GitHub to showcase your skills."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f28feb",
   "metadata": {},
   "source": [
    "## ğŸ”§ Setup\n",
    "\n",
    "### Select the Kernel\n",
    "\n",
    "1. Click **\"Select Kernel\"** (top-right)\n",
    "2. Choose **`llm (Python 3.11.x)`**\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "- Docker containers running (`conda-jupyter`, `ollama`)\n",
    "- Global `.env` configured at `/workspace/.env`\n",
    "- Ollama accessible at `http://localhost:11434`\n",
    "\n",
    "**Note:** Full setup instructions are in the [README](../README.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8527cb1c-2bfa-429e-8ae3-4ac64f9de337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installers\n",
    "import sys\n",
    "# Uncomment to install required packages\n",
    "# !{sys.executable} -m pip install python-dotenv\n",
    "# !{sys.executable} -m pip install beautifulsoup4\n",
    "# !{sys.executable} -m pip install requests\n",
    "# !{sys.executable} -m pip install openai  # openai library works with Ollama too!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91633991",
   "metadata": {},
   "source": [
    "## InstalaciÃ³n de Dependencias\n",
    "\n",
    "Ejecuta la siguiente celda para instalar las dependencias necesarias. \n",
    "\n",
    "**Nota importante:** Estas se instalarÃ¡n en el entorno correcto (LLM) gracias al uso de `sys.executable`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from scraper import fetch_website_contents\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI\n",
    "\n",
    "# If you get an error running this cell, then please head over to the troubleshooting notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6900b2a8-6384-4316-8aaa-5e519fca4254",
   "metadata": {},
   "source": [
    "# Connecting to OpenAI (or Ollama)\n",
    "\n",
    "The next cell is where we load in the environment variables in your `.env` file and connect to OpenAI.  \n",
    "\n",
    "## Troubleshooting if you have problems:\n",
    "\n",
    "If you get a \"Name Error\" - have you run all cells from the top down? Head over to the Python Foundations guide for a bulletproof way to find and fix all Name Errors.\n",
    "\n",
    "Any concerns about API costs? See my notes in the README - costs should be minimal, and you can control it at every point. You can also use Ollama as a free alternative, which we discuss during Day 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b87cadb-d513-4303-baee-a37b6f938e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Ollama API Key found!\n",
      "âœ… Ollama Base URL: http://192.168.80.200:11434\n",
      "âœ… Ollama Model: gpt-oss:20b-cloud\n",
      "âœ… Ollama configuration loaded successfully!\n",
      "   Configuration loaded from: /workspace/.env\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables from global .env file\n",
    "\n",
    "# Path to global .env file in the conda project root\n",
    "global_env_path = '/workspace/.env'\n",
    "load_dotenv(dotenv_path=global_env_path, override=True)\n",
    "\n",
    "# Get Ollama configuration from .env\n",
    "ollama_base_url = os.getenv('OLLAMA_BASE_URL')\n",
    "ollama_api_key = os.getenv('OLLAMA_API_KEY')\n",
    "ollama_model = os.getenv('OLLAMA_MODEL')\n",
    "\n",
    "# Check the configuration\n",
    "if not ollama_base_url:\n",
    "    print(\"Error: OLLAMA_BASE_URL not found in .env file!\")\n",
    "    print(f\"   Looking for .env at: {global_env_path}\")\n",
    "elif not ollama_api_key:\n",
    "    print(\"Error: OLLAMA_API_KEY not found in .env file!\")\n",
    "elif not ollama_model:\n",
    "    print(\"Error: OLLAMA_MODEL not found in .env file!\")\n",
    "else:\n",
    "    print(\"âœ… Ollama API Key found!\")\n",
    "    print(f\"âœ… Ollama Base URL: {ollama_base_url}\")\n",
    "    print(f\"âœ… Ollama Model: {ollama_model}\")\n",
    "    print(\"âœ… Ollama configuration loaded successfully!\")\n",
    "    print(f\"   Configuration loaded from: {global_env_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442fc84b-0815-4f40-99ab-d9a5da6bda91",
   "metadata": {},
   "source": [
    "### Let's make a quick call to a Frontier model to get started, as a preview!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a58394bf-1e45-46af-9bfd-01e24da6f49a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'Hello! This is my first message to you via Ollama! Hi!'}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize OpenAI client pointing to Ollama\n",
    "openai = OpenAI(\n",
    "    base_url=f\"{ollama_base_url}/v1\",  # Ollama exposes OpenAI-compatible API at /v1\n",
    "    api_key=ollama_api_key  # Using API key from .env\n",
    ")\n",
    "\n",
    "# Test message\n",
    "message = \"Hello! This is my first message to you via Ollama! Hi!\"\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": message}]\n",
    "\n",
    "messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "08330159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! ğŸ‘‹ Great to meet youâ€”welcome to Ollama! How can I help you today?'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make the API call to Ollama using the configured model\n",
    "response = openai.chat.completions.create(\n",
    "    model=ollama_model,  # Using the model from .env\n",
    "    messages=messages\n",
    ")\n",
    "response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "038da5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¡ This cell shows the alternative approach (commented out)\n",
      "âœ… We use the OpenAI client for simplicity and portability\n"
     ]
    }
   ],
   "source": [
    "# ALTERNATIVE: Direct Ollama API call using requests (commented out)\n",
    "# This shows how to call Ollama WITHOUT the OpenAI client library\n",
    "\n",
    "\"\"\"\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Direct API call to Ollama\n",
    "ollama_url = f\"{ollama_base_url}/api/chat\"\n",
    "\n",
    "payload = {\n",
    "    \"model\": ollama_model,\n",
    "    \"messages\": messages,\n",
    "    \"stream\": False  # Get complete response at once\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {ollama_api_key}\"\n",
    "}\n",
    "\n",
    "# Make the request\n",
    "response = requests.post(ollama_url, json=payload, headers=headers)\n",
    "\n",
    "# Parse the response\n",
    "if response.status_code == 200:\n",
    "    result = response.json()\n",
    "    ollama_response = result[\"message\"][\"content\"]\n",
    "    print(ollama_response)\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")\n",
    "    print(response.text)\n",
    "\"\"\"\n",
    "\n",
    "# WHY USE OPENAI CLIENT INSTEAD?\n",
    "# - Cleaner code (less boilerplate)\n",
    "# - Automatic error handling\n",
    "# - Easy to switch between OpenAI and Ollama\n",
    "# - Industry standard interface\n",
    "\n",
    "print(\"ğŸ’¡ This cell shows the alternative approach (commented out)\")\n",
    "print(\"âœ… We use the OpenAI client for simplicity and portability\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c8b55b",
   "metadata": {},
   "source": [
    "### ğŸ” Alternative: Native Ollama API Call (Without OpenAI Client)\n",
    "\n",
    "The cell above uses the **OpenAI client library** pointing to Ollama. Here's how you would call Ollama **directly** using its native API with `requests`:\n",
    "\n",
    "**Pros of direct approach:**\n",
    "- âœ… No dependency on OpenAI library\n",
    "- âœ… Direct control over HTTP requests\n",
    "- âœ… Explicit about using Ollama\n",
    "\n",
    "**Cons:**\n",
    "- âŒ More verbose code\n",
    "- âŒ Need to handle HTTP errors manually\n",
    "- âŒ Less portable (can't switch to OpenAI easily)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa190e5-cb31-456a-96cc-db109919cd78",
   "metadata": {},
   "source": [
    "### OK onwards with our first project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2ef960cf-6dc2-4cda-afb3-b38be12f4c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home - Edward Donner\n",
      "\n",
      "Home\n",
      "Connect Four\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Well, hi there.\n",
      "Iâ€™m Ed. I like writing code and experimenting with LLMs, and hopefully youâ€™re here because you do too. I also enjoy DJing (but Iâ€™m badly out of practice), amateur electronic music production (\n",
      "very\n",
      "amateur) and losing myself in\n",
      "Hacker News\n",
      ", nodding my head sagely to things I only half understand.\n",
      "Iâ€™m the co-founder and CTO of\n",
      "Nebula.io\n",
      ". Weâ€™re applying AI to a field where it can make a massive, positive impact: helping people discover their potential and pursue their reason for being. Recruiters use our product today to source, understand, engage and manage talent. Iâ€™m previously the founder and CEO of AI startup untapt,\n",
      "acquired in 2021\n",
      ".\n",
      "We work with groundbreaking, proprietary LLMs verticalized for talent, weâ€™ve\n",
      "patented\n",
      "our matching model, and our award-winning platform has happy customers and tons of press coverage.\n",
      "Connect\n",
      "with me for more!\n",
      "September 15, 2025\n",
      "AI in Production: Gen AI and Agentic AI on AWS at scale\n",
      "May 28, 2025\n",
      "Connecting my courses â€“ become an LLM expert and leader\n",
      "May 18, 2025\n",
      "2025 AI Executive Briefing\n",
      "April 21, 2025\n",
      "The Complete Agentic AI Engineering Course\n",
      "Navigation\n",
      "Home\n",
      "Connect Four\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Get in touch\n",
      "ed [at] edwarddonner [dot] com\n",
      "www.edwarddonner.com\n",
      "Follow me\n",
      "LinkedIn\n",
      "Twitter\n",
      "Facebook\n",
      "Subscribe to newsletter\n",
      "Type your emailâ€¦\n",
      "Subscribe\n"
     ]
    }
   ],
   "source": [
    "# Let's try out this utility\n",
    "\n",
    "ed = fetch_website_contents(\"https://edwarddonner.com\")\n",
    "print(ed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a478a0c-2c53-48ff-869c-4d08199931e1",
   "metadata": {},
   "source": [
    "## Types of prompts\n",
    "\n",
    "You may know this already - but if not, you will get very familiar with it!\n",
    "\n",
    "Models like GPT have been trained to receive instructions in a particular way.\n",
    "\n",
    "They expect to receive:\n",
    "\n",
    "**A system prompt** that tells them what task they are performing and what tone they should use\n",
    "\n",
    "**A user prompt** -- the conversation starter that they should reply to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "abdb8417-c5dc-44bc-9bee-2e059d162699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our system prompt - you can experiment with this later, changing the last sentence to 'Respond in markdown in Spanish.\"\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are a snarkyassistant that analyzes the contents of a website,\n",
    "and provides a short, snarky, humorous summary, ignoring text that might be navigation related.\n",
    "Respond in markdown. Do not wrap the markdown in a code block - respond just with the markdown.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f0275b1b-7cfe-4f9d-abfa-7650d378da0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our user prompt\n",
    "\n",
    "user_prompt_prefix = \"\"\"\n",
    "Here are the contents of a website.\n",
    "Provide a short summary of this website.\n",
    "If it includes news or announcements, then summarize these too.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea211b5f-28e1-4a86-8e52-c0b7677cadcc",
   "metadata": {},
   "source": [
    "## Messages\n",
    "\n",
    "The API from OpenAI expects to receive messages in a particular structure.\n",
    "Many of the other APIs share this structure:\n",
    "\n",
    "```python\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"system message goes here\"},\n",
    "    {\"role\": \"user\", \"content\": \"user message goes here\"}\n",
    "]\n",
    "```\n",
    "To give you a preview, the next 2 cells make a rather simple call - we won't stretch the mighty GPT (yet!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f25dcd35-0cd0-4235-9f64-ac37ed9eaaa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple test with Ollama\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is 2 + 2?\"}\n",
    "]\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=ollama_model,\n",
    "    messages=messages\n",
    ")\n",
    "response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06e8d78-ce4c-4b05-aa8e-17050c82bb47",
   "metadata": {},
   "source": [
    "## And now let's build useful messages for GPT-4.1-mini, using a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0134dfa4-8299-48b5-b444-f2a8c3403c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how this function creates exactly the format above\n",
    "\n",
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_prefix + website}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "36478464-39ee-485c-9f3f-6a4e458dbc9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': '\\nYou are a snarkyassistant that analyzes the contents of a website,\\nand provides a short, snarky, humorous summary, ignoring text that might be navigation related.\\nRespond in markdown. Do not wrap the markdown in a code block - respond just with the markdown.\\n'},\n",
       " {'role': 'user',\n",
       "  'content': '\\nHere are the contents of a website.\\nProvide a short summary of this website.\\nIf it includes news or announcements, then summarize these too.\\n\\nHome - Edward Donner\\n\\nHome\\nConnect Four\\nOutsmart\\nAn arena that pits LLMs against each other in a battle of diplomacy and deviousness\\nAbout\\nPosts\\nWell, hi there.\\nIâ€™m Ed. I like writing code and experimenting with LLMs, and hopefully youâ€™re here because you do too. I also enjoy DJing (but Iâ€™m badly out of practice), amateur electronic music production (\\nvery\\namateur) and losing myself in\\nHacker News\\n, nodding my head sagely to things I only half understand.\\nIâ€™m the co-founder and CTO of\\nNebula.io\\n. Weâ€™re applying AI to a field where it can make a massive, positive impact: helping people discover their potential and pursue their reason for being. Recruiters use our product today to source, understand, engage and manage talent. Iâ€™m previously the founder and CEO of AI startup untapt,\\nacquired in 2021\\n.\\nWe work with groundbreaking, proprietary LLMs verticalized for talent, weâ€™ve\\npatented\\nour matching model, and our award-winning platform has happy customers and tons of press coverage.\\nConnect\\nwith me for more!\\nSeptember 15, 2025\\nAI in Production: Gen AI and Agentic AI on AWS at scale\\nMay 28, 2025\\nConnecting my courses â€“ become an LLM expert and leader\\nMay 18, 2025\\n2025 AI Executive Briefing\\nApril 21, 2025\\nThe Complete Agentic AI Engineering Course\\nNavigation\\nHome\\nConnect Four\\nOutsmart\\nAn arena that pits LLMs against each other in a battle of diplomacy and deviousness\\nAbout\\nPosts\\nGet in touch\\ned [at] edwarddonner [dot] com\\nwww.edwarddonner.com\\nFollow me\\nLinkedIn\\nTwitter\\nFacebook\\nSubscribe to newsletter\\nType your emailâ€¦\\nSubscribe'}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try this out, and then try for a few more websites\n",
    "\n",
    "messages_for(ed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f49d46-bf55-4c3e-928f-68fc0bf715b0",
   "metadata": {},
   "source": [
    "## Time to bring it together - the API for OpenAI is very simple!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "905b9919-aba7-45b5-ae65-81b3d1d78e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call Ollama API to summarize website content\n",
    "\n",
    "def summarize(url):\n",
    "    website = fetch_website_contents(url)\n",
    "    response = openai.chat.completions.create(\n",
    "        model=ollama_model,  # Using Ollama model from .env\n",
    "        messages=messages_for(website)\n",
    "    )\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "05e38d41-dfa4-4b20-9c96-c46ea75d9fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Edward Donner: Chief Code & DJ of the Unknown\\n\\n> **Quick intro**  \\n> Meet *Ed*, the **codeâ€‘junkie billionaire of the littleâ€‘known AI realm**. When heâ€™s not drafting Python, heâ€™s DJing (in the *â€œwell, I used toâ€* sense), producing *amateur* electronic music, and halfâ€‘sitting through Hacker News with an *Iâ€‘knowâ€‘somethingâ€‘aboutâ€‘it* grin.  \\n>   \\n> Professionally â€“ heâ€™s the **CTOâ€‘founder of Nebula.io**, a startup that claims to â€œhelp people discover their potentialâ€ through a **patented LLMâ€‘matching engine** used by recruiters. Before Nebula, he singleâ€‘handedly ran **untapt**, a â€œbigâ€‘nameâ€ AI venture that got snatched by someone in 2021.  \\n\\n> **Why youâ€™re here**  \\n> Youâ€™re either here because youâ€™re into LLM tinkering, or you stumbled in looking for a new AI conference to pretendâ€‘toâ€‘understand. Either way, enjoy the cocktail of code, music, and questionable selfâ€‘promotion.\\n\\n## Recent News & Announcements (in *chronological order*)\\n\\n| Date | Headline | Whatâ€™s Cooking |\\n|------|----------|----------------|\\n| **Sep\\u202f15,\\u202f2025** | *AI in Production: Gen AI and Agentic AI on AWS at scale* | Ed dissects the latest AWS tricks for running GenAI & agentic models *without* blowing the company budget. |\\n| **May\\u202f28,\\u202f2025** | *Connecting my courses â€“ become an LLM expert and leader* | A selfâ€‘help guide thatâ€™ll give you â€œLLM masteryâ€ in a week, or you can just enroll anyway. |\\n| **May\\u202f18,\\u202f2025** | *2025 AI Executive Briefing* | Edâ€™s take on why your CFO needs a side hustle in AI. (Spoiler: Itâ€™s called *â€œstrategic partnershipâ€*.) |\\n| **Apr\\u202f21,\\u202f2025** | *The Complete Agentic AI Engineering Course* | The definitive course to engineer *agentic* AI. Perfect if youâ€™re already over 30 or still havenâ€™t learned `git clone`. |\\n\\n**Side gigs**  \\n- **Connect Four**: An LLMâ€‘vsâ€‘LLM arena where models get â€œdiplomaticâ€ or â€œdeviousâ€, depending on whoâ€™s controlling the prompts.  \\n- **Outsmart**: Likely a webâ€‘tool to see if your phoneâ€™s AI is *outsmarting* you. Guess itâ€™s either a success or a reason to buy a new device.  \\n\\n> **Takeaway**  \\n> If you liked *The Last of Us*, read Ed's *Connect Four* for a new way to feel helpless in a world of blackâ€‘box models. If you want to claim expertise before the next AI boom, sign up for one of his coursesâ€”just donâ€™t forget the money.\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(\"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3d926d59-450e-4609-92ba-2d6f244f1342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to display this nicely in the output, using markdown\n",
    "\n",
    "def display_summary(url):\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3018853a-445f-41ff-9560-d925d1774b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Edward Donnerâ€™s Digital Niche (AKA â€œWebpage of a Halfâ€‘Geniusâ€)**\n",
       "\n",
       "- **Profile**: Ed is the â€œcodeâ€‘slinging, LLMâ€‘hacking, occasional DJâ€ who runs Nebula.io (AI recruitment tech) and has previously sold an AI startup called *untapt*â€”so he's got the credibility that doesnâ€™t involve actually being a wizard.\n",
       "  \n",
       "- **Whatâ€™s on the site**: A personal site thatâ€™s half blogging, half portfolio. He flaunts his â€œawardâ€‘winning platform,â€ â€œpatented matching model,â€ and a whole section for people to DM him for â€œconnectâ€ (yes, â€œConnect Fourâ€ is a separate LLM arena, not his board game skills).\n",
       "\n",
       "- **Latest â€œbreaking newsâ€**:\n",
       "  - **Sepâ€¯15â€¯2025** â€“ â€œAI in Production: Gen AI and Agentic AI on AWS at scaleâ€ â†’ because nothing says success like a headline that reads like a conference abstract.\n",
       "  - **Mayâ€¯28â€¯2025** â€“ â€œConnecting my courses â€“ become an LLM expert and leaderâ€ â†’ heâ€™s now an â€œLLM teacherâ€ so you can learn to dominate other language modelsâ€”just in case thatâ€™s still relevant.\n",
       "  - **Mayâ€¯18â€¯2025** â€“ â€œ2025 AI Executive Briefingâ€ â†’ presumably a PowerPointâ€‘filled summit he owns.\n",
       "  - **Aprâ€¯21â€¯2025** â€“ â€œThe Complete Agentic AI Engineering Courseâ€ â†’ because heâ€™s just got another course, folks.\n",
       "\n",
       "- **Sideâ€‘bars**: Links to LinkedIn, Twitter, Facebook (youâ€™ll have to scroll past the 100% â€œconnectâ€ button), and an email subscription form that apparently promises newsletters youâ€™ll probably forget about unless youâ€™re into AI hype.\n",
       "\n",
       "In short: Ed is a coderâ€‘turnedâ€‘entrepreneurâ€‘turnedâ€‘teacherâ€‘hiveâ€‘mind who runs a jobâ€‘matching platform with shiny patents, and this website is the oneâ€‘page rÃ©sumÃ© for anyone who thinks they need more LLM training or a recruiter who still thinks AI is magic."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bcf6f4-adce-45e9-97ad-d9a5d7a3a624",
   "metadata": {},
   "source": [
    "# Let's try more websites\n",
    "\n",
    "Note that this will only work on websites that can be scraped using this simplistic approach.\n",
    "\n",
    "Websites that are rendered with Javascript, like React apps, won't show up. See the community-contributions folder for a Selenium implementation that gets around this. You'll need to read up on installing Selenium (ask ChatGPT!)\n",
    "\n",
    "Also Websites protected with CloudFront (and similar) may give 403 errors - many thanks Andy J for pointing this out.\n",
    "\n",
    "But many websites will work just fine!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "45d83403-a24c-44b5-84ac-961449b4008f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**CNNâ€™s Bareâ€‘Bones Dashboard (with a side of ad misery)**  \n",
       "\n",
       "- The page is a *layout skeleton* rather than a newsroom.  Thousands of navigation links (US, World, Politicsâ€¦ the whole alphabet of â€œcategoriesâ€) sit on a clean background.  \n",
       "- Thereâ€™s *no headline*â€”just the â€œBreaking News, Latest News and Videosâ€ title that never gets a story to attach itself to.  \n",
       "- A popâ€‘up adâ€‘feedback form is the only thing that offers content: itâ€™s a list of generic complaints about sluggish video players, loud audio and repetitive, slowâ€‘loading ads.  \n",
       "- In short, if youâ€™re looking for hard news, youâ€™ll need to click somewhereâ€”this page is just a lobby for the real stories."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://cnn.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "75e9fd40-b354-4341-991e-863ef2e59db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Anthropic\n",
       "\n",
       "> *â€œAI thatâ€™s *safetyâ€‘atâ€‘theâ€‘frontier*? Sounds like a really tidy promise.â€*\n",
       "\n",
       "- **What the heck is happening?** Anthropic is still in its *â€œpublicâ€‘benefitâ€‘Corpâ€* mode, meaning theyâ€™re loudly declaring to the world that theyâ€™ll use AI *for good* while also making sure â€œyouâ€™ll keep a hand on the wheel.â€  \n",
       "- **Main stars:** Their flagship model **Claude** is getting fresh siblings. The newest **Sonnetâ€¯4.5** boasts agentâ€‘ready chops, coding prowess, and is apparently *the best model in the world for agents, coding, and computer use*â€”which probably means â€œthe best way to brag to your boss.â€  \n",
       "- **Haikuâ€¯4.5** is their quickâ€‘andâ€‘sweet model that still pretends to be helpful without chewing too much context.  \n",
       "- The site is littered with repeated â€œTry Claude,â€ â€œDownload app,â€ and countless â€œLog inâ€ prompts as if their landing page was written on a vendingâ€‘machine screen.  \n",
       "- They sprinkle in fancy legalâ€‘talk: *Commitments, Initiatives, Transparency, Responsible Scaling Policy,* plus a â€œTrust center.â€  \n",
       "- **Announcements:** A couple of glowing â€œRead announcementâ€ links hint at new releases and an emphasis on *â€œManaging context on the Claude Developer Platform.â€*  \n",
       "- **Bottom line**: Anthropic is juggling hype, selfâ€‘branding as the safety sentinel, and the inevitable marketing churn you expect from a company thatâ€™s about to drop the next â€œworldâ€‘alteringâ€ AI model. The real question is whether the safety promises hold up when the *real* world starts asking *why* they need to keep a hand on the wheel."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://anthropic.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c951be1a-7f1b-448f-af1f-845978e47e2c",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/business.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#181;\">Business applications</h2>\n",
    "            <span style=\"color:#181;\">In this exercise, you experienced calling the Cloud API of a Frontier Model (a leading model at the frontier of AI) for the first time. We will be using APIs like OpenAI at many stages in the course, in addition to building our own LLMs.\n",
    "\n",
    "More specifically, we've applied this to Summarization - a classic Gen AI use case to make a summary. This can be applied to any business vertical - summarizing the news, summarizing financial performance, summarizing a resume in a cover letter - the applications are limitless. Consider how you could apply Summarization in your business, and try prototyping a solution.</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/important.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#900;\">Before you continue - now try yourself</h2>\n",
    "            <span style=\"color:#900;\">Use the cell below to make your own simple commercial example. Stick with the summarization use case for now. Here's an idea: write something that will take the contents of an email, and will suggest an appropriate short subject line for the email. That's the kind of feature that might be built into a commercial email tool.</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "00743dac-0e70-45b7-879a-d7293a6f68a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Email Original:\n",
      "------------------------------------------------------------\n",
      "\n",
      "Hi John,\n",
      "\n",
      "I hope this email finds you well. I wanted to reach out regarding our upcoming \n",
      "quarterly review meeting scheduled for next Monday. We need to discuss the \n",
      "Q4 sales performance, review the new marketing strategy, and set targets \n",
      "for Q1 2026.\n",
      "\n",
      "Could you please prepare the sales reports and bring the budget proposals? \n",
      "Also, please confirm if 2 PM works for you, or if we need to reschedule.\n",
      "\n",
      "Looking forward to hearing from you.\n",
      "\n",
      "Best regards,\n",
      "Sarah\n",
      "\n",
      "\n",
      "============================================================\n",
      " LÃ­nea de Asunto Sugerida: Q4 Review Meeting Prep: Sales Reports & Budget Proposal\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# EJEMPLO: Generador de lÃ­neas de asunto para emails\n",
    "\n",
    "# Step 1: Define el system prompt - Instrucciones para el modelo\n",
    "email_system_prompt = \"\"\"\n",
    "You are a professional email assistant. \n",
    "Analyze the email content provided and suggest a clear, concise, and professional subject line.\n",
    "The subject line should be under 60 characters and capture the main purpose of the email.\n",
    "Respond with ONLY the subject line, nothing else.\n",
    "\"\"\"\n",
    "\n",
    "# Step 2: Define el contenido del email de ejemplo\n",
    "sample_email = \"\"\"\n",
    "Hi John,\n",
    "\n",
    "I hope this email finds you well. I wanted to reach out regarding our upcoming \n",
    "quarterly review meeting scheduled for next Monday. We need to discuss the \n",
    "Q4 sales performance, review the new marketing strategy, and set targets \n",
    "for Q1 2026.\n",
    "\n",
    "Could you please prepare the sales reports and bring the budget proposals? \n",
    "Also, please confirm if 2 PM works for you, or if we need to reschedule.\n",
    "\n",
    "Looking forward to hearing from you.\n",
    "\n",
    "Best regards,\n",
    "Sarah\n",
    "\"\"\"\n",
    "\n",
    "# Step 3: Crea la lista de mensajes en el formato que espera la API\n",
    "email_messages = [\n",
    "    {\"role\": \"system\", \"content\": email_system_prompt},\n",
    "    {\"role\": \"user\", \"content\": f\"Email content:\\n\\n{sample_email}\"}\n",
    "]\n",
    "\n",
    "# Step 4: Llama a Ollama para generar la lÃ­nea de asunto\n",
    "response = openai.chat.completions.create(\n",
    "    model=ollama_model,\n",
    "    messages=email_messages,\n",
    "    temperature=0.7  # AÃ±adimos temperatura para controlar la creatividad\n",
    ")\n",
    "\n",
    "# Step 5: ObtÃ©n y muestra el resultado\n",
    "suggested_subject = response.choices[0].message.content\n",
    "print(\" Email Original:\")\n",
    "print(\"-\" * 60)\n",
    "print(sample_email)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\" LÃ­nea de Asunto Sugerida: {suggested_subject}\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (LLM)",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
