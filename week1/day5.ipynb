{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a98030af-fcd1-4d63-a36e-38ba053498fa",
   "metadata": {},
   "source": [
    "# A full business solution\n",
    "\n",
    "## Now we will take our project from Day 1 to the next level\n",
    "\n",
    "### BUSINESS CHALLENGE:\n",
    "\n",
    "Create a product that builds a Brochure for a company to be used for prospective clients, investors and potential recruits.\n",
    "\n",
    "We will be provided a company name and their primary website.\n",
    "\n",
    "See the end of this notebook for examples of real-world business applications.\n",
    "\n",
    "And remember: I'm always available if you have problems or ideas! Please do reach out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5b08506-dc8b-4443-9201-5f1848161363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "# If these fail, please check you're running from an 'activated' environment with (llms) in the command prompt\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from scraper import fetch_website_links, fetch_website_contents\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3da3aa1",
   "metadata": {},
   "source": [
    "## LLM Provider Configuration\n",
    "\n",
    "You can switch between **Ollama** (local, free) and **OpenAI** (cloud API).\n",
    "\n",
    "**To change:**\n",
    "1. Edit the next cell\n",
    "2. Change `USE_PROVIDER = 'ollama'` to `USE_PROVIDER = 'openai'`\n",
    "3. Execute cells from here downward\n",
    "\n",
    "### Cost Comparison:\n",
    "\n",
    "| Provider | Model | Input Cost | Output Cost | Speed |\n",
    "|----------|-------|------------|-------------|-------|\n",
    "| **Ollama** | deepseek-v3.1:671b-cloud | FREE | FREE | Fast (local) |\n",
    "| **OpenAI** | gpt-4o-mini | $0.15 / 1M tokens | $0.60 / 1M tokens | Very fast (cloud) |\n",
    "\n",
    "**Estimate for this notebook:**\n",
    "- With OpenAI: ~$0.01 - $0.05 per complete execution\n",
    "- With Ollama: $0.00 (100% free)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2228db29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected provider: OLLAMA\n"
     ]
    }
   ],
   "source": [
    "# CONFIGURATION: Change here to test different providers\n",
    "# Options: 'ollama' or 'openai'\n",
    "USE_PROVIDER = 'ollama'  # Change to 'openai' to use OpenAI\n",
    "\n",
    "print(f\"Selected provider: {USE_PROVIDER.upper()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "288451f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Using OLLAMA (Local)\n",
      "==================================================\n",
      "   Base URL: http://192.168.80.200:11434\n",
      "   Model: deepseek-v3.1:671b-cloud\n",
      "   Cost: FREE\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Initialize and constants\n",
    "\n",
    "# Load configuration from global .env\n",
    "load_dotenv(dotenv_path='/workspace/.env', override=True)\n",
    "\n",
    "# Use provider selected in previous cell (or from .env as fallback)\n",
    "llm_provider = USE_PROVIDER if 'USE_PROVIDER' in globals() else os.getenv('LLM_PROVIDER', 'ollama')\n",
    "\n",
    "if llm_provider == 'ollama':\n",
    "    # OLLAMA CONFIGURATION (Local)\n",
    "    ollama_base_url = os.getenv('OLLAMA_BASE_URL')\n",
    "    ollama_api_key = os.getenv('OLLAMA_API_KEY')\n",
    "    ollama_model = os.getenv('OLLAMA_MODEL')\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(\"Using OLLAMA (Local)\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"   Base URL: {ollama_base_url}\")\n",
    "    print(f\"   Model: {ollama_model}\")\n",
    "    print(f\"   Cost: FREE\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Create OpenAI client pointing to Ollama\n",
    "    openai = OpenAI(\n",
    "        base_url=f\"{ollama_base_url}/v1\",\n",
    "        api_key=ollama_api_key\n",
    "    )\n",
    "    MODEL = ollama_model\n",
    "    \n",
    "else:\n",
    "    # OPENAI CONFIGURATION (Cloud)\n",
    "    api_key = os.getenv('OPENAI_API_KEY')\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(\"Using OPENAI (Cloud API)\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    if api_key and api_key.startswith('sk-proj-') and len(api_key) > 50:\n",
    "        print(f\"   API Key: sk-proj-...{api_key[-8:]}\")\n",
    "        print(f\"   Model: gpt-4o-mini\")\n",
    "        print(f\"   Cost: ~$0.15 / 1M tokens input\")\n",
    "        print(\"   Status: Configured correctly\")\n",
    "    else:\n",
    "        print(\"   Status: Invalid or missing API Key\")\n",
    "        print(\"   Check the .env file\")\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    openai = OpenAI(api_key=api_key)\n",
    "    MODEL = 'gpt-4o-mini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e30d8128-933b-44cc-81c8-ab4c9d86589a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clase para representar una pagina web con BeautifulSoup\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "class WebPage:\n",
    "    \"\"\"Class to represent a scraped webpage, with links and content.\"\"\"\n",
    "    \n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Constructor: Downloads and parses a webpage.\n",
    "        \n",
    "        Args:\n",
    "            url (str): URL of the webpage to scrape\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        \n",
    "        # 1. Make HTTP request and get content\n",
    "        response = requests.get(url)\n",
    "        self.body = response.content  # Fixed: was 'boby'\n",
    "        \n",
    "        # 2. Parse HTML with BeautifulSoup\n",
    "        self.soup = BeautifulSoup(self.body, 'html.parser')  # Fixed: missing 'self.'\n",
    "        \n",
    "        # 3. Extract page title\n",
    "        self.title = self.soup.title.string if self.soup.title else 'No Title'\n",
    "        \n",
    "        # 4. Clean and extract body text\n",
    "        if self.soup.body:\n",
    "            # Remove irrelevant elements (scripts, styles, navigation, etc.)\n",
    "            for irrelevant in self.soup.body(['script', 'style', 'header', 'footer', 'nav', 'aside']):\n",
    "                irrelevant.decompose()\n",
    "            # Get all cleaned text\n",
    "            self.text = self.soup.body.get_text(separator='\\n', strip=True)\n",
    "        else:\n",
    "            self.text = 'No Body Content'\n",
    "        \n",
    "        # 5. Extract all links (href) from page\n",
    "        links = [link.get('href') for link in self.soup.find_all('a', href=True)]\n",
    "        # Filter out empty or None links\n",
    "        self.links = [link for link in links if link]\n",
    "        \n",
    "    def get_contents(self):\n",
    "        \"\"\"\n",
    "        Returns page content in readable format.\n",
    "        \n",
    "        Returns:\n",
    "            str: Title and text content of the page\n",
    "        \"\"\"\n",
    "        return f\"Title: {self.title}\\n\\nContent:\\n{self.text}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567c46d4",
   "metadata": {},
   "source": [
    "## Connection Test\n",
    "\n",
    "Run this cell to verify that the selected provider works correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e7cb7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing connection with OLLAMA...\n",
      "\n",
      "SUCCESS!\n",
      "Model response: Connection successful!\n",
      "Model used: deepseek-v3.1:671b-cloud\n"
     ]
    }
   ],
   "source": [
    "# Quick connection test\n",
    "print(f\"Testing connection with {llm_provider.upper()}...\\n\")\n",
    "\n",
    "try:\n",
    "    test_response = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": \"Respond only with: 'Connection successful!'\"}\n",
    "        ],\n",
    "        max_tokens=50\n",
    "    )\n",
    "    result = test_response.choices[0].message.content\n",
    "    print(f\"SUCCESS!\")\n",
    "    print(f\"Model response: {result}\")\n",
    "    print(f\"Model used: {MODEL}\")\n",
    "except Exception as e:\n",
    "    print(f\"Connection ERROR:\")\n",
    "    print(f\"   {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b34567",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1771af9c-717a-4fca-bbbe-8a95893312c3",
   "metadata": {},
   "source": [
    "## First step: Have gpt-4o-mini or deepseek-v3.1:671b-cloud figure out which links are relevant\n",
    "\n",
    "### Use a call to gpt-5-nano to read the links on a webpage, and respond in structured JSON.  \n",
    "It should decide which links are relevant, and replace relative links such as \"/about\" with \"https://company.com/about\".  \n",
    "We will use \"one shot prompting\" in which we provide an example of how it should respond in the prompt.\n",
    "\n",
    "This is an excellent use case for an LLM, because it requires nuanced understanding. Imagine trying to code this without LLMs by parsing and analyzing the webpage - it would be very hard!\n",
    "\n",
    "Sidenote: there is a more advanced technique called \"Structured Outputs\" in which we require the model to respond according to a spec. We cover this technique in Week 8 during our autonomous Agentic AI project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6957b079-0d96-45f7-a26a-3487510e9b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_system_prompt = \"\"\"\n",
    "You are provided with a list of links found on a webpage.\n",
    "You are able to decide which of the links would be most relevant to include in a brochure about the company,\n",
    "such as links to an About page, or a Company page, or Careers/Jobs pages.\n",
    "\n",
    "IMPORTANT: You MUST respond with ONLY valid JSON, no other text before or after. Do not include markdown code blocks.\n",
    "\n",
    "Respond in this exact JSON format:\n",
    "\n",
    "{\n",
    "    \"links\": [\n",
    "        {\"type\": \"about page\", \"url\": \"https://full.url/goes/here/about\"},\n",
    "        {\"type\": \"careers page\", \"url\": \"https://another.full.url/careers\"}\n",
    "    ]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8f03260-e13e-44bb-a651-e00c05d0576b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are provided with a list of links found on a webpage.\n",
      "You are able to decide which of the links would be most relevant to include in a brochure about the company,\n",
      "such as links to an About page, or a Company page, or Careers/Jobs pages.\n",
      "\n",
      "IMPORTANT: You MUST respond with ONLY valid JSON, no other text before or after. Do not include markdown code blocks.\n",
      "\n",
      "Respond in this exact JSON format:\n",
      "\n",
      "{\n",
      "    \"links\": [\n",
      "        {\"type\": \"about page\", \"url\": \"https://full.url/goes/here/about\"},\n",
      "        {\"type\": \"careers page\", \"url\": \"https://another.full.url/careers\"}\n",
      "    ]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(link_system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e1f601b-2eaf-499d-b6b8-c99050c9d6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links_user_prompt(webpage):\n",
    "    \"\"\"\n",
    "    Generates user prompt with the list of links from a webpage.\n",
    "    \n",
    "    Args:\n",
    "        webpage (WebPage): WebPage object with extracted links\n",
    "    \n",
    "    Returns:\n",
    "        str: Formatted prompt with link list\n",
    "    \"\"\"\n",
    "    user_prompt = f\"\"\"\n",
    "Here is the list of links on the website {webpage.url} -\n",
    "Please decide which of these are relevant web links for a brochure about the company, \n",
    "respond with the full https URL in JSON format.\n",
    "Do not include Terms of Service, Privacy, email links.\n",
    "\n",
    "Links (some might be relative links):\n",
    "\n",
    "\"\"\"\n",
    "    # Use links directly from WebPage object (already extracted)\n",
    "    user_prompt += \"\\n\".join(webpage.links)\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "effeb95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_relevant_links(webpage):\n",
    "    \"\"\"\n",
    "    Selects relevant links from a webpage using GPT/Ollama.\n",
    "    \n",
    "    Args:\n",
    "        webpage (WebPage): WebPage object with extracted links\n",
    "    \n",
    "    Returns:\n",
    "        dict: JSON with relevant links in format {\"links\": [...]}\n",
    "    \"\"\"\n",
    "    # NOTE: Ollama does not support response_format, so we make it conditional\n",
    "    if llm_provider == 'ollama':\n",
    "        # For Ollama: without response_format, rely on prompt\n",
    "        response = openai.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": link_system_prompt},\n",
    "                {\"role\": \"user\", \"content\": get_links_user_prompt(webpage)}\n",
    "            ],\n",
    "            temperature=0  # More deterministic for consistent JSON\n",
    "        )\n",
    "    else:\n",
    "        # For OpenAI: use response_format\n",
    "        response = openai.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": link_system_prompt},\n",
    "                {\"role\": \"user\", \"content\": get_links_user_prompt(webpage)}\n",
    "            ],\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "    \n",
    "    result = response.choices[0].message.content\n",
    "    \n",
    "    # CLEANUP: Remove markdown code blocks if present\n",
    "    # Some models wrap JSON in ```json ... ```\n",
    "    if result.strip().startswith('```'):\n",
    "        # Extract content between ``` markers\n",
    "        lines = result.strip().split('\\n')\n",
    "        # Remove first line (```json or ```) and last line (```)\n",
    "        result = '\\n'.join(lines[1:-1])\n",
    "    \n",
    "    # Attempt to parse JSON with error handling\n",
    "    try:\n",
    "        links = json.loads(result)\n",
    "        print(f\"Found {len(links.get('links', []))} relevant links\")\n",
    "        return links\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error parsing JSON. Model response:\")\n",
    "        print(result)\n",
    "        print(f\"\\nError: {e}\")\n",
    "        # Return empty structure on error\n",
    "        return {\"links\": []}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "028c41c3-a68e-46a4-8894-eb6c45511115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#main',\n",
       " '#footer',\n",
       " 'https://www.anthropic.com/',\n",
       " 'https://www.anthropic.com/',\n",
       " 'https://www.anthropic.com/news/claude-sonnet-4-5',\n",
       " 'https://www.anthropic.com/news/claude-haiku-4-5',\n",
       " 'https://anthropic.com/news/context-management',\n",
       " 'https://www.anthropic.com/claude/sonnet',\n",
       " 'https://www.anthropic.com/news/core-views-on-ai-safety',\n",
       " 'https://www.anthropic.com/rsp-updates',\n",
       " 'https://www.anthropic.com/learn',\n",
       " 'https://www.anthropic.com/news/claude-haiku-4-5',\n",
       " 'https://www.anthropic.com/news/claude-sonnet-4-5',\n",
       " 'https://www.anthropic.com/economic-index',\n",
       " 'https://www.anthropic.com/news/claude-opus-4-1',\n",
       " 'https://www.anthropic.com/research/project-vend-1',\n",
       " 'https://www.anthropic.com/research/agentic-misalignment',\n",
       " 'https://www.anthropic.com/research/tracing-thoughts-language-model',\n",
       " 'https://www.anthropic.com/jobs',\n",
       " 'https://www.anthropic.com/jobs',\n",
       " 'https://www.anthropic.com/contact-sales']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "antropic = WebPage(\"https://anthropic.com\")\n",
    "antropic.links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d5b1ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 relevant links\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'links': [{'type': 'about page', 'url': 'https://www.anthropic.com/'},\n",
       "  {'type': 'news page',\n",
       "   'url': 'https://www.anthropic.com/news/claude-sonnet-4-5'},\n",
       "  {'type': 'news page',\n",
       "   'url': 'https://www.anthropic.com/news/claude-haiku-4-5'},\n",
       "  {'type': 'news page',\n",
       "   'url': 'https://anthropic.com/news/context-management'},\n",
       "  {'type': 'product page', 'url': 'https://www.anthropic.com/claude/sonnet'},\n",
       "  {'type': 'research page',\n",
       "   'url': 'https://www.anthropic.com/research/project-vend-1'},\n",
       "  {'type': 'research page',\n",
       "   'url': 'https://www.anthropic.com/research/agentic-misalignment'},\n",
       "  {'type': 'research page',\n",
       "   'url': 'https://www.anthropic.com/research/tracing-thoughts-language-model'},\n",
       "  {'type': 'careers page', 'url': 'https://www.anthropic.com/jobs'},\n",
       "  {'type': 'contact page', 'url': 'https://www.anthropic.com/contact-sales'}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_relevant_links(antropic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3d583e2-dcc4-40cc-9b28-1e8dbf402924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7 relevant links\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'links': [{'type': 'models page', 'url': 'https://huggingface.co/models'},\n",
       "  {'type': 'spaces page', 'url': 'https://huggingface.co/spaces'},\n",
       "  {'type': 'datasets page', 'url': 'https://huggingface.co/datasets'},\n",
       "  {'type': 'enterprise page', 'url': 'https://huggingface.co/enterprise'},\n",
       "  {'type': 'pricing page', 'url': 'https://huggingface.co/pricing'},\n",
       "  {'type': 'join page', 'url': 'https://huggingface.co/join'},\n",
       "  {'type': 'documentation', 'url': 'https://huggingface.co/docs'}]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probar con HuggingFace\n",
    "hf = WebPage(\"https://huggingface.co\")\n",
    "select_relevant_links(hf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d74128e-dfb6-47ec-9549-288b621c838c",
   "metadata": {},
   "source": [
    "## Second step: make the brochure!\n",
    "\n",
    "Assemble all the details into another prompt to GPT-5-nano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a5b6e2-e7ef-44a9-bc7f-59ede71037b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_page_and_all_relevant_links(url):\n",
    "    \"\"\"\n",
    "    Fetches content from main page and all its relevant links.\n",
    "    \n",
    "    Args:\n",
    "        url (str): Website URL\n",
    "    \n",
    "    Returns:\n",
    "        str: Formatted content with main page and relevant links\n",
    "    \"\"\"\n",
    "    # Create WebPage object (download and parse ONCE)\n",
    "    webpage = WebPage(url)\n",
    "    \n",
    "    # Get main page content\n",
    "    contents = webpage.get_contents()\n",
    "    \n",
    "    # Select relevant links using GPT\n",
    "    relevant_links = select_relevant_links(webpage)\n",
    "    \n",
    "    # Build result\n",
    "    result = f\"## Landing Page:\\n\\n{contents}\\n## Relevant Links:\\n\"\n",
    "    for link in relevant_links['links']:\n",
    "        result += f\"\\n\\n### Link: {link['type']}\\n\"\n",
    "        result += fetch_website_contents(link[\"url\"])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5099bd14-076d-4745-baf3-dac08d8e5ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fetch_page_and_all_relevant_links(\"https://huggingface.co\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b863a55-f86c-4e3f-8a79-94e24c1a8cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "brochure_system_prompt = \"\"\"\n",
    "You are an assistant that analyzes the contents of several relevant pages from a company website\n",
    "and creates a short brochure about the company for prospective customers, investors and recruits.\n",
    "Respond in markdown without code blocks.\n",
    "Include details of company culture, customers and careers/jobs if you have the information.\n",
    "\"\"\"\n",
    "\n",
    "# Or uncomment the lines below for a more humorous brochure - this demonstrates how easy it is to incorporate 'tone':\n",
    "\n",
    "# brochure_system_prompt = \"\"\"\n",
    "# You are an assistant that analyzes the contents of several relevant pages from a company website\n",
    "# and creates a short, humorous, entertaining, witty brochure about the company for prospective customers, investors and recruits.\n",
    "# Respond in markdown without code blocks.\n",
    "# Include details of company culture, customers and careers/jobs if you have the information.\n",
    "# \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab83d92-d36b-4ce0-8bcc-5bb4c2f8ff23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_brochure_user_prompt(company_name, url):\n",
    "    user_prompt = f\"\"\"\n",
    "You are looking at a company called: {company_name}\n",
    "Here are the contents of its landing page and other relevant pages;\n",
    "use this information to build a short brochure of the company in markdown without code blocks.\\n\\n\n",
    "\"\"\"\n",
    "    user_prompt += fetch_page_and_all_relevant_links(url)\n",
    "    user_prompt = user_prompt[:5_000] # Truncate if more than 5,000 characters\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd909e0b-1312-4ce2-a553-821e795d7572",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_brochure_user_prompt(\"HuggingFace\", \"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b45846d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_brochure(company_name, url):\n",
    "    response = openai.chat.completions.create(\n",
    "        model=MODEL,  # FIXED: Use MODEL variable (gpt-4o-mini or ollama)\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": brochure_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
    "        ],\n",
    "    )\n",
    "    result = response.choices[0].message.content\n",
    "    display(Markdown(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b123615a",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_brochure(\"HuggingFace\", \"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61eaaab7-0b47-4b29-82d4-75d474ad8d18",
   "metadata": {},
   "source": [
    "## Finally - a minor improvement\n",
    "\n",
    "With a small adjustment, we can change this so that the results stream back from OpenAI,\n",
    "with the familiar typewriter animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51db0e49-f261-4137-aabe-92dd601f7725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_brochure(company_name, url):\n",
    "    stream = openai.chat.completions.create(\n",
    "        model=MODEL,  # FIXED: Use MODEL variable (gpt-4o-mini or ollama)\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": brochure_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
    "          ],\n",
    "        stream=True\n",
    "    )    \n",
    "    response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bf0ae3-ee9d-4a72-9cd6-edcac67ceb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_brochure(\"HuggingFace\", \"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb3f8d8-a3eb-41c8-b1aa-9f60686a653b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try changing the system prompt to the humorous version when you make the Brochure for Hugging Face:\n",
    "\n",
    "stream_brochure(\"HuggingFace\", \"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27bf9e0-665f-4645-b66b-9725e2a959b5",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/business.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#181;\">Business applications</h2>\n",
    "            <span style=\"color:#181;\">In this exercise we extended the Day 1 code to make multiple LLM calls, and generate a document.\n",
    "\n",
    "This is perhaps the first example of Agentic AI design patterns, as we combined multiple calls to LLMs. This will feature more in Week 2, and then we will return to Agentic AI in a big way in Week 8 when we build a fully autonomous Agent solution.\n",
    "\n",
    "Generating content in this way is one of the very most common Use Cases. As with summarization, this can be applied to any business vertical. Write marketing content, generate a product tutorial from a spec, create personalized email content, and so much more. Explore how you can apply content generation to your business, and try making yourself a proof-of-concept prototype. See what other students have done in the community-contributions folder -- so many valuable projects -- it's wild!</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b2454b-8ef8-4b5c-b928-053a15e0d553",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/important.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#900;\">Before you move to Week 2 (which is tons of fun)</h2>\n",
    "            <span style=\"color:#900;\">Please see the week1 EXERCISE notebook for your challenge for the end of week 1. This will give you some essential practice working with Frontier APIs, and prepare you well for Week 2.</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b64f0f-7d33-4493-985a-033d06e8db08",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">A reminder on 3 useful resources</h2>\n",
    "            <span style=\"color:#f71;\">1. The resources for the course are available <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">here.</a><br/>\n",
    "            2. I'm on LinkedIn <a href=\"https://www.linkedin.com/in/eddonner/\">here</a> and I love connecting with people taking the course!<br/>\n",
    "            3. I'm trying out X/Twitter and I'm at <a href=\"https://x.com/edwarddonner\">@edwarddonner<a> and hoping people will teach me how it's done..  \n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f48e42e-fa7a-495f-a5d4-26bfc24d60b6",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/thankyou.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#090;\">Finally! I have a special request for you</h2>\n",
    "            <span style=\"color:#090;\">\n",
    "                My editor tells me that it makes a MASSIVE difference when students rate this course on Udemy - it's one of the main ways that Udemy decides whether to show it to others. If you're able to take a minute to rate this, I'd be so very grateful! And regardless - always please reach out to me at ed@edwarddonner.com if I can help at any point.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (LLM)",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
