{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a98030af-fcd1-4d63-a36e-38ba053498fa",
   "metadata": {},
   "source": [
    "# A full business solution\n",
    "\n",
    "## Now we will take our project from Day 1 to the next level\n",
    "\n",
    "### BUSINESS CHALLENGE:\n",
    "\n",
    "Create a product that builds a Brochure for a company to be used for prospective clients, investors and potential recruits.\n",
    "\n",
    "We will be provided a company name and their primary website.\n",
    "\n",
    "See the end of this notebook for examples of real-world business applications.\n",
    "\n",
    "And remember: I'm always available if you have problems or ideas! Please do reach out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5b08506-dc8b-4443-9201-5f1848161363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "# If these fail, please check you're running from an 'activated' environment with (llms) in the command prompt\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from scraper import fetch_website_links, fetch_website_contents\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3da3aa1",
   "metadata": {},
   "source": [
    "## LLM Provider Configuration\n",
    "\n",
    "You can switch between **Ollama** (local, free) and **OpenAI** (cloud API).\n",
    "\n",
    "**To change:**\n",
    "1. Edit the next cell\n",
    "2. Change `USE_PROVIDER = 'ollama'` to `USE_PROVIDER = 'openai'`\n",
    "3. Execute cells from here downward\n",
    "\n",
    "### Cost Comparison:\n",
    "\n",
    "| Provider | Model | Input Cost | Output Cost | Speed |\n",
    "|----------|-------|------------|-------------|-------|\n",
    "| **Ollama** | deepseek-v3.1:671b-cloud | FREE | FREE | Fast (local) |\n",
    "| **OpenAI** | gpt-4o-mini | $0.15 / 1M tokens | $0.60 / 1M tokens | Very fast (cloud) |\n",
    "\n",
    "**Estimate for this notebook:**\n",
    "- With OpenAI: ~$0.01 - $0.05 per complete execution\n",
    "- With Ollama: $0.00 (100% free)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2228db29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected provider: OLLAMA\n"
     ]
    }
   ],
   "source": [
    "# CONFIGURATION: Change here to test different providers\n",
    "# Options: 'ollama' or 'openai'\n",
    "USE_PROVIDER = 'ollama'  # Change to 'openai' to use OpenAI\n",
    "\n",
    "print(f\"Selected provider: {USE_PROVIDER.upper()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "288451f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Using OLLAMA (Local)\n",
      "==================================================\n",
      "   Base URL: http://192.168.80.200:11434\n",
      "   Model: deepseek-v3.1:671b-cloud\n",
      "   Cost: FREE\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Initialize and constants\n",
    "\n",
    "# Load configuration from global .env\n",
    "load_dotenv(dotenv_path='/workspace/.env', override=True)\n",
    "\n",
    "# Use provider selected in previous cell (or from .env as fallback)\n",
    "llm_provider = USE_PROVIDER if 'USE_PROVIDER' in globals() else os.getenv('LLM_PROVIDER', 'ollama')\n",
    "\n",
    "if llm_provider == 'ollama':\n",
    "    # OLLAMA CONFIGURATION (Local)\n",
    "    ollama_base_url = os.getenv('OLLAMA_BASE_URL')\n",
    "    ollama_api_key = os.getenv('OLLAMA_API_KEY')\n",
    "    ollama_model = os.getenv('OLLAMA_MODEL')\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(\"Using OLLAMA (Local)\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"   Base URL: {ollama_base_url}\")\n",
    "    print(f\"   Model: {ollama_model}\")\n",
    "    print(f\"   Cost: FREE\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Create OpenAI client pointing to Ollama\n",
    "    openai = OpenAI(\n",
    "        base_url=f\"{ollama_base_url}/v1\",\n",
    "        api_key=ollama_api_key\n",
    "    )\n",
    "    MODEL = ollama_model\n",
    "    \n",
    "else:\n",
    "    # OPENAI CONFIGURATION (Cloud)\n",
    "    api_key = os.getenv('OPENAI_API_KEY')\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(\"Using OPENAI (Cloud API)\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    if api_key and api_key.startswith('sk-proj-') and len(api_key) > 50:\n",
    "        print(f\"   API Key: sk-proj-...{api_key[-8:]}\")\n",
    "        print(f\"   Model: gpt-4o-mini\")\n",
    "        print(f\"   Cost: ~$0.15 / 1M tokens input\")\n",
    "        print(\"   Status: Configured correctly\")\n",
    "    else:\n",
    "        print(\"   Status: Invalid or missing API Key\")\n",
    "        print(\"   Check the .env file\")\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    openai = OpenAI(api_key=api_key)\n",
    "    MODEL = 'gpt-4o-mini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e30d8128-933b-44cc-81c8-ab4c9d86589a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clase para representar una pagina web con BeautifulSoup\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "class WebPage:\n",
    "    \"\"\"Class to represent a scraped webpage, with links and content.\"\"\"\n",
    "    \n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Constructor: Downloads and parses a webpage.\n",
    "        \n",
    "        Args:\n",
    "            url (str): URL of the webpage to scrape\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        \n",
    "        # 1. Make HTTP request and get content\n",
    "        response = requests.get(url)\n",
    "        self.body = response.content  # Fixed: was 'boby'\n",
    "        \n",
    "        # 2. Parse HTML with BeautifulSoup\n",
    "        self.soup = BeautifulSoup(self.body, 'html.parser')  # Fixed: missing 'self.'\n",
    "        \n",
    "        # 3. Extract page title\n",
    "        self.title = self.soup.title.string if self.soup.title else 'No Title'\n",
    "        \n",
    "        # 4. Clean and extract body text\n",
    "        if self.soup.body:\n",
    "            # Remove irrelevant elements (scripts, styles, navigation, etc.)\n",
    "            for irrelevant in self.soup.body(['script', 'style', 'header', 'footer', 'nav', 'aside']):\n",
    "                irrelevant.decompose()\n",
    "            # Get all cleaned text\n",
    "            self.text = self.soup.body.get_text(separator='\\n', strip=True)\n",
    "        else:\n",
    "            self.text = 'No Body Content'\n",
    "        \n",
    "        # 5. Extract all links (href) from page\n",
    "        links = [link.get('href') for link in self.soup.find_all('a', href=True)]\n",
    "        # Filter out empty or None links\n",
    "        self.links = [link for link in links if link]\n",
    "        \n",
    "    def get_contents(self):\n",
    "        \"\"\"\n",
    "        Returns page content in readable format.\n",
    "        \n",
    "        Returns:\n",
    "            str: Title and text content of the page\n",
    "        \"\"\"\n",
    "        return f\"Title: {self.title}\\n\\nContent:\\n{self.text}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567c46d4",
   "metadata": {},
   "source": [
    "## Connection Test\n",
    "\n",
    "Run this cell to verify that the selected provider works correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e7cb7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing connection with OLLAMA...\n",
      "\n",
      "SUCCESS!\n",
      "Model response: Connection successful!\n",
      "Model used: deepseek-v3.1:671b-cloud\n"
     ]
    }
   ],
   "source": [
    "# Quick connection test\n",
    "print(f\"Testing connection with {llm_provider.upper()}...\\n\")\n",
    "\n",
    "try:\n",
    "    test_response = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": \"Respond only with: 'Connection successful!'\"}\n",
    "        ],\n",
    "        max_tokens=50\n",
    "    )\n",
    "    result = test_response.choices[0].message.content\n",
    "    print(f\"SUCCESS!\")\n",
    "    print(f\"Model response: {result}\")\n",
    "    print(f\"Model used: {MODEL}\")\n",
    "except Exception as e:\n",
    "    print(f\"Connection ERROR:\")\n",
    "    print(f\"   {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b34567",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1771af9c-717a-4fca-bbbe-8a95893312c3",
   "metadata": {},
   "source": [
    "## First step: Have gpt-4o-mini or deepseek-v3.1:671b-cloud figure out which links are relevant\n",
    "\n",
    "### Use a call to gpt-5-nano to read the links on a webpage, and respond in structured JSON.  \n",
    "It should decide which links are relevant, and replace relative links such as \"/about\" with \"https://company.com/about\".  \n",
    "We will use \"one shot prompting\" in which we provide an example of how it should respond in the prompt.\n",
    "\n",
    "This is an excellent use case for an LLM, because it requires nuanced understanding. Imagine trying to code this without LLMs by parsing and analyzing the webpage - it would be very hard!\n",
    "\n",
    "Sidenote: there is a more advanced technique called \"Structured Outputs\" in which we require the model to respond according to a spec. We cover this technique in Week 8 during our autonomous Agentic AI project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6957b079-0d96-45f7-a26a-3487510e9b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_system_prompt = \"\"\"\n",
    "You are provided with a list of links found on a webpage.\n",
    "You are able to decide which of the links would be most relevant to include in a brochure about the company,\n",
    "such as links to an About page, or a Company page, or Careers/Jobs pages.\n",
    "\n",
    "IMPORTANT: You MUST respond with ONLY valid JSON, no other text before or after. Do not include markdown code blocks.\n",
    "\n",
    "Respond in this exact JSON format:\n",
    "\n",
    "{\n",
    "    \"links\": [\n",
    "        {\"type\": \"about page\", \"url\": \"https://full.url/goes/here/about\"},\n",
    "        {\"type\": \"careers page\", \"url\": \"https://another.full.url/careers\"}\n",
    "    ]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8f03260-e13e-44bb-a651-e00c05d0576b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are provided with a list of links found on a webpage.\n",
      "You are able to decide which of the links would be most relevant to include in a brochure about the company,\n",
      "such as links to an About page, or a Company page, or Careers/Jobs pages.\n",
      "\n",
      "IMPORTANT: You MUST respond with ONLY valid JSON, no other text before or after. Do not include markdown code blocks.\n",
      "\n",
      "Respond in this exact JSON format:\n",
      "\n",
      "{\n",
      "    \"links\": [\n",
      "        {\"type\": \"about page\", \"url\": \"https://full.url/goes/here/about\"},\n",
      "        {\"type\": \"careers page\", \"url\": \"https://another.full.url/careers\"}\n",
      "    ]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(link_system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e1f601b-2eaf-499d-b6b8-c99050c9d6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links_user_prompt(webpage):\n",
    "    \"\"\"\n",
    "    Generates user prompt with the list of links from a webpage.\n",
    "    \n",
    "    Args:\n",
    "        webpage (WebPage): WebPage object with extracted links\n",
    "    \n",
    "    Returns:\n",
    "        str: Formatted prompt with link list\n",
    "    \"\"\"\n",
    "    user_prompt = f\"\"\"\n",
    "Here is the list of links on the website {webpage.url} -\n",
    "Please decide which of these are relevant web links for a brochure about the company, \n",
    "respond with the full https URL in JSON format.\n",
    "Do not include Terms of Service, Privacy, email links.\n",
    "\n",
    "Links (some might be relative links):\n",
    "\n",
    "\"\"\"\n",
    "    # Use links directly from WebPage object (already extracted)\n",
    "    user_prompt += \"\\n\".join(webpage.links)\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "effeb95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_relevant_links(webpage):\n",
    "    \"\"\"\n",
    "    Selects relevant links from a webpage using GPT/Ollama.\n",
    "    \n",
    "    Args:\n",
    "        webpage (WebPage): WebPage object with extracted links\n",
    "    \n",
    "    Returns:\n",
    "        dict: JSON with relevant links in format {\"links\": [...]}\n",
    "    \"\"\"\n",
    "    # NOTE: Ollama does not support response_format, so we make it conditional\n",
    "    if llm_provider == 'ollama':\n",
    "        # For Ollama: without response_format, rely on prompt\n",
    "        response = openai.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": link_system_prompt},\n",
    "                {\"role\": \"user\", \"content\": get_links_user_prompt(webpage)}\n",
    "            ],\n",
    "            temperature=0  # More deterministic for consistent JSON\n",
    "        )\n",
    "    else:\n",
    "        # For OpenAI: use response_format\n",
    "        response = openai.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": link_system_prompt},\n",
    "                {\"role\": \"user\", \"content\": get_links_user_prompt(webpage)}\n",
    "            ],\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "    \n",
    "    result = response.choices[0].message.content\n",
    "    \n",
    "    # CLEANUP: Remove markdown code blocks if present\n",
    "    # Some models wrap JSON in ```json ... ```\n",
    "    if result.strip().startswith('```'):\n",
    "        # Extract content between ``` markers\n",
    "        lines = result.strip().split('\\n')\n",
    "        # Remove first line (```json or ```) and last line (```)\n",
    "        result = '\\n'.join(lines[1:-1])\n",
    "    \n",
    "    # Attempt to parse JSON with error handling\n",
    "    try:\n",
    "        links = json.loads(result)\n",
    "        print(f\"Found {len(links.get('links', []))} relevant links\")\n",
    "        return links\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error parsing JSON. Model response:\")\n",
    "        print(result)\n",
    "        print(f\"\\nError: {e}\")\n",
    "        # Return empty structure on error\n",
    "        return {\"links\": []}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "028c41c3-a68e-46a4-8894-eb6c45511115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#main',\n",
       " '#footer',\n",
       " 'https://www.anthropic.com/',\n",
       " 'https://www.anthropic.com/',\n",
       " 'https://www.anthropic.com/news/claude-sonnet-4-5',\n",
       " 'https://www.anthropic.com/news/claude-haiku-4-5',\n",
       " 'https://anthropic.com/news/context-management',\n",
       " 'https://www.anthropic.com/claude/sonnet',\n",
       " 'https://www.anthropic.com/news/core-views-on-ai-safety',\n",
       " 'https://www.anthropic.com/rsp-updates',\n",
       " 'https://www.anthropic.com/learn',\n",
       " 'https://www.anthropic.com/news/claude-haiku-4-5',\n",
       " 'https://www.anthropic.com/news/claude-sonnet-4-5',\n",
       " 'https://www.anthropic.com/economic-index',\n",
       " 'https://www.anthropic.com/news/claude-opus-4-1',\n",
       " 'https://www.anthropic.com/research/project-vend-1',\n",
       " 'https://www.anthropic.com/research/agentic-misalignment',\n",
       " 'https://www.anthropic.com/research/tracing-thoughts-language-model',\n",
       " 'https://www.anthropic.com/jobs',\n",
       " 'https://www.anthropic.com/jobs',\n",
       " 'https://www.anthropic.com/contact-sales']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "antropic = WebPage(\"https://anthropic.com\")\n",
    "antropic.links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d5b1ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 relevant links\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'links': [{'type': 'about page', 'url': 'https://www.anthropic.com/'},\n",
       "  {'type': 'news page',\n",
       "   'url': 'https://www.anthropic.com/news/claude-sonnet-4-5'},\n",
       "  {'type': 'news page',\n",
       "   'url': 'https://www.anthropic.com/news/claude-haiku-4-5'},\n",
       "  {'type': 'news page',\n",
       "   'url': 'https://anthropic.com/news/context-management'},\n",
       "  {'type': 'product page', 'url': 'https://www.anthropic.com/claude/sonnet'},\n",
       "  {'type': 'research page',\n",
       "   'url': 'https://www.anthropic.com/research/project-vend-1'},\n",
       "  {'type': 'research page',\n",
       "   'url': 'https://www.anthropic.com/research/agentic-misalignment'},\n",
       "  {'type': 'research page',\n",
       "   'url': 'https://www.anthropic.com/research/tracing-thoughts-language-model'},\n",
       "  {'type': 'careers page', 'url': 'https://www.anthropic.com/jobs'},\n",
       "  {'type': 'contact page', 'url': 'https://www.anthropic.com/contact-sales'}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_relevant_links(antropic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3d583e2-dcc4-40cc-9b28-1e8dbf402924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7 relevant links\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'links': [{'type': 'models page', 'url': 'https://huggingface.co/models'},\n",
       "  {'type': 'spaces page', 'url': 'https://huggingface.co/spaces'},\n",
       "  {'type': 'datasets page', 'url': 'https://huggingface.co/datasets'},\n",
       "  {'type': 'enterprise page', 'url': 'https://huggingface.co/enterprise'},\n",
       "  {'type': 'pricing page', 'url': 'https://huggingface.co/pricing'},\n",
       "  {'type': 'join page', 'url': 'https://huggingface.co/join'},\n",
       "  {'type': 'documentation', 'url': 'https://huggingface.co/docs'}]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probar con HuggingFace\n",
    "hf = WebPage(\"https://huggingface.co\")\n",
    "select_relevant_links(hf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d74128e-dfb6-47ec-9549-288b621c838c",
   "metadata": {},
   "source": [
    "## Second step: make the brochure!\n",
    "\n",
    "Assemble all the details into another prompt to GPT-5-nano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85a5b6e2-e7ef-44a9-bc7f-59ede71037b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_page_and_all_relevant_links(url):\n",
    "    \"\"\"\n",
    "    Fetches content from main page and all its relevant links.\n",
    "    \n",
    "    Args:\n",
    "        url (str): Website URL\n",
    "    \n",
    "    Returns:\n",
    "        str: Formatted content with main page and relevant links\n",
    "    \"\"\"\n",
    "    # Create WebPage object (download and parse ONCE)\n",
    "    webpage = WebPage(url)\n",
    "    \n",
    "    # Get main page content\n",
    "    contents = webpage.get_contents()\n",
    "    \n",
    "    # Select relevant links using GPT\n",
    "    relevant_links = select_relevant_links(webpage)\n",
    "    \n",
    "    # Build result\n",
    "    result = f\"## Landing Page:\\n\\n{contents}\\n## Relevant Links:\\n\"\n",
    "    for link in relevant_links['links']:\n",
    "        result += f\"\\n\\n### Link: {link['type']}\\n\"\n",
    "        result += fetch_website_contents(link[\"url\"])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5099bd14-076d-4745-baf3-dac08d8e5ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 relevant links\n",
      "## Landing Page:\n",
      "\n",
      "Title: Hugging Face ‚Äì The AI community building the future.\n",
      "\n",
      "Content:\n",
      "The AI community building the future.\n",
      "The platform where the machine learning community collaborates on models, datasets, and applications.\n",
      "Explore AI Apps\n",
      "or\n",
      "Browse 1M+ models\n",
      "Trending on\n",
      "this week\n",
      "Models\n",
      "Updated\n",
      "6 days ago\n",
      "‚Ä¢\n",
      "810k\n",
      "‚Ä¢\n",
      "1.05k\n",
      "Updated\n",
      "4 days ago\n",
      "‚Ä¢\n",
      "19.4k\n",
      "‚Ä¢\n",
      "347\n",
      "Updated\n",
      "1 day ago\n",
      "‚Ä¢\n",
      "2.25M\n",
      "‚Ä¢\n",
      "2.46k\n",
      "Updated\n",
      "2 days ago\n",
      "‚Ä¢\n",
      "3.03k\n",
      "‚Ä¢\n",
      "221\n",
      "Updated\n",
      "about 14 hours ago\n",
      "‚Ä¢\n",
      "219\n",
      "Browse 1M+ models\n",
      "Spaces\n",
      "1.38k\n",
      "The Smol Training Playbook: The Secrets to Building World-Class LLMs\n",
      "üìù\n",
      "15.7k\n",
      "DeepSite v3\n",
      "üê≥\n",
      "Generate any application by Vibe Coding\n",
      "2.27k\n",
      "Wan2.2 Animate\n",
      "üëÅ\n",
      "Wan2.2 Animate\n",
      "149\n",
      "Dream-wan2-2-faster-Pro\n",
      "üé¨\n",
      "Generate a video from an image with detailed prompts\n",
      "2.05k\n",
      "Wan2.2 14B Fast\n",
      "üé•\n",
      "generate a video from an image with a text prompt\n",
      "Browse 400k+ applications\n",
      "Datasets\n",
      "Updated\n",
      "7 days ago\n",
      "‚Ä¢\n",
      "12.4k\n",
      "‚Ä¢\n",
      "195\n",
      "Updated\n",
      "14 days ago\n",
      "‚Ä¢\n",
      "13.6k\n",
      "‚Ä¢\n",
      "207\n",
      "Updated\n",
      "Sep 9\n",
      "‚Ä¢\n",
      "4.53k\n",
      "‚Ä¢\n",
      "59\n",
      "Updated\n",
      "6 days ago\n",
      "‚Ä¢\n",
      "2.04k\n",
      "‚Ä¢\n",
      "45\n",
      "Updated\n",
      "Jan 6\n",
      "‚Ä¢\n",
      "36.9k\n",
      "‚Ä¢\n",
      "9.34k\n",
      "Browse 250k+ datasets\n",
      "The Home of Machine Learning\n",
      "Create, discover and collaborate on ML better.\n",
      "The collaboration platform\n",
      "Host and collaborate on unlimited public models, datasets and applications.\n",
      "Move faster\n",
      "With the HF Open source stack.\n",
      "Explore all modalities\n",
      "Text, image, video, audio or even 3D.\n",
      "Build your portfolio\n",
      "Share your work with the world and build your ML profile.\n",
      "Sign Up\n",
      "Accelerate your ML\n",
      "We provide paid Compute and Enterprise solutions.\n",
      "Team & Enterprise\n",
      "Give your team the most advanced platform to build AI with enterprise-grade security, access controls and\n",
      "\t\t\tdedicated support.\n",
      "Getting started\n",
      "Starting at $20/user/month\n",
      "Single Sign-On\n",
      "Regions\n",
      "Priority Support\n",
      "Audit Logs\n",
      "Resource Groups\n",
      "Private Datasets Viewer\n",
      "Inference Providers\n",
      "Access 45,000+ models from leading AI providers through a single, unified API with no service fees.\n",
      "Explore Models\n",
      "Compute\n",
      "Deploy on optimized\n",
      "Inference Endpoints\n",
      "or update your\n",
      "Spaces applications\n",
      "to a GPU in a few clicks.\n",
      "View pricing\n",
      "Starting at $0.60/hour for GPU\n",
      "More than 50,000 organizations are using Hugging Face\n",
      "Ai2\n",
      "Team\n",
      "non-profit\n",
      "‚Ä¢\n",
      "805 models\n",
      "‚Ä¢\n",
      "4.33k followers\n",
      "AI at Meta\n",
      "Enterprise\n",
      "company\n",
      "‚Ä¢\n",
      "2.23k models\n",
      "‚Ä¢\n",
      "8.6k followers\n",
      "Amazon\n",
      "company\n",
      "‚Ä¢\n",
      "21 models\n",
      "‚Ä¢\n",
      "3.51k followers\n",
      "Google\n",
      "Enterprise\n",
      "company\n",
      "‚Ä¢\n",
      "1.05k models\n",
      "‚Ä¢\n",
      "34.5k followers\n",
      "Intel\n",
      "company\n",
      "‚Ä¢\n",
      "250 models\n",
      "‚Ä¢\n",
      "3.17k followers\n",
      "Microsoft\n",
      "Enterprise\n",
      "company\n",
      "‚Ä¢\n",
      "426 models\n",
      "‚Ä¢\n",
      "16.3k followers\n",
      "Grammarly\n",
      "Team\n",
      "company\n",
      "‚Ä¢\n",
      "11 models\n",
      "‚Ä¢\n",
      "186 followers\n",
      "Writer\n",
      "Enterprise\n",
      "company\n",
      "‚Ä¢\n",
      "32 models\n",
      "‚Ä¢\n",
      "365 followers\n",
      "Our Open Source\n",
      "We are building the foundation of ML tooling with the community.\n",
      "Transformers\n",
      "152,088\n",
      "State-of-the-art AI models for PyTorch\n",
      "Diffusers\n",
      "31,482\n",
      "State-of-the-art Diffusion models in PyTorch\n",
      "Safetensors\n",
      "3,500\n",
      "Safe way to store/distribute neural network weights\n",
      "Hub Python Library\n",
      "3,034\n",
      "Python client to interact with the Hugging Face Hub\n",
      "Tokenizers\n",
      "10,206\n",
      "Fast tokenizers optimized for research & production\n",
      "TRL\n",
      "16,152\n",
      "Train transformers LMs with reinforcement learning\n",
      "Transformers.js\n",
      "14,794\n",
      "State-of-the-art ML running directly in your browser\n",
      "smolagents\n",
      "23,771\n",
      "Smol library to build great agents in Python\n",
      "PEFT\n",
      "19,984\n",
      "Parameter-efficient finetuning for large language models\n",
      "Datasets\n",
      "20,810\n",
      "Access & share datasets for any ML tasks\n",
      "Text Generation Inference\n",
      "10,620\n",
      "Serve language models with TGI optimized toolkit\n",
      "Accelerate\n",
      "9,262\n",
      "Train PyTorch models with multi-GPU, TPU, mixed precision\n",
      "## Relevant Links:\n",
      "\n",
      "\n",
      "### Link: about page\n",
      "Enterprise Hub - Hugging Face\n",
      "\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Team & Enterprise Hub\n",
      "Scale your organization with the world‚Äôs leading AI platform\n",
      "Subscribe to\n",
      "Team\n",
      "starting at $20/user/month\n",
      "or\n",
      "Contact sales for\n",
      "Enterprise\n",
      "to explore flexible contract options\n",
      "Give your organization the most advanced platform to build AI with enterprise-grade security, access controls,\n",
      "\t\t\tdedicated support and more.\n",
      "Single Sign-On\n",
      "Connect securely to your identity provider with SSO integration.\n",
      "Regions\n",
      "Select, manage, and audit the location of your repository data.\n",
      "Audit Logs\n",
      "Stay in control with comprehensive logs that report on actions taken.\n",
      "Resource Groups\n",
      "Accurately manage access to repositories with granular access control.\n",
      "Token Management\n",
      "Centralized token control and custom approval policies for organization access.\n",
      "Analytics\n",
      "Track and analyze repository usage data in a single dashboard.\n",
      "Advanced Compute Options\n",
      "Increase scalability and performance with more compute options like ZeroGPU.\n",
      "ZeroGPU Quota Boost\n",
      "All organization members get 5x more ZeroGPU quota to get the most of Spaces.\n",
      "Private Datasets Viewer\n",
      "Enable the Dataset Viewer on your private datasets for easier collaboration.\n",
      "Private Storage\n",
      "Get an additional 1 TB of private storage for each member of your organization (then $25/month per extra TB).\n",
      "Inference Providers\n",
      "Enable organization billing for Inference Providers, monitor usage with analytics, and manage spending limits.\n",
      "Advanced security\n",
      "Configure organization-wide security policies and default repository visibility.\n",
      "Billing\n",
      "Control your budget effectively with managed billing and yearly commit options.\n",
      "Priority Support\n",
      "Maximize your platform usage with priority support from the Hugging Face team.\n",
      "Join the most forward-thinking AI organizations\n",
      "Everything you already know and love about Hugging Face in Enterprise mode.\n",
      "Subscribe to\n",
      "Team\n",
      "starting at $20/user/month\n",
      "or\n",
      "Contact sales for\n",
      "Enterprise\n",
      "to explore fl\n",
      "\n",
      "### Link: pricing page\n",
      "Hugging Face ‚Äì Pricing\n",
      "\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Pricing\n",
      "Leveling up AI collaboration and compute.\n",
      "Give your personal account or your organization the most advanced platform to build AI.\n",
      "PRO\n",
      "PRO Account\n",
      "Boost your personal HF experience\n",
      "Subscribe for\n",
      "$9\n",
      "per month\n",
      "Get PRO\n",
      "10√ó private storage capacity\n",
      "20√ó included inference credits\n",
      "8√ó ZeroGPU quota and highest queue priority\n",
      "Spaces Dev Mode & ZeroGPU Spaces hosting\n",
      "Publish blog articles on your HF profile\n",
      "Dataset Viewer for private datasets\n",
      "Show your support with a Pro badge\n",
      "Team\n",
      "Instant setup for growing teams\n",
      "Subscribe for\n",
      "$20\n",
      "per user per month\n",
      "Get Team (via credit card)\n",
      "SSO and SAML support\n",
      "Choose data location with Storage Regions\n",
      "Detailed action reviews with Audit Logs\n",
      "Granular access control via Resource Groups\n",
      "Repository usage Analytics\n",
      "Set auth policies and default repository visibility\n",
      "Centralized token control and approvals\n",
      "Dataset Viewer for private datasets\n",
      "Advanced compute options for Spaces\n",
      "All organization members get ZeroGPU and Inference Providers PRO benefits\n",
      "Enterprise\n",
      "Custom onboarding and enterprise features\n",
      "Starting at\n",
      "$50\n",
      "per user per month\n",
      "Contact Sales\n",
      "All benefits from the Team plan\n",
      "Highest storage, bandwidth, and API rate limits\n",
      "Managed billing with annual commitments\n",
      "Legal and Compliance processes\n",
      "Personalized support\n",
      "Need support to adopt the HF Hub in your organization? View our\n",
      "Expert Support\n",
      ".\n",
      "Hugging Face Hub\n",
      "free\n",
      "The HF Hub is the central place to explore, experiment, collaborate and build technology with Machine\n",
      "\t\t\t\t\tLearning.\n",
      "Join the open source Machine Learning movement!\n",
      "‚Üí\n",
      "Sign Up\n",
      "Create with ML\n",
      "Packed with ML features, like model eval, dataset viewer and much more.\n",
      "Collaborate\n",
      "Git based and designed for collaboration at its core.\n",
      "Play and learn\n",
      "Learn by experimenting and sharing with our awesome community.\n",
      "Build your ML portfolio\n",
      "Share your work with the world and build your own ML profile.\n",
      "Spaces Hardware\n",
      "Starting at $\n",
      "\n",
      "### Link: documentation page\n",
      "Hugging Face - Documentation\n",
      "\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Documentation\n",
      "Hub & Client Libraries\n",
      "Hub\n",
      "Host Git-based models, datasets, and Spaces on the HF Hub\n",
      "Hub Python Library\n",
      "Python client to interact with the Hugging Face Hub\n",
      "Huggingface.js\n",
      "JavaScript libraries for Hugging Face with built-in TS types\n",
      "Tasks\n",
      "Explore demos, models, and datasets for any ML tasks\n",
      "Dataset viewer\n",
      "API for metadata, stats, and content of HF Hub datasets\n",
      "Deployment & Inference\n",
      "Inference Providers\n",
      "Call 200k+ models hosted by our 10+ Inference partners\n",
      "Inference Endpoints (dedicated)\n",
      "Deploy models on dedicated & fully managed infrastructure on HF\n",
      "Deploying on AWS\n",
      "Train/deploy models from Hugging Face to AWS with DLCs\n",
      "Text Generation Inference\n",
      "Serve language models with TGI optimized toolkit\n",
      "Text Embeddings Inference\n",
      "Serve embeddings models with TEI optimized toolkit\n",
      "Microsoft Azure\n",
      "Deploy Hugging Face models on Microsoft Azure\n",
      "Core ML Libraries\n",
      "Transformers\n",
      "State-of-the-art AI models for PyTorch\n",
      "Diffusers\n",
      "State-of-the-art Diffusion models in PyTorch\n",
      "Datasets\n",
      "Access & share datasets for any ML tasks\n",
      "Transformers.js\n",
      "State-of-the-art ML running directly in your browser\n",
      "Tokenizers\n",
      "Fast tokenizers optimized for research & production\n",
      "Evaluate\n",
      "Evaluate and compare models performance\n",
      "timm\n",
      "State-of-the-art vision models: layers, optimizers, and utilities\n",
      "Sentence Transformers\n",
      "Embeddings, Retrieval, and Reranking\n",
      "Kernels\n",
      "Load and run compute kernels from the Hugging Face Hub\n",
      "Training & Optimization\n",
      "PEFT\n",
      "Parameter-efficient finetuning for large language models\n",
      "Accelerate\n",
      "Train PyTorch models with multi-GPU, TPU, mixed precision\n",
      "Optimum\n",
      "Optimize HF Transformers for faster training/inference\n",
      "AWS Trainium & Inferentia\n",
      "Train/deploy Transformers/Diffusers on AWS\n",
      "TRL\n",
      "Train transformers LMs with reinforcement learning\n",
      "Safetensors\n",
      "Safe way to store/distribute neural network weights\n",
      "Bitsandbytes\n",
      "Optimize and quantize models with bitsandbytes\n",
      "Lighteval\n",
      "All-\n",
      "\n",
      "### Link: models page\n",
      "Models ‚Äì Hugging Face\n",
      "\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Edit Models filters\n",
      "Main\n",
      "Tasks\n",
      "Libraries\n",
      "Languages\n",
      "Licenses\n",
      "Other\n",
      "Tasks\n",
      "Text Generation\n",
      "Any-to-Any\n",
      "Image-Text-to-Text\n",
      "Image-to-Text\n",
      "Image-to-Image\n",
      "Text-to-Image\n",
      "Text-to-Video\n",
      "Text-to-Speech\n",
      "+ 42\n",
      "Parameters\n",
      "Reset Parameters\n",
      "< 1B\n",
      "6B\n",
      "12B\n",
      "32B\n",
      "128B\n",
      "> 500B\n",
      "< 1B\n",
      "> 500B\n",
      "Libraries\n",
      "PyTorch\n",
      "google-tensorflow\n",
      "TensorFlow\n",
      "JAX\n",
      "Transformers\n",
      "Diffusers\n",
      "Safetensors\n",
      "ONNX\n",
      "GGUF\n",
      "Transformers.js\n",
      "MLX\n",
      "Keras\n",
      "+ 41\n",
      "Apps\n",
      "vLLM\n",
      "TGI\n",
      "llama.cpp\n",
      "MLX LM\n",
      "LM Studio\n",
      "Ollama\n",
      "Jan\n",
      "+ 13\n",
      "Inference Providers\n",
      "Groq\n",
      "Novita\n",
      "Nebius AI\n",
      "Cerebras\n",
      "SambaNova\n",
      "Nscale\n",
      "fal\n",
      "Hyperbolic\n",
      "+ 10\n",
      "Apply filters\n",
      "Models\n",
      "Full-text search\n",
      "Inference Available\n",
      "Add filters\n",
      "Sort:¬†\n",
      "\t\tTrending\n",
      "MiniMaxAI/MiniMax-M2\n",
      "Text Generation\n",
      "‚Ä¢\n",
      "229B\n",
      "‚Ä¢\n",
      "Updated\n",
      "6 days ago\n",
      "‚Ä¢\n",
      "810k\n",
      "‚Ä¢\n",
      "‚Ä¢\n",
      "1.05k\n",
      "moonshotai/Kimi-Linear-48B-A3B-Instruct\n",
      "Text Generation\n",
      "‚Ä¢\n",
      "49B\n",
      "‚Ä¢\n",
      "Updated\n",
      "4 days ago\n",
      "‚Ä¢\n",
      "19.4k\n",
      "‚Ä¢\n",
      "347\n",
      "deepseek-ai/DeepSeek-OCR\n",
      "Image-Text-to-Text\n",
      "‚Ä¢\n",
      "3B\n",
      "‚Ä¢\n",
      "Updated\n",
      "1 day ago\n",
      "‚Ä¢\n",
      "2.25M\n",
      "‚Ä¢\n",
      "2.46k\n",
      "briaai/FIBO\n",
      "Text-to-Image\n",
      "‚Ä¢\n",
      "Updated\n",
      "2 days ago\n",
      "‚Ä¢\n",
      "3.03k\n",
      "‚Ä¢\n",
      "‚Ä¢\n",
      "221\n",
      "dx8152/Qwen-Edit-2509-Multiple-angles\n",
      "Image-to-Image\n",
      "‚Ä¢\n",
      "Updated\n",
      "about 14 hours ago\n",
      "‚Ä¢\n",
      "219\n",
      "Soul-AILab/SoulX-Podcast-1.7B\n",
      "Text-to-Speech\n",
      "‚Ä¢\n",
      "2B\n",
      "‚Ä¢\n",
      "Updated\n",
      "3 days ago\n",
      "‚Ä¢\n",
      "1.1k\n",
      "‚Ä¢\n",
      "161\n",
      "openai/gpt-oss-safeguard-20b\n",
      "Text Generation\n",
      "‚Ä¢\n",
      "22B\n",
      "‚Ä¢\n",
      "Updated\n",
      "7 days ago\n",
      "‚Ä¢\n",
      "6.97k\n",
      "‚Ä¢\n",
      "‚Ä¢\n",
      "130\n",
      "datalab-to/chandra\n",
      "Image-to-Text\n",
      "‚Ä¢\n",
      "9B\n",
      "‚Ä¢\n",
      "Updated\n",
      "15 days ago\n",
      "‚Ä¢\n",
      "21.1k\n",
      "‚Ä¢\n",
      "224\n",
      "BAAI/Emu3.5\n",
      "34B\n",
      "‚Ä¢\n",
      "Updated\n",
      "5 days ago\n",
      "‚Ä¢\n",
      "306\n",
      "‚Ä¢\n",
      "110\n",
      "nvidia/ChronoEdit-14B-Diffusers\n",
      "Image-to-Image\n",
      "‚Ä¢\n",
      "Updated\n",
      "6 days ago\n",
      "‚Ä¢\n",
      "575\n",
      "‚Ä¢\n",
      "‚Ä¢\n",
      "103\n",
      "meituan-longcat/LongCat-Video\n",
      "Text-to-Video\n",
      "‚Ä¢\n",
      "Updated\n",
      "7 days ago\n",
      "‚Ä¢\n",
      "1.43k\n",
      "‚Ä¢\n",
      "‚Ä¢\n",
      "281\n",
      "Phr00t/Qwen-Image-Edit-Rapid-AIO\n",
      "Text-to-Image\n",
      "‚Ä¢\n",
      "Updated\n",
      "about 2 hours ago\n",
      "‚Ä¢\n",
      "556\n",
      "meituan-longcat/LongCat-Flash-Omni\n",
      "Text Generation\n",
      "‚Ä¢\n",
      "561B\n",
      "‚Ä¢\n",
      "Updated\n",
      "4 days ago\n",
      "‚Ä¢\n",
      "181\n",
      "‚Ä¢\n",
      "73\n",
      "PaddlePaddle/PaddleOCR-VL\n",
      "Image-Text-to-Text\n",
      "‚Ä¢\n",
      "1.0B\n",
      "‚Ä¢\n",
      "Updated\n",
      "about 12 hours ago\n",
      "‚Ä¢\n",
      "29.4k\n",
      "‚Ä¢\n",
      "1.21k\n",
      "dx8152/Fusion_lora\n",
      "Image-to-Image\n",
      "‚Ä¢\n",
      "Updated\n",
      "about 18 hours ago\n",
      "‚Ä¢\n",
      "3.48k\n",
      "‚Ä¢\n",
      "107\n",
      "ibm-granite/granite-4.0-h-1b\n",
      "Text Generation\n",
      "‚Ä¢\n",
      "1B\n",
      "‚Ä¢\n",
      "\n",
      "### Link: datasets page\n",
      "Datasets ‚Äì Hugging Face\n",
      "\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Edit Datasets filters\n",
      "Main\n",
      "Tasks\n",
      "Libraries\n",
      "Languages\n",
      "Licenses\n",
      "Other\n",
      "Modalities\n",
      "3D\n",
      "Audio\n",
      "Document\n",
      "Geospatial\n",
      "Image\n",
      "Tabular\n",
      "Text\n",
      "Time-series\n",
      "Video\n",
      "Size\n",
      "\t\t\t(rows)\n",
      "Reset Size\n",
      "< 1K\n",
      "> 1T\n",
      "Format\n",
      "json\n",
      "csv\n",
      "parquet\n",
      "imagefolder\n",
      "soundfolder\n",
      "webdataset\n",
      "text\n",
      "arrow\n",
      "Apply filters\n",
      "Datasets\n",
      "541,795\n",
      "Full-text search\n",
      "Add filters\n",
      "Sort:¬†\n",
      "\t\tTrending\n",
      "nvidia/PhysicalAI-Autonomous-Vehicles\n",
      "Updated\n",
      "7 days ago\n",
      "‚Ä¢\n",
      "12.4k\n",
      "‚Ä¢\n",
      "195\n",
      "HuggingFaceFW/finewiki\n",
      "Viewer\n",
      "‚Ä¢\n",
      "Updated\n",
      "14 days ago\n",
      "‚Ä¢\n",
      "61.6M\n",
      "‚Ä¢\n",
      "13.6k\n",
      "‚Ä¢\n",
      "207\n",
      "neulab/agent-data-collection\n",
      "Viewer\n",
      "‚Ä¢\n",
      "Updated\n",
      "Sep 9\n",
      "‚Ä¢\n",
      "225k\n",
      "‚Ä¢\n",
      "4.53k\n",
      "‚Ä¢\n",
      "59\n",
      "nvidia/Nemotron-VLM-Dataset-v2\n",
      "Viewer\n",
      "‚Ä¢\n",
      "Updated\n",
      "6 days ago\n",
      "‚Ä¢\n",
      "4.58M\n",
      "‚Ä¢\n",
      "2.04k\n",
      "‚Ä¢\n",
      "45\n",
      "fka/awesome-chatgpt-prompts\n",
      "Viewer\n",
      "‚Ä¢\n",
      "Updated\n",
      "Jan 6\n",
      "‚Ä¢\n",
      "203\n",
      "‚Ä¢\n",
      "36.9k\n",
      "‚Ä¢\n",
      "9.34k\n",
      "Bingguang/FunReason-MT\n",
      "Viewer\n",
      "‚Ä¢\n",
      "Updated\n",
      "about 2 hours ago\n",
      "‚Ä¢\n",
      "17k\n",
      "‚Ä¢\n",
      "320\n",
      "‚Ä¢\n",
      "21\n",
      "mrlbenchmarks/global-piqa-nonparallel\n",
      "Viewer\n",
      "‚Ä¢\n",
      "Updated\n",
      "7 days ago\n",
      "‚Ä¢\n",
      "11.6k\n",
      "‚Ä¢\n",
      "2.07k\n",
      "‚Ä¢\n",
      "20\n",
      "RUC-DataLab/DataScience-Instruct-500K\n",
      "Viewer\n",
      "‚Ä¢\n",
      "Updated\n",
      "15 days ago\n",
      "‚Ä¢\n",
      "26.2k\n",
      "‚Ä¢\n",
      "6.18k\n",
      "‚Ä¢\n",
      "46\n",
      "AlicanKiraz0/Turkish-SFT-Dataset-v1.0\n",
      "Viewer\n",
      "‚Ä¢\n",
      "Updated\n",
      "9 days ago\n",
      "‚Ä¢\n",
      "5.58k\n",
      "‚Ä¢\n",
      "745\n",
      "‚Ä¢\n",
      "36\n",
      "FreedomIntelligence/medical-o1-reasoning-SFT\n",
      "Viewer\n",
      "‚Ä¢\n",
      "Updated\n",
      "Apr 22\n",
      "‚Ä¢\n",
      "90.1k\n",
      "‚Ä¢\n",
      "7.68k\n",
      "‚Ä¢\n",
      "929\n",
      "HuggingFaceM4/FineVision\n",
      "Viewer\n",
      "‚Ä¢\n",
      "Updated\n",
      "15 days ago\n",
      "‚Ä¢\n",
      "24.2M\n",
      "‚Ä¢\n",
      "251k\n",
      "‚Ä¢\n",
      "428\n",
      "openai/gsm8k\n",
      "Viewer\n",
      "‚Ä¢\n",
      "Updated\n",
      "Jan 4, 2024\n",
      "‚Ä¢\n",
      "17.6k\n",
      "‚Ä¢\n",
      "446k\n",
      "‚Ä¢\n",
      "931\n",
      "HuggingFaceFW/finepdfs\n",
      "Viewer\n",
      "‚Ä¢\n",
      "Updated\n",
      "Sep 8\n",
      "‚Ä¢\n",
      "475M\n",
      "‚Ä¢\n",
      "56.5k\n",
      "‚Ä¢\n",
      "648\n",
      "HuggingFaceFW/fineweb\n",
      "Viewer\n",
      "‚Ä¢\n",
      "Updated\n",
      "Jul 11\n",
      "‚Ä¢\n",
      "52.5B\n",
      "‚Ä¢\n",
      "305k\n",
      "‚Ä¢\n",
      "2.42k\n",
      "nick007x/github-code-2025\n",
      "Viewer\n",
      "‚Ä¢\n",
      "Updated\n",
      "20 days ago\n",
      "‚Ä¢\n",
      "147M\n",
      "‚Ä¢\n",
      "15.2k\n",
      "‚Ä¢\n",
      "94\n",
      "karpathy/fineweb-edu-100b-shuffle\n",
      "Viewer\n",
      "‚Ä¢\n",
      "Updated\n",
      "Sep 25\n",
      "‚Ä¢\n",
      "97.2M\n",
      "‚Ä¢\n",
      "54k\n",
      "‚Ä¢\n",
      "123\n",
      "Agent-Ark/Toucan-1.5M\n",
      "Viewer\n",
      "‚Ä¢\n",
      "Updated\n",
      "Oct 4\n",
      "‚Ä¢\n",
      "1.65M\n",
      "‚Ä¢\n",
      "15.9k\n",
      "‚Ä¢\n",
      "169\n",
      "zhihefang/UltraHR-100K\n",
      "Viewer\n",
      "‚Ä¢\n",
      "Updated\n",
      "3 days ago\n",
      "‚Ä¢\n",
      "900\n",
      "‚Ä¢\n",
      "9.63k\n",
      "‚Ä¢\n",
      "12\n",
      "DAVIAN-Robotics/PHUMA\n",
      "Updated\n",
      "4 days ago\n",
      "‚Ä¢\n",
      "50\n",
      "‚Ä¢\n",
      "10\n",
      "AlicanKiraz0/seneca-trbench\n",
      "Viewer\n",
      "‚Ä¢\n",
      "Updated\n",
      "6 days ago\n",
      "‚Ä¢\n",
      "553\n",
      "‚Ä¢\n",
      "408\n",
      "‚Ä¢\n",
      "10\n",
      "Anthropic/hh-rlhf\n",
      "Viewer\n",
      "‚Ä¢\n",
      "Updated\n",
      "May 26, 2023\n",
      "‚Ä¢\n",
      "169k\n",
      "‚Ä¢\n",
      "41.7k\n",
      "‚Ä¢\n",
      "1.47k\n",
      "Huggin\n",
      "\n",
      "### Link: spaces page\n",
      "Spaces - Hugging Face\n",
      "\n",
      "Hugging Face\n",
      "Models\n",
      "Datasets\n",
      "Spaces\n",
      "Community\n",
      "Docs\n",
      "Enterprise\n",
      "Pricing\n",
      "Log In\n",
      "Sign Up\n",
      "Spaces\n",
      "¬∑\n",
      "The AI App Directory\n",
      "New Space\n",
      "Get PRO\n",
      "Learn more\n",
      "Image Generation\n",
      "Video Generation\n",
      "Text Generation\n",
      "Language Translation\n",
      "Speech Synthesis\n",
      "3D Modeling\n",
      "Object Detection\n",
      "Text Analysis\n",
      "Image Editing\n",
      "Code Generation\n",
      "Question Answering\n",
      "Data Visualization\n",
      "Voice Cloning\n",
      "Background Removal\n",
      "Image Upscaling\n",
      "OCR\n",
      "Document Analysis\n",
      "Visual QA\n",
      "Image Captioning\n",
      "Chatbots\n",
      "Sentiment Analysis\n",
      "Text Summarization\n",
      "Music Generation\n",
      "Medical Imaging\n",
      "Financial Analysis\n",
      "Game AI\n",
      "Model Benchmarking\n",
      "Fine Tuning Tools\n",
      "Dataset Creation\n",
      "Pose Estimation\n",
      "Face Recognition\n",
      "Anomaly Detection\n",
      "Recommendation Systems\n",
      "Character Animation\n",
      "Style Transfer\n",
      "Image\n",
      "Spaces of the week\n",
      "3 Nov 2025\n",
      "Filters\n",
      "(0)\n",
      "Sort:¬†\n",
      "\t\tRelevance\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "29\n",
      "Wan2.2 Animate [Local]\n",
      "üî•\n",
      "Edit Videos with Wan 2.2\n",
      "alexnasa\n",
      "1 day ago\n",
      "Running\n",
      "on\n",
      "CPU Upgrade\n",
      "1.38k\n",
      "The Smol Training Playbook: The Secrets to Building World-Class LLMs\n",
      "üìù\n",
      "HuggingFaceTB\n",
      "about 18 hours ago\n",
      "Runtime error\n",
      "50\n",
      "Qwen-Image-2509-MultipleAngles\n",
      "üëÄ\n",
      "Qwen-Image-2509-MultipleAngles\n",
      "tori29umai\n",
      "about 9 hours ago\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "29\n",
      "FIBO\n",
      "‚ú®\n",
      "Generate images from text or images\n",
      "briaai\n",
      "3 days ago\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "83\n",
      "KaniTTS\n",
      "üòª\n",
      "Generate speech from text using selected models\n",
      "nineninesix\n",
      "5 days ago\n",
      "Running\n",
      "75\n",
      "Granite 4.0 Nano WebGPU\n",
      "üõ†\n",
      "In-browser tool calling with IBM Granite-4.0\n",
      "ibm-granite\n",
      "7 days ago\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "49\n",
      "LongCat Video\n",
      "üòº\n",
      "Generate videos from text or images\n",
      "multimodalart\n",
      "8 days ago\n",
      "Running\n",
      "13\n",
      "LFM2 ColBERT\n",
      "üèÜ\n",
      "One Model to Embed Them All\n",
      "LiquidAI\n",
      "8 days ago\n",
      "All running apps, trending first\n",
      "Running\n",
      "on\n",
      "CPU Upgrade\n",
      "1.38k\n",
      "The Smol Training Playbook: The Secrets to Building World-Class LLMs\n",
      "üìù\n",
      "HuggingFaceTB\n",
      "about 18 hours ago\n",
      "Running\n",
      "15.7k\n",
      "DeepSite v3\n",
      "üê≥\n",
      "Generate any application by Vibe Coding\n",
      "enzostvs\n",
      "1 day ago\n",
      "Running\n",
      "2.27k\n",
      "Wan2.2 Animate\n",
      "üëÅ\n",
      "Wan2.2 Animate\n",
      "Wan-AI\n",
      "16 days ago\n",
      "Running\n",
      "on\n",
      "Zero\n",
      "MCP\n",
      "149\n",
      "Dream-wan2-2-faster-Pro\n",
      "üé¨\n",
      "Generate a video from an image with detailed \n"
     ]
    }
   ],
   "source": [
    "print(fetch_page_and_all_relevant_links(\"https://huggingface.co\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b863a55-f86c-4e3f-8a79-94e24c1a8cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "brochure_system_prompt = \"\"\"\n",
    "You are an assistant that analyzes the contents of several relevant pages from a company website\n",
    "and creates a short brochure about the company for prospective customers, investors and recruits.\n",
    "Respond in markdown without code blocks.\n",
    "Include details of company culture, customers and careers/jobs if you have the information.\n",
    "\"\"\"\n",
    "\n",
    "# Or uncomment the lines below for a more humorous brochure - this demonstrates how easy it is to incorporate 'tone':\n",
    "\n",
    "# brochure_system_prompt = \"\"\"\n",
    "# You are an assistant that analyzes the contents of several relevant pages from a company website\n",
    "# and creates a short, humorous, entertaining, witty brochure about the company for prospective customers, investors and recruits.\n",
    "# Respond in markdown without code blocks.\n",
    "# Include details of company culture, customers and careers/jobs if you have the information.\n",
    "# \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ab83d92-d36b-4ce0-8bcc-5bb4c2f8ff23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_brochure_user_prompt(company_name, url):\n",
    "    user_prompt = f\"\"\"\n",
    "You are looking at a company called: {company_name}\n",
    "Here are the contents of its landing page and other relevant pages;\n",
    "use this information to build a short brochure of the company in markdown without code blocks.\\n\\n\n",
    "\"\"\"\n",
    "    user_prompt += fetch_page_and_all_relevant_links(url)\n",
    "    user_prompt = user_prompt[:5_000] # Truncate if more than 5,000 characters\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd909e0b-1312-4ce2-a553-821e795d7572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 relevant links\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nYou are looking at a company called: HuggingFace\\nHere are the contents of its landing page and other relevant pages;\\nuse this information to build a short brochure of the company in markdown without code blocks.\\n\\n\\n## Landing Page:\\n\\nTitle: Hugging Face ‚Äì The AI community building the future.\\n\\nContent:\\nThe AI community building the future.\\nThe platform where the machine learning community collaborates on models, datasets, and applications.\\nExplore AI Apps\\nor\\nBrowse 1M+ models\\nTrending on\\nthis week\\nModels\\nUpdated\\n6 days ago\\n‚Ä¢\\n810k\\n‚Ä¢\\n1.05k\\nUpdated\\n4 days ago\\n‚Ä¢\\n19.4k\\n‚Ä¢\\n347\\nUpdated\\n1 day ago\\n‚Ä¢\\n2.25M\\n‚Ä¢\\n2.46k\\nUpdated\\n2 days ago\\n‚Ä¢\\n3.03k\\n‚Ä¢\\n221\\nUpdated\\nabout 14 hours ago\\n‚Ä¢\\n219\\nBrowse 1M+ models\\nSpaces\\n1.38k\\nThe Smol Training Playbook: The Secrets to Building World-Class LLMs\\nüìù\\n15.7k\\nDeepSite v3\\nüê≥\\nGenerate any application by Vibe Coding\\n2.27k\\nWan2.2 Animate\\nüëÅ\\nWan2.2 Animate\\n149\\nDream-wan2-2-faster-Pro\\nüé¨\\nGenerate a video from an image with detailed prompts\\n2.05k\\nWan2.2 14B Fast\\nüé•\\ngenerate a video from an image with a text prompt\\nBrowse 400k+ applications\\nDatasets\\nUpdated\\n7 days ago\\n‚Ä¢\\n12.4k\\n‚Ä¢\\n195\\nUpdated\\n14 days ago\\n‚Ä¢\\n13.6k\\n‚Ä¢\\n207\\nUpdated\\nSep 9\\n‚Ä¢\\n4.53k\\n‚Ä¢\\n59\\nUpdated\\n6 days ago\\n‚Ä¢\\n2.04k\\n‚Ä¢\\n45\\nUpdated\\nJan 6\\n‚Ä¢\\n36.9k\\n‚Ä¢\\n9.34k\\nBrowse 250k+ datasets\\nThe Home of Machine Learning\\nCreate, discover and collaborate on ML better.\\nThe collaboration platform\\nHost and collaborate on unlimited public models, datasets and applications.\\nMove faster\\nWith the HF Open source stack.\\nExplore all modalities\\nText, image, video, audio or even 3D.\\nBuild your portfolio\\nShare your work with the world and build your ML profile.\\nSign Up\\nAccelerate your ML\\nWe provide paid Compute and Enterprise solutions.\\nTeam & Enterprise\\nGive your team the most advanced platform to build AI with enterprise-grade security, access controls and\\n\\t\\t\\tdedicated support.\\nGetting started\\nStarting at $20/user/month\\nSingle Sign-On\\nRegions\\nPriority Support\\nAudit Logs\\nResource Groups\\nPrivate Datasets Viewer\\nInference Providers\\nAccess 45,000+ models from leading AI providers through a single, unified API with no service fees.\\nExplore Models\\nCompute\\nDeploy on optimized\\nInference Endpoints\\nor update your\\nSpaces applications\\nto a GPU in a few clicks.\\nView pricing\\nStarting at $0.60/hour for GPU\\nMore than 50,000 organizations are using Hugging Face\\nAi2\\nTeam\\nnon-profit\\n‚Ä¢\\n805 models\\n‚Ä¢\\n4.33k followers\\nAI at Meta\\nEnterprise\\ncompany\\n‚Ä¢\\n2.23k models\\n‚Ä¢\\n8.6k followers\\nAmazon\\ncompany\\n‚Ä¢\\n21 models\\n‚Ä¢\\n3.51k followers\\nGoogle\\nEnterprise\\ncompany\\n‚Ä¢\\n1.05k models\\n‚Ä¢\\n34.5k followers\\nIntel\\ncompany\\n‚Ä¢\\n250 models\\n‚Ä¢\\n3.17k followers\\nMicrosoft\\nEnterprise\\ncompany\\n‚Ä¢\\n426 models\\n‚Ä¢\\n16.3k followers\\nGrammarly\\nTeam\\ncompany\\n‚Ä¢\\n11 models\\n‚Ä¢\\n186 followers\\nWriter\\nEnterprise\\ncompany\\n‚Ä¢\\n32 models\\n‚Ä¢\\n365 followers\\nOur Open Source\\nWe are building the foundation of ML tooling with the community.\\nTransformers\\n152,088\\nState-of-the-art AI models for PyTorch\\nDiffusers\\n31,482\\nState-of-the-art Diffusion models in PyTorch\\nSafetensors\\n3,500\\nSafe way to store/distribute neural network weights\\nHub Python Library\\n3,034\\nPython client to interact with the Hugging Face Hub\\nTokenizers\\n10,206\\nFast tokenizers optimized for research & production\\nTRL\\n16,152\\nTrain transformers LMs with reinforcement learning\\nTransformers.js\\n14,794\\nState-of-the-art ML running directly in your browser\\nsmolagents\\n23,771\\nSmol library to build great agents in Python\\nPEFT\\n19,984\\nParameter-efficient finetuning for large language models\\nDatasets\\n20,810\\nAccess & share datasets for any ML tasks\\nText Generation Inference\\n10,620\\nServe language models with TGI optimized toolkit\\nAccelerate\\n9,262\\nTrain PyTorch models with multi-GPU, TPU, mixed precision\\n## Relevant Links:\\n\\n\\n### Link: about page\\nEnterprise Hub - Hugging Face\\n\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nCommunity\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nTeam & Enterprise Hub\\nScale your organization with the world‚Äôs leading AI platform\\nSubscribe to\\nTeam\\nstarting at $20/user/month\\nor\\nContact sales for\\nEnterprise\\nto explore flexible contract options\\nGive your organization the most advanced platform to build AI with enterprise-grade security, access controls,\\n\\t\\t\\tdedicated support and more.\\nSingle Sign-On\\nConnect securely to your identity provider with SSO integration.\\nRegions\\nSelect, manage, and audit the location of your repository data.\\nAudit Logs\\nStay in control with comprehensive logs that report on actions taken.\\nResource Groups\\nAccurately manage access to repositories with granular access control.\\nToken Management\\nCentralized token control and custom approval policies for organization access.\\nAnalytics\\nTrack and analyze repository usage data in a single dashboard.\\nAdvanced Compute Options\\nIncrease scalability and performance with more compute options like ZeroGPU.\\nZeroGPU Quota Boost\\nAll organization members get 5x more ZeroGPU quota to get the most of Spaces.\\nPrivate Datasets Viewer\\nEnable the Dataset Viewer on your private datasets for easier collaboration.\\nPrivate Storage\\nGet an additional 1 TB of private storage for each member '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_brochure_user_prompt(\"HuggingFace\", \"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b45846d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_brochure(company_name, url):\n",
    "    response = openai.chat.completions.create(\n",
    "        model=MODEL,  # FIXED: Use MODEL variable (gpt-4o-mini or ollama)\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": brochure_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
    "        ],\n",
    "    )\n",
    "    result = response.choices[0].message.content\n",
    "    display(Markdown(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b123615a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7 relevant links\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Hugging Face ‚Äì The AI Community Building the Future\n",
       "\n",
       "## Who We Are\n",
       "\n",
       "Hugging Face is the leading AI community and collaboration platform where developers, researchers, and organizations build the future of machine learning together. We provide the essential tools, infrastructure, and community space for creating, discovering, and collaborating on AI models, datasets, and applications across all modalities - including text, image, video, audio, and 3D.\n",
       "\n",
       "## Our Platform & Ecosystem\n",
       "\n",
       "**The Hub of Machine Learning Innovation**\n",
       "- **1M+ models** available for exploration and deployment\n",
       "- **400k+ applications** (Spaces) showcasing real-world AI implementations\n",
       "- **250k+ datasets** for training and research\n",
       "- Host and collaborate on unlimited public models, datasets, and applications\n",
       "\n",
       "**Enterprise-Grade Solutions**\n",
       "We provide Team and Enterprise subscriptions starting at $20/user/month, offering:\n",
       "- Enterprise-grade security and access controls\n",
       "- Single Sign-On integration\n",
       "- Comprehensive audit logs and analytics\n",
       "- Regional data management\n",
       "- Private storage and datasets viewer\n",
       "- Dedicated support and advanced compute options\n",
       "\n",
       "## Trusted by Industry Leaders\n",
       "\n",
       "More than 50,000 organizations trust Hugging Face, including major technology companies and research institutions:\n",
       "- **Google** (34.5k followers, 1.05k models)\n",
       "- **Microsoft** (16.3k followers, 426 models)\n",
       "- **AI at Meta** (8.6k followers, 2.23k models)\n",
       "- **Amazon**, **Intel**, **Grammarly**, **Writer**, and non-profits like **AI2**\n",
       "\n",
       "## Open Source Foundation\n",
       "\n",
       "We build the core ML tooling with the community through our popular open-source libraries:\n",
       "\n",
       "**Transformers** (152k+ stars) - State-of-the-art AI models for PyTorch  \n",
       "**Diffusers** (31k+ stars) - Advanced Diffusion models in PyTorch  \n",
       "**Datasets** (20k+ stars) - Access & share datasets for any ML tasks  \n",
       "**PEFT** (19k+ stars) - Parameter-efficient fine-tuning for large language models  \n",
       "**TRL** (16k+ stars) - Train transformers with reinforcement learning  \n",
       "**Transformers.js** (14k+ stars) - Run ML directly in your browser\n",
       "\n",
       "## Why Join Hugging Face?\n",
       "\n",
       "**For Developers & Researchers:**\n",
       "- Build your ML portfolio by sharing work with the global community\n",
       "- Accelerate development with our open-source stack\n",
       "- Access 45,000+ models through a unified API with no service fees\n",
       "- Deploy on optimized Inference Endpoints starting at $0.60/hour for GPU\n",
       "\n",
       "**For Enterprises:**\n",
       "- Scale your organization with the world's leading AI platform\n",
       "- Benefit from enterprise-grade security and dedicated support\n",
       "- Leverage advanced compute options like ZeroGPU with 5x quota boosts\n",
       "- Gain comprehensive analytics and resource management tools\n",
       "\n",
       "Hugging Face is more than a platform - we're a movement democratizing AI through collaboration, open-source innovation, and enterprise-ready solutions that empower everyone to build the future of machine learning."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_brochure(\"HuggingFace\", \"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61eaaab7-0b47-4b29-82d4-75d474ad8d18",
   "metadata": {},
   "source": [
    "## Finally - a minor improvement\n",
    "\n",
    "With a small adjustment, we can change this so that the results stream back from OpenAI,\n",
    "with the familiar typewriter animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51db0e49-f261-4137-aabe-92dd601f7725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_brochure(company_name, url):\n",
    "    stream = openai.chat.completions.create(\n",
    "        model=MODEL,  # FIXED: Use MODEL variable (gpt-4o-mini or ollama)\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": brochure_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
    "          ],\n",
    "        stream=True\n",
    "    )    \n",
    "    response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56bf0ae3-ee9d-4a72-9cd6-edcac67ceb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7 relevant links\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Hugging Face ‚Äì The AI Community Building the Future\n",
       "\n",
       "Hugging Face is the central platform where the global machine learning community collaborates to build the future of artificial intelligence. It is the home for creating, discovering, and collaborating on machine learning models, datasets, and applications.\n",
       "\n",
       "## The Platform for ML Collaboration\n",
       "\n",
       "*   **Host and Collaborate:** A platform for hosting and collaborating on unlimited public models, datasets, and applications.\n",
       "*   **Vast Repository:** Access over **1 million models**, **250,000 datasets**, and **400,000 applications** across all modalities, including text, image, video, audio, and 3D.\n",
       "*   **Build Your Portfolio:** A space for individuals and teams to share their work with the world and build their professional ML profiles.\n",
       "\n",
       "## Enterprise-Grade Solutions\n",
       "\n",
       "Hugging Face provides advanced tools for organizations of all sizes to accelerate their machine learning initiatives.\n",
       "\n",
       "*   **Team & Enterprise Hub:** Offers enterprise-grade security, access controls, dedicated support, and single sign-on. Plans start at **$20/user/month**.\n",
       "*   **Inference API:** Access over **45,000 models** from leading AI providers through a single, unified API with no service fees.\n",
       "*   **Compute:** Deploy on optimized Inference Endpoints or upgrade your applications with GPU compute, starting at **$0.60/hour**.\n",
       "\n",
       "## Trusted by Industry Leaders\n",
       "\n",
       "More than **50,000 organizations** trust Hugging Face, including major technology innovators and enterprises such as:\n",
       "*   **Google**, **Microsoft**, **AI at Meta**, **Amazon**, and **Intel**\n",
       "*   Companies like **Grammarly** and **Writer**\n",
       "\n",
       "## Open Source Leadership\n",
       "\n",
       "Hugging Face is the foundation of modern ML tooling, building critical open-source libraries in collaboration with the community. Key projects include:\n",
       "*   **Transformers:** State-of-the-art AI models for PyTorch.\n",
       "*   **Diffusers:** Cutting-edge Diffusion models.\n",
       "*   **Datasets:** Library for accessing and sharing datasets.\n",
       "*   **Transformers.js:** Run state-of-the-art ML directly in your browser.\n",
       "\n",
       "---\n",
       "**Join the community that is building the future of AI.**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stream_brochure(\"HuggingFace\", \"https://huggingface.co\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fdb3f8d8-a3eb-41c8-b1aa-9f60686a653b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7 relevant links\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Hugging Face: The AI Community Building the Future\n",
       "\n",
       "## Company Overview\n",
       "Hugging Face is the leading collaboration platform where the machine learning community works together on models, datasets, and applications. Positioned as \"The Home of Machine Learning,\" Hugging Face enables creators to build, discover, and collaborate on AI development in an open, community-driven environment.\n",
       "\n",
       "## Platform & Offerings\n",
       "\n",
       "**Core Platform Features:**\n",
       "- Hosting for unlimited public models, datasets, and applications\n",
       "- Access to over 1 million AI models, 250k+ datasets, and 400k+ applications\n",
       "- Support for multiple modalities including text, image, video, audio, and 3D\n",
       "- Tools for building ML portfolios and sharing work globally\n",
       "\n",
       "**Open Source Libraries:**\n",
       "Hugging Face maintains essential open-source tools that form the foundation of modern AI development:\n",
       "- **Transformers**: State-of-the-art AI models for PyTorch (152,088 stars)\n",
       "- **Diffusers**: Advanced diffusion models in PyTorch\n",
       "- **Datasets**: Access and share datasets for ML tasks\n",
       "- **Transformers.js**: Run ML models directly in browsers\n",
       "- **PEFT**: Parameter-efficient fine-tuning for large language models\n",
       "\n",
       "**Enterprise Solutions:**\n",
       "- Team & Enterprise plans starting at $20/user/month\n",
       "- Enterprise-grade security with Single Sign-On and audit logs\n",
       "- Dedicated support and resource groups\n",
       "- Private datasets viewer and inference providers\n",
       "- GPU compute starting at $0.60/hour\n",
       "\n",
       "## Company Culture & Community\n",
       "Hugging Face operates as a community-centric organization where collaboration and open-source development are foundational principles. The platform enables ML practitioners to build their professional profiles and portfolios while contributing to the broader AI ecosystem.\n",
       "\n",
       "## Customers & Partnerships\n",
       "More than 50,000 organizations trust Hugging Face, including major technology leaders:\n",
       "- **AI2 (Allen Institute for AI)**: 805 models, 4.33k followers\n",
       "- **Meta AI**: 2,200+ models, 8,600+ followers\n",
       "- **Google**: 1,000+ models, 34,500+ followers\n",
       "- **Microsoft**: 426 models, 16,300+ followers\n",
       "- **Amazon, Intel, Grammarly, Writer**, and many others\n",
       "\n",
       "## Career & Ecosystem Impact\n",
       "While specific career information isn't provided, Hugging Face represents a vital hub for AI professionals to:\n",
       "- Develop and showcase ML expertise\n",
       "- Collaborate on cutting-edge AI projects\n",
       "- Access state-of-the-art models and datasets\n",
       "- Build professional networks within the AI community\n",
       "\n",
       "Hugging Face has established itself as the central nervous system of the open AI ecosystem, empowering both individual developers and enterprise teams to accelerate machine learning development through community collaboration and robust platform tools."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Try changing the system prompt to the humorous version when you make the Brochure for Hugging Face:\n",
    "\n",
    "stream_brochure(\"HuggingFace\", \"https://huggingface.co\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (LLM)",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
