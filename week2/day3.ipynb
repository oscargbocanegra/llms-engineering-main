{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75e2ef28-594f-4c18-9d22-c6b8cd40ead2",
   "metadata": {},
   "source": [
    "# Day 3 - Conversational AI - aka Chatbot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "70e39cd8-ec79-4e3e-9c26-5659d42d0861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import anthropic\n",
    "import google.generativeai\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "87c698c3-3db4-40ba-b364-4638c0607bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "231605aa-fccb-447e-89cf-8b187444536a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key loaded: sk-proj-...\n",
      "Anthropic API Key loaded: sk-ant-...\n",
      "Google API Key loaded: AI...\n",
      "Ollama configured at: http://192.168.80.200:11434\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# API keys from environment\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "google_model = os.getenv('GOOGLE_MODEL')\n",
    "ollama_base_url = os.getenv('OLLAMA_BASE_URL')\n",
    "ollama_api_key = os.getenv('OLLAMA_API_KEY')\n",
    "ollama_model = os.getenv('OLLAMA_MODEL', 'deepseek-v3.1:671b-cloud')\n",
    "\n",
    "# Verify API keys\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key loaded: {openai_api_key[:8]}...\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key loaded: {anthropic_api_key[:7]}...\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key loaded: {google_api_key[:2]}...\")\n",
    "else:\n",
    "    print(\"Google API Key not set\")\n",
    "\n",
    "if ollama_base_url:\n",
    "    print(f\"Ollama configured at: {ollama_base_url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6541d58e-2297-4de1-b1f7-77da1b98b8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All clients initialized successfully\n"
     ]
    }
   ],
   "source": [
    "# Initialize API clients\n",
    "openai_client = OpenAI(api_key=openai_api_key)\n",
    "claude_client = anthropic.Anthropic(api_key=anthropic_api_key)\n",
    "google.generativeai.configure(api_key=google_api_key)\n",
    "\n",
    "# Initialize Ollama client (uses OpenAI-compatible API)\n",
    "ollama_client = OpenAI(\n",
    "    base_url=f\"{ollama_base_url}/v1\",\n",
    "    api_key=ollama_api_key\n",
    ")\n",
    "\n",
    "print(\"All clients initialized successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "75796079-00c1-4106-9e90-1656eeed050f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_ollama(prompt, stream=False):\n",
    "    \"\"\"Call Ollama model with OpenAI-compatible API\"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    \n",
    "    response = ollama_client.chat.completions.create(\n",
    "        model=ollama_model,\n",
    "        messages=messages,\n",
    "        stream=stream\n",
    "    )\n",
    "    \n",
    "    if stream:\n",
    "        for chunk in response:\n",
    "            if chunk.choices[0].delta.content:\n",
    "                print(chunk.choices[0].delta.content, end='', flush=True)\n",
    "    else:\n",
    "        return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e16839b5-c03b-4d9d-add6-87a0f6f37575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, I'll be in scientist-mode and change this global during the lab\n",
    "\n",
    "system_message = \"You are a helpful assistant\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e97227-f162-4d1a-a0b2-345ff248cbe7",
   "metadata": {},
   "source": [
    "## And now, writing a new callback\n",
    "\n",
    "We now need to write a function called:\n",
    "\n",
    "`chat(message, history)`\n",
    "\n",
    "Which will be a callback function we will give gradio.\n",
    "\n",
    "### The job of this function\n",
    "\n",
    "Take a message, take the prior conversation, and return the response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3bce145a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    history = [{\"role\":h[\"role\"], \"content\":h[\"content\"]} for h in history]\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    \n",
    "    stream = ollama_client.chat.completions.create(\n",
    "        model=ollama_model,\n",
    "        messages=messages,\n",
    "        stream = True\n",
    "    )\n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        yield response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8beeca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n",
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://3db28181c41d12cdae.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://3db28181c41d12cdae.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El historial es: \n",
      "[]\n",
      "Los mensajes son: \n",
      "[{'role': 'system', 'content': 'You are a helpful assistant'}, {'role': 'user', 'content': 'Hola'}]\n",
      "El historial es: \n",
      "[{'role': 'user', 'content': 'Hola'}, {'role': 'assistant', 'content': 'Â¡Hola! ðŸ˜Š Â¿En quÃ© puedo ayudarte hoy?'}]\n",
      "Los mensajes son: \n",
      "[{'role': 'system', 'content': 'You are a helpful assistant'}, {'role': 'user', 'content': 'Hola'}, {'role': 'assistant', 'content': 'Â¡Hola! ðŸ˜Š Â¿En quÃ© puedo ayudarte hoy?'}, {'role': 'user', 'content': 'quiero comprar una corbata'}]\n"
     ]
    }
   ],
   "source": [
    "gr.close_all()\n",
    "gr.ChatInterface(fn=chat, type=\"messages\").launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1334422a-808f-4147-9c4c-57d63d9780d0",
   "metadata": {},
   "source": [
    "## OK let's keep going!\n",
    "\n",
    "Using a system message to add context, and to give an example answer.. this is \"one shot prompting\" again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f91b414-8bab-472d-b9c9-3fa51259bdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful assistant in a clothes store. You should try to gently encourage \\\n",
    "the customer to try items that are on sale. Hats are 60% off, and most other items are 50% off. \\\n",
    "For example, if the customer says 'I'm looking to buy a hat', \\\n",
    "you could reply something like, 'Wonderful - we have lots of hats - including several that are part of our sales event.'\\\n",
    "Encourage the customer to buy hats if they are unsure what to get.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "413e9e4e-7836-43ac-a0c3-e1ab5ed6b136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* Running on public URL: https://163b4e221a166c122f.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://163b4e221a166c122f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El historial es: \n",
      "[]\n",
      "Los mensajes son: \n",
      "[{'role': 'system', 'content': \"You are a helpful assistant in a clothes store. You should try to gently encourage the customer to try items that are on sale. Hats are 60% off, and most other items are 50% off. For example, if the customer says 'I'm looking to buy a hat', you could reply something like, 'Wonderful - we have lots of hats - including several that are part of our sales event.'Encourage the customer to buy hats if they are unsure what to get.\"}, {'role': 'user', 'content': 'Hola'}]\n",
      "El historial es: \n",
      "[{'role': 'user', 'content': 'Hola'}, {'role': 'assistant', 'content': 'Â¡Hola! Bienvenido/a a nuestra tienda. Â¿En quÃ© puedo ayudarle hoy? Por ejemplo, tenemos muchas ofertas especiales en gorras y otras prendas. Â¿Hay algo que le interese ver?'}]\n",
      "Los mensajes son: \n",
      "[{'role': 'system', 'content': \"You are a helpful assistant in a clothes store. You should try to gently encourage the customer to try items that are on sale. Hats are 60% off, and most other items are 50% off. For example, if the customer says 'I'm looking to buy a hat', you could reply something like, 'Wonderful - we have lots of hats - including several that are part of our sales event.'Encourage the customer to buy hats if they are unsure what to get.\"}, {'role': 'user', 'content': 'Hola'}, {'role': 'assistant', 'content': 'Â¡Hola! Bienvenido/a a nuestra tienda. Â¿En quÃ© puedo ayudarle hoy? Por ejemplo, tenemos muchas ofertas especiales en gorras y otras prendas. Â¿Hay algo que le interese ver?'}, {'role': 'user', 'content': 'me gustaria comprar unos zapatos'}]\n"
     ]
    }
   ],
   "source": [
    "gr.close_all()\n",
    "gr.ChatInterface(fn=chat, type=\"messages\").launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d75f0ffa-55c8-4152-b451-945021676837",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message += \"\\nIf the customer asks for shoes, you should respond that shoes are not on sale today, \\\n",
    "but remind the customer to look at hats!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c602a8dd-2df7-4eb7-b539-4e01865a6351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* Running on public URL: https://357de3778122269866.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://357de3778122269866.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El historial es: \n",
      "[]\n",
      "Los mensajes son: \n",
      "[{'role': 'system', 'content': \"You are a helpful assistant in a clothes store. You should try to gently encourage the customer to try items that are on sale. Hats are 60% off, and most other items are 50% off. For example, if the customer says 'I'm looking to buy a hat', you could reply something like, 'Wonderful - we have lots of hats - including several that are part of our sales event.'Encourage the customer to buy hats if they are unsure what to get.\\nIf the customer asks for shoes, you should respond that shoes are not on sale today, but remind the customer to look at hats!\"}, {'role': 'user', 'content': 'hola'}]\n",
      "El historial es: \n",
      "[{'role': 'user', 'content': 'hola'}, {'role': 'assistant', 'content': 'Â¡Hola! Â¡Bienvenido/a a nuestra tienda! Â¿En quÃ© puedo ayudarte hoy? Â¿Buscas algo en especial? Tenemos una fantÃ¡stica promociÃ³n en sombreros, con un 60% de descuento.'}]\n",
      "Los mensajes son: \n",
      "[{'role': 'system', 'content': \"You are a helpful assistant in a clothes store. You should try to gently encourage the customer to try items that are on sale. Hats are 60% off, and most other items are 50% off. For example, if the customer says 'I'm looking to buy a hat', you could reply something like, 'Wonderful - we have lots of hats - including several that are part of our sales event.'Encourage the customer to buy hats if they are unsure what to get.\\nIf the customer asks for shoes, you should respond that shoes are not on sale today, but remind the customer to look at hats!\"}, {'role': 'user', 'content': 'hola'}, {'role': 'assistant', 'content': 'Â¡Hola! Â¡Bienvenido/a a nuestra tienda! Â¿En quÃ© puedo ayudarte hoy? Â¿Buscas algo en especial? Tenemos una fantÃ¡stica promociÃ³n en sombreros, con un 60% de descuento.'}, {'role': 'user', 'content': 'quiero comprar unos zapatos'}]\n"
     ]
    }
   ],
   "source": [
    "gr.close_all()\n",
    "gr.ChatInterface(fn=chat, type=\"messages\").launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0a987a66-1061-46d6-a83a-a30859dc88bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def chat(message, history):\n",
    "    history = [{\"role\":h[\"role\"], \"content\":h[\"content\"]} for h in history]\n",
    "    relevant_system_message = system_message\n",
    "    if 'belt' in message.lower():\n",
    "        relevant_system_message += \" The store does not sell belts; if you are asked for belts, be sure to point out other items on sale.\"\n",
    "    \n",
    "    messages = [{\"role\": \"system\", \"content\": relevant_system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "\n",
    "    stream = ollama_client.chat.completions.create(\n",
    "        model=ollama_model,\n",
    "        messages=messages,\n",
    "        stream = True\n",
    "    )\n",
    "\n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        yield response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "20570de2-eaad-42cc-a92c-c779d71b48b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7865\n",
      "* Running on public URL: https://bcf3359b474f8b6df1.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://bcf3359b474f8b6df1.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.close_all()\n",
    "gr.ChatInterface(fn=chat, type=\"messages\").launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (LLM)",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
