{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {},
   "source": [
    "# Personalized Programming Tutor - Week 1 Project\n",
    "\n",
    "## Project Objective\n",
    "\n",
    "Build a **personalized tutor** that takes a technical question about code and responds with a detailed and educational explanation.\n",
    "\n",
    "### What does this tutor do?\n",
    "\n",
    "- Explains complex code in a simple and structured way\n",
    "- Provides examples and analogies\n",
    "- Teaches the \"why\" behind code patterns\n",
    "- Responds in well-formatted Markdown\n",
    "- Supports **streaming** to see responses in real-time\n",
    "\n",
    "### Features:\n",
    "\n",
    "- **Flexible**: Switch between Ollama (local, free) and OpenAI (cloud)\n",
    "- **Interactive**: Streaming mode with typewriter effect\n",
    "- **Educational**: Designed specifically for learning\n",
    "\n",
    "---\n",
    "\n",
    "**Instructions**: Execute the cells in order and modify the `question` variable to ask new questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "# If these fail, please check you're running from an 'activated' environment with (llms) in the command prompt\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from scraper import fetch_website_links, fetch_website_contents\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3a79f19-e9f8-4d4c-8a7e-ce7b58d3150d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected provider: OLLAMA\n"
     ]
    }
   ],
   "source": [
    "# CONFIGURATION: Change here to test different providers\n",
    "# Options: 'ollama' or 'openai'\n",
    "USE_PROVIDER = 'ollama'  # Change to 'openai' to use OpenAI\n",
    "\n",
    "print(f\"Selected provider: {USE_PROVIDER.upper()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "529c7952-36c5-4c9e-9bfe-479cb75f7db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Using OLLAMA (Local)\n",
      "==================================================\n",
      "   Base URL: http://192.168.80.200:11434\n",
      "   Model: qwen3-coder:480b-cloud\n",
      "   Cost: FREE\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Initialize and constants\n",
    "\n",
    "# Load configuration from global .env\n",
    "load_dotenv(dotenv_path='/workspace/.env', override=True)\n",
    "\n",
    "# Use provider selected in previous cell (or from .env as fallback)\n",
    "llm_provider = USE_PROVIDER if 'USE_PROVIDER' in globals() else os.getenv('LLM_PROVIDER', 'ollama')\n",
    "\n",
    "if llm_provider == 'ollama':\n",
    "    # OLLAMA CONFIGURATION (Local)\n",
    "    ollama_base_url = os.getenv('OLLAMA_BASE_URL')\n",
    "    ollama_api_key = os.getenv('OLLAMA_API_KEY')\n",
    "    #ollama_model = os.getenv('OLLAMA_MODEL')\n",
    "    ollama_model = 'qwen3-coder:480b-cloud'\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(\"Using OLLAMA (Local)\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"   Base URL: {ollama_base_url}\")\n",
    "    print(f\"   Model: {ollama_model}\")\n",
    "    print(f\"   Cost: FREE\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Create OpenAI client pointing to Ollama\n",
    "    openai = OpenAI(\n",
    "        base_url=f\"{ollama_base_url}/v1\",\n",
    "        api_key=ollama_api_key\n",
    "    )\n",
    "    MODEL = ollama_model\n",
    "    \n",
    "else:\n",
    "    # OPENAI CONFIGURATION (Cloud)\n",
    "    api_key = os.getenv('OPENAI_API_KEY')\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(\"Using OPENAI (Cloud API)\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    if api_key and api_key.startswith('sk-proj-') and len(api_key) > 50:\n",
    "        print(f\"   API Key: sk-proj-...{api_key[-8:]}\")\n",
    "        print(f\"   Model: gpt-4o-mini\")\n",
    "        print(f\"   Cost: ~$0.15 / 1M tokens input\")\n",
    "        print(\"   Status: Configured correctly\")\n",
    "    else:\n",
    "        print(\"   Status: Invalid or missing API Key\")\n",
    "        print(\"   Check the .env file\")\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    openai = OpenAI(api_key=api_key)\n",
    "    MODEL = 'gpt-4o-mini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "08a52f22-d661-4d45-9a78-dfba570abc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call LLM API with streaming support\n",
    "\n",
    "def callModel(ask, use_stream=False):\n",
    "    \"\"\"\n",
    "    Calls the LLM model with the provided messages\n",
    "    \n",
    "    Args:\n",
    "        ask: List of messages with format [{\"role\": \"...\", \"content\": \"...\"}]\n",
    "        use_stream: If True, displays response in real-time (typewriter effect)\n",
    "    \n",
    "    Returns:\n",
    "        The complete response content\n",
    "    \"\"\"\n",
    "    if use_stream:\n",
    "        stream = openai.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=ask,\n",
    "            stream=True  # Enable streaming\n",
    "        )\n",
    "        \n",
    "        response = \"\"\n",
    "        display_handle = None\n",
    "        \n",
    "        for chunk in stream:\n",
    "            content = chunk.choices[0].delta.content or ''\n",
    "            response += content\n",
    "            \n",
    "            if display_handle is None and response:\n",
    "                display_handle = display(Markdown(response), display_id=True)\n",
    "            elif display_handle is not None:\n",
    "                update_display(Markdown(response), display_id=display_handle.display_id)\n",
    "        \n",
    "    else:\n",
    "        response = openai.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=ask\n",
    "        )\n",
    "        result = response.choices[0].message.content\n",
    "        display(Markdown(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our system prompt - PERSONALIZED TUTOR\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are an expert programming tutor with deep knowledge in Python, JavaScript, and software engineering.\n",
    "\n",
    "Your teaching style:\n",
    "- Explain concepts clearly and step by step\n",
    "- Use analogies and real-world examples\n",
    "- Break down complex code into understandable parts\n",
    "- Highlight best practices and common pitfalls\n",
    "- Encourage learning by explaining the \"why\" behind the code\n",
    "\n",
    "Response format:\n",
    "- Always respond in well-formatted Markdown\n",
    "- Use headers, lists, and code blocks appropriately\n",
    "- Do NOT wrap your entire response in markdown code fences (```)\n",
    "- Include examples when helpful\n",
    "- Be concise but thorough\n",
    "\n",
    "Your goal is to help students truly understand programming concepts, not just memorize syntax.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0188d485-6a9f-4c5c-85b9-d0c127532e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PERSONALIZED PROGRAMMING TUTOR\n",
      "============================================================\n",
      "\n",
      "Enter the code you want to understand.\n",
      "\n",
      "Example:\n",
      "  yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
      "\n",
      "Your question (paste your code below):\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n"
     ]
    }
   ],
   "source": [
    "# Get the technical question from user input\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"PERSONALIZED PROGRAMMING TUTOR\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nEnter the code you want to understand.\")\n",
    "print(\"\\nExample:\")\n",
    "print('  yield from {book.get(\"author\") for book in books if book.get(\"author\")}')\n",
    "print(\"\\nYour question (paste your code below):\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "question = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d041ea01-3517-428a-a68b-b62bda983631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define user prompt using the question variable\n",
    "\n",
    "user_prompt = f\"\"\"\n",
    "Please explain the following code in detail:\n",
    "\n",
    "```python\n",
    "{question}\n",
    "```\n",
    "\n",
    "Include:\n",
    "1. What this code does\n",
    "2. How it works step by step\n",
    "3. Why someone would use this approach\n",
    "4. Any important concepts or patterns involved\n",
    "\"\"\"\n",
    "\n",
    "# Build messages for the LLM\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": user_prompt}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8d627f33-b12c-4890-8a25-0fd20d95afae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Understanding `yield from` with Set Comprehension\n",
       "\n",
       "## What This Code Does\n",
       "\n",
       "This code **extracts unique author names** from a collection of books and yields them one by one. It's a generator expression that:\n",
       "- Filters books to only those with author information\n",
       "- Extracts the author names\n",
       "- Ensures uniqueness (no duplicate authors)\n",
       "- Yields each unique author individually\n",
       "\n",
       "## How It Works Step by Step\n",
       "\n",
       "Let me break this down into its components:\n",
       "\n",
       "### 1. The Set Comprehension `{...}`\n",
       "```python\n",
       "{book.get(\"author\") for book in books if book.get(\"author\")}\n",
       "```\n",
       "\n",
       "This creates a **set** (unique collection) using this logic:\n",
       "- **Iteration**: `for book in books` - goes through each book\n",
       "- **Filter**: `if book.get(\"author\")` - only includes books that have an author\n",
       "- **Extraction**: `book.get(\"author\")` - gets the author name from each book\n",
       "\n",
       "### 2. The `yield from` Statement\n",
       "```python\n",
       "yield from {set_of_authors}\n",
       "```\n",
       "\n",
       "Instead of yielding the entire set at once, `yield from` **delegates** to the set and yields each element individually.\n",
       "\n",
       "## Complete Example\n",
       "\n",
       "```python\n",
       "def get_unique_authors(books):\n",
       "    yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
       "\n",
       "# Example usage\n",
       "books = [\n",
       "    {\"title\": \"Book 1\", \"author\": \"Author A\"},\n",
       "    {\"title\": \"Book 2\", \"author\": \"Author B\"},\n",
       "    {\"title\": \"Book 3\", \"author\": \"Author A\"},  # Duplicate\n",
       "    {\"title\": \"Book 4\"},  # No author\n",
       "    {\"title\": \"Book 5\", \"author\": \"Author C\"}\n",
       "]\n",
       "\n",
       "authors = list(get_unique_authors(books))\n",
       "print(authors)  # ['Author A', 'Author B', 'Author C'] (order may vary - it's a set!)\n",
       "```\n",
       "\n",
       "## Why Use This Approach?\n",
       "\n",
       "### Advantages:\n",
       "1. **Memory Efficient**: Generates authors one at a time instead of creating a full list\n",
       "2. **Automatic Deduplication**: Sets inherently remove duplicates\n",
       "3. **Clean and Concise**: Combines filtering, extraction, and deduplication in one line\n",
       "4. **Lazy Evaluation**: Authors are only processed when requested\n",
       "\n",
       "### Alternative Approaches:\n",
       "```python\n",
       "# More verbose but clearer for beginners\n",
       "def get_unique_authors_verbose(books):\n",
       "    seen_authors = set()\n",
       "    for book in books:\n",
       "        author = book.get(\"author\")\n",
       "        if author and author not in seen_authors:\n",
       "            seen_authors.add(author)\n",
       "            yield author\n",
       "\n",
       "# Creates full list in memory (less efficient)\n",
       "def get_unique_authors_list(books):\n",
       "    return list({book.get(\"author\") for book in books if book.get(\"author\")})\n",
       "```\n",
       "\n",
       "## Important Concepts and Patterns\n",
       "\n",
       "### 1. **Set Comprehension**\n",
       "```python\n",
       "{expression for item in iterable if condition}\n",
       "```\n",
       "- Creates a set automatically removing duplicates\n",
       "- More efficient than list comprehension + set conversion\n",
       "\n",
       "### 2. **`yield from` Pattern**\n",
       "- **Delegation**: Delegates to another iterable\n",
       "- **Flattening**: Useful for yielding elements from nested structures\n",
       "- **Memory Efficiency**: Maintains generator benefits\n",
       "\n",
       "### 3. **Defensive Programming with `.get()`**\n",
       "```python\n",
       "book.get(\"author\")  # Returns None if key doesn't exist\n",
       "book[\"author\"]      # Raises KeyError if key doesn't exist\n",
       "```\n",
       "\n",
       "### 4. **Truthiness Filtering**\n",
       "```python\n",
       "if book.get(\"author\")  # Filters out None, empty strings, etc.\n",
       "```\n",
       "\n",
       "## Common Pitfalls\n",
       "\n",
       "⚠️ **Order is not guaranteed** - sets are unordered, so author yield order may vary\n",
       "⚠️ **Empty values** - If author field exists but is empty string (`\"\"`), it gets filtered out\n",
       "⚠️ **Type safety** - assumes all author values are hashable (strings, not lists/dicts)\n",
       "\n",
       "## Real-World Analogy\n",
       "\n",
       "Think of this like a **library card catalog system**:\n",
       "1. You have a pile of books (`books`)\n",
       "2. You only want cards for books that have author information (`if book.get(\"author\")`)\n",
       "3. You extract the author names and put each unique name on a separate index card (`set comprehension`)\n",
       "4. You then feed these cards one by one into a sorting machine (`yield from`)\n",
       "\n",
       "This approach is elegant for scenarios where you need unique values processed individually while maintaining memory efficiency!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Execute the tutor with the question\n",
    "\n",
    "# Option 1: Without streaming (shows complete result at the end)\n",
    "# callModel(messages)\n",
    "\n",
    "# Option 2: With streaming (typewriter effect - recommended)\n",
    "callModel(messages, use_stream=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603a5714-f4eb-4c18-9fdf-11c3a9d09a72",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bffb1a-4618-4bc9-bf8b-d1f44886ff6f",
   "metadata": {},
   "source": [
    "## How to Use This Personalized Tutor\n",
    "\n",
    "To ask a question:\n",
    "\n",
    "1. **Execute cells 1-6** to set up the environment\n",
    "2. **Execute cell 7** and enter your code when prompted\n",
    "3. **Execute cells 8 and 9** to get the explanation\n",
    "\n",
    "### Examples of questions you can ask:\n",
    "\n",
    "```python\n",
    "# Example 1: Generators\n",
    "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
    "\n",
    "# Example 2: List comprehension\n",
    "[x**2 for x in range(10) if x % 2 == 0]\n",
    "\n",
    "# Example 3: Decorators\n",
    "@decorator\n",
    "def function(): pass\n",
    "\n",
    "# Example 4: Context managers\n",
    "with open(\"file.txt\") as f:\n",
    "    data = f.read()\n",
    "\n",
    "# Example 5: Lambda and map\n",
    "list(map(lambda x: x * 2, [1, 2, 3]))\n",
    "```\n",
    "\n",
    "**Tip**: Use `use_stream=True` in cell 9 to see the response in real-time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043f0e67-f4ef-4e61-a97d-ded4b6539fce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (LLM)",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
